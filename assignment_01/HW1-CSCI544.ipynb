{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove this before submission\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/aditya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "! pip install bs4 # in case you don't have it installed\n",
    "\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Jewelry_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/gcxbjppx70qfkdwy32kg04dh0000gn/T/ipykernel_43879/949400013.py:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"./data/amazon_reviews_us_Jewelry_v1_00.tsv\", sep=\"\\t\", usecols=[\"star_rating\", \"review_body\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>so beautiful even tho clearly not high end ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.. I got this set for my mother, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Exactly as pictured and my daughter's friend l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Love it. Fits great. Super comfortable and nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Got this as a Mother's Day gift for my Mom and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  star_rating                                        review_body\n",
       "0           5  so beautiful even tho clearly not high end ......\n",
       "1           5  Great product.. I got this set for my mother, ...\n",
       "2           5  Exactly as pictured and my daughter's friend l...\n",
       "3           5  Love it. Fits great. Super comfortable and nea...\n",
       "4           5  Got this as a Mother's Day gift for my Mom and..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the tab separated data file, and print the first 5 rows for confirmation\n",
    "data = pd.read_csv(\"./data/amazon_reviews_us_Jewelry_v1_00.tsv\", sep=\"\\t\", usecols=[\"star_rating\", \"review_body\"])\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1767042</td>\n",
       "      <td>1766807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11</td>\n",
       "      <td>1618522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>5</td>\n",
       "      <td>Love it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1041056</td>\n",
       "      <td>4288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        star_rating review_body\n",
       "count       1767042     1766807\n",
       "unique           11     1618522\n",
       "top               5     Love it\n",
       "freq        1041056        4288"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 4, 3, 2, nan, '5', '1', '3', '4', '2', '2012-12-21'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.star_rating.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1040896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             review_body\n",
       "star_rating             \n",
       "1                 150441\n",
       "2                  97259\n",
       "3                 153660\n",
       "4                 259019\n",
       "5                1040896\n",
       "1                   4566\n",
       "2                   3541\n",
       "2012-12-21             0\n",
       "3                   5999\n",
       "4                  11411\n",
       "5                  40015"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby([\"star_rating\"]).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the outlier which is star_rating = \"2012-12-21\"\n",
    "data = data[data.star_rating != \"2012-12-21\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan valued rows\n",
    "data = data[data.star_rating.notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1767041</td>\n",
       "      <td>1766807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10</td>\n",
       "      <td>1618522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>5</td>\n",
       "      <td>Love it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1041056</td>\n",
       "      <td>4288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        star_rating review_body\n",
       "count       1767041     1766807\n",
       "unique           10     1618522\n",
       "top               5     Love it\n",
       "freq        1041056        4288"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all star rating to integer\n",
    "data[\"star_rating\"] = data.star_rating.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>so beautiful even tho clearly not high end ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.. I got this set for my mother, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Exactly as pictured and my daughter's friend l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Love it. Fits great. Super comfortable and nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Got this as a Mother's Day gift for my Mom and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                        review_body\n",
       "0            5  so beautiful even tho clearly not high end ......\n",
       "1            5  Great product.. I got this set for my mother, ...\n",
       "2            5  Exactly as pictured and my daughter's friend l...\n",
       "3            5  Love it. Fits great. Super comfortable and nea...\n",
       "4            5  Got this as a Mother's Day gift for my Mom and..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>so beautiful even tho clearly not high end ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.. I got this set for my mother, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Exactly as pictured and my daughter's friend l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Love it. Fits great. Super comfortable and nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Got this as a Mother's Day gift for my Mom and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                        review_body\n",
       "0            5  so beautiful even tho clearly not high end ......\n",
       "1            5  Great product.. I got this set for my mother, ...\n",
       "2            5  Exactly as pictured and my daughter's friend l...\n",
       "3            5  Love it. Fits great. Super comfortable and nea...\n",
       "4            5  Got this as a Mother's Day gift for my Mom and..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data.review_body.notnull()]\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are no empty reviews\n",
    "(data.review_body.str.len() <= 0).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can continue with the process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We select 20000 reviews randomly from each rating class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(101)\n",
    "N_SAMPLES = 25000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = data.groupby(\"star_rating\", group_keys=False).apply(lambda x: x.sample(N_SAMPLES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avg. length of reviews BEFORE CLEANING :: 189.754576'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_len_before_cleaning = sampled_data.review_body.str.len().mean()\n",
    "f\"Avg. length of reviews BEFORE CLEANING :: {avg_len_before_cleaning}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all reviews to lower case (optional according to study)\n",
    "def to_lower(data: pd.Series):\n",
    "    return data.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_characters(data: pd.Series):\n",
    "    import unicodedata\n",
    "\n",
    "    \"\"\"Removes accented characters from the Series\n",
    "\n",
    "    Args:\n",
    "        data (pd.Series): Series of string\n",
    "\n",
    "    Returns:\n",
    "        _type_: pd.Series\n",
    "    \"\"\"\n",
    "    import unicodedata\n",
    "\n",
    "    return data.apply(lambda x: unicodedata.normalize(\"NFKD\", x).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_and_url(data: pd.Series):\n",
    "    \"\"\"Function to remove\n",
    "             1. HTML encodings\n",
    "             2. HTML tags (both closed and open)\n",
    "             3. URLs\n",
    "\n",
    "    Args:\n",
    "        data (pd.Series): A Pandas series of type string\n",
    "\n",
    "    Returns:\n",
    "        _type_: pd.Series\n",
    "    \"\"\"\n",
    "    # Remove HTML encodings\n",
    "    data.str.replace(r\"&#\\d+;\", \" \", regex=True)\n",
    "\n",
    "    # Remove HTML tags (both open and closed)\n",
    "    data.str.replace(r\"<[a-zA-Z]+\\s?/?>\", \" \", regex=True)\n",
    "\n",
    "    # Remove URLs\n",
    "    data.str.replace(r\"https?://([\\w\\-\\._]+){2,}/[\\w\\-\\.\\-/=\\+_\\?]+\", \" \", regex=True)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-alphabetical characters\n",
    "def remove_non_alpa_characters(data: pd.Series):\n",
    "    return data.str.replace(r\"_+|\\\\|[^a-zA-Z\\s]\", \" \", regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "def remove_extra_spaces(data: pd.Series):\n",
    "    return data.str.replace(r\"^\\s*|\\s\\s*\", \" \", regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (0.1.72)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (from contractions) (0.0.21)\n",
      "Requirement already satisfied: pyahocorasick in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
      "Requirement already satisfied: anyascii in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n"
     ]
    }
   ],
   "source": [
    "# Install contractions package, if you don't have it\n",
    "! pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding contractions\n",
    "def fix_contractions(data: pd.Series):\n",
    "    import contractions\n",
    "\n",
    "    def contraction_fixer(txt: str):\n",
    "        return \" \".join([contractions.fix(word) for word in txt.split()])\n",
    "\n",
    "    return data.apply(contraction_fixer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: to_lower\n",
      "Ended: to_lower\n",
      "Starting: remove_accented_characters\n",
      "Ended: remove_accented_characters\n",
      "Starting: remove_html_and_url\n",
      "Ended: remove_html_and_url\n",
      "Starting: fix_contractions\n",
      "Ended: fix_contractions\n",
      "Starting: remove_non_alpa_characters\n",
      "Ended: remove_non_alpa_characters\n",
      "Starting: remove_extra_spaces\n",
      "Ended: remove_extra_spaces\n"
     ]
    }
   ],
   "source": [
    "# A dictionary containing the columns and a list of functions to perform on it in order\n",
    "# TODO: Think about handling negation.\n",
    "# TODO: Replace numbers with NUM tag.\n",
    "data_cleaning_pipeline = {\n",
    "    \"review_body\": [\n",
    "        to_lower,\n",
    "        remove_accented_characters,\n",
    "        remove_html_and_url,\n",
    "        fix_contractions,\n",
    "        remove_non_alpa_characters,\n",
    "        remove_extra_spaces,\n",
    "    ]\n",
    "}\n",
    "\n",
    "cleaned_data = sampled_data.copy()\n",
    "\n",
    "# Process all the cleaning instructions\n",
    "for col, pipeline in data_cleaning_pipeline.items():\n",
    "    # Get the column to perform cleaning on\n",
    "    temp_data = cleaned_data[col].copy()\n",
    "\n",
    "    # Perform all the cleaning functions sequencially\n",
    "    for func in pipeline:\n",
    "        print(f\"Starting: {func.__name__}\")\n",
    "        temp_data = func(temp_data)\n",
    "        print(f\"Ended: {func.__name__}\")\n",
    "\n",
    "    # Replace the old column with cleaned one.\n",
    "    cleaned_data[col] = temp_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avg. length of reviews after cleaning :: 185.227792'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_len_after_cleaning = cleaned_data.review_body.str.len().mean()\n",
    "f\"Avg. length of reviews after cleaning :: {avg_len_after_cleaning}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Before Cleaning: 189.754576 ;; After Cleaning: 185.227792'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Before Cleaning: {avg_len_before_cleaning} ;; After Cleaning: {avg_len_after_cleaning}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove Test Block\n",
    "# Checkpoint: Cleaned Data\n",
    "cleaned_data.to_csv(\"./data/cleaned.tsv\", sep=\"\\t\", index=False, encoding=\"UTF-8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove Test Block\n",
    "cleaned_data = pd.read_csv(\"./data/cleaned.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. length of the reviews before preprocessing :: 185.227792\n"
     ]
    }
   ],
   "source": [
    "avg_len_before_preprocessing = cleaned_data[\"review_body\"].str.len().mean()\n",
    "print(f\"Avg. length of the reviews before preprocessing :: {avg_len_before_preprocessing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data: pd.Series):\n",
    "    from nltk.tokenize import word_tokenize\n",
    "\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "    return data.apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Set\n",
    "\n",
    "\n",
    "def remove_stopwords(data: pd.Series):\n",
    "    \"\"\"Remove stop words using the NLTK stopwords dictionary\n",
    "\n",
    "    Args:\n",
    "        string (str): a document\n",
    "\n",
    "    Returns:\n",
    "        str: a document with stopwords removed\n",
    "    \"\"\"\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    nltk.download(\"stopwords\")\n",
    "\n",
    "    stopwords = set(stopwords.words())\n",
    "\n",
    "    def remover(word_list: List[str], stopwords: Set[str]):\n",
    "        return [word for word in word_list if not word in stopwords]\n",
    "\n",
    "    return data.apply(lambda word_list: remover(word_list, stopwords))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(data: pd.Series, consider_pos_tag: bool = True):\n",
    "    from nltk.corpus import wordnet\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "    nltk.download(\"omw-1.4\")\n",
    "\n",
    "    # POS tagging\n",
    "    def perform_nltk_pos_tag(data: pd.Series):\n",
    "        from nltk import pos_tag\n",
    "\n",
    "        nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "        return data.apply(pos_tag)\n",
    "\n",
    "    # Convert POS tag to wordnet pos tags\n",
    "    def wordnet_pos_tagger(tag: str):\n",
    "        if tag.startswith(\"J\"):\n",
    "            return wordnet.ADJ\n",
    "        elif tag.startswith(\"V\"):\n",
    "            return wordnet.VERB\n",
    "        elif tag.startswith(\"N\"):\n",
    "            return wordnet.NOUN\n",
    "        elif tag.startswith(\"R\"):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = list()\n",
    "\n",
    "    if consider_pos_tag:\n",
    "        pos_tagged_data = data.copy()\n",
    "        pos_tagged_data = perform_nltk_pos_tag(data)\n",
    "\n",
    "        for row in pos_tagged_data:\n",
    "\n",
    "            lemmatized_row = list()\n",
    "\n",
    "            if consider_pos_tag:\n",
    "                for word, tag in row:\n",
    "                    wordnet_pos_tag = wordnet_pos_tagger(tag)\n",
    "\n",
    "                    if wordnet_pos_tag is None:\n",
    "                        lemmatized_row.append(word)\n",
    "                    else:\n",
    "                        result = lemmatizer.lemmatize(word, wordnet_pos_tag)\n",
    "                        lemmatized_row.append(lemmatizer.lemmatize(word, wordnet_pos_tag))\n",
    "\n",
    "            lemmatized.append(lemmatized_row)\n",
    "    else:\n",
    "        for row in data:\n",
    "            lemmatized_row = list()\n",
    "\n",
    "            for word in row:\n",
    "                lemmatized_row.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "            lemmatized.append(lemmatized_row)\n",
    "\n",
    "    return pd.Series(lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate lemmatized sentences back into one sentence\n",
    "def concatenate(data: pd.Series):\n",
    "    return data.apply(lambda words: \" \".join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: tokenize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/aditya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended: tokenize\n",
      "Starting: lemmatize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/aditya/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended: lemmatize\n",
      "Starting: concatenate\n",
      "Ended: concatenate\n"
     ]
    }
   ],
   "source": [
    "preprocessing_pipeline = {\"review_body\": [tokenize, lemmatize, concatenate]}\n",
    "\n",
    "# Run the pipeline\n",
    "preprocessed_data = cleaned_data.copy()\n",
    "\n",
    "# Process all the cleaning instructions\n",
    "for col, pipeline in preprocessing_pipeline.items():\n",
    "    # Get the column to perform cleaning on\n",
    "    temp_data = preprocessed_data[col].copy()\n",
    "\n",
    "    # Perform all the cleaning functions sequencially\n",
    "    for func in pipeline:\n",
    "        print(f\"Starting: {func.__name__}\")\n",
    "\n",
    "        if func.__name__ == \"lemmatize\":\n",
    "            temp_data = func(temp_data, consider_pos_tag=False)\n",
    "        else:\n",
    "            temp_data = func(temp_data)\n",
    "\n",
    "        print(f\"Ended: {func.__name__}\")\n",
    "\n",
    "    # Replace the old column with cleaned one.\n",
    "    preprocessed_data[col] = temp_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove Test Block\n",
    "# Save lemmatized data\n",
    "import pickle as pkl\n",
    "\n",
    "with open(\"./data/preprocessed.pkl\", \"wb\") as file:\n",
    "    pkl.dump(preprocessed_data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. length of the reviews after preprocessing :: 181.045968\n"
     ]
    }
   ],
   "source": [
    "avg_len_after_preprocessing = preprocessed_data[\"review_body\"].str.len().mean()\n",
    "print(f\"Avg. length of the reviews after preprocessing :: {avg_len_after_preprocessing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Before Preprocessing: 185.227792 ;; After Preprocessing: 181.045968'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Before Preprocessing: {avg_len_before_preprocessing} ;; After Preprocessing: {avg_len_after_preprocessing}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove Test Block\n",
    "# Load lemmatized data\n",
    "# import pickle as pkl\n",
    "\n",
    "# preprocessed_data = None\n",
    "# with open(\"./data/preprocessed.pkl\", \"rb\") as file:\n",
    "#     lemmatized_data = pkl.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             review_body\n",
       "star_rating             \n",
       "1                     14\n",
       "2                      2\n",
       "3                      1\n",
       "4                     12\n",
       "5                     25"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data[preprocessed_data[\"review_body\"].str.len() == 0].groupby(\"star_rating\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [star_rating, review_body]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data[preprocessed_data[\"review_body\"].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data[\"review_body\"].isnull().values.any(), preprocessed_data[\"review_body\"].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_body]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(False, 0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Drop empty strings\n",
    "preprocessed_data[\"review_body\"].replace(\"\", np.nan, inplace=True)\n",
    "preprocessed_data.dropna(subset=[\"review_body\"], inplace=True)\n",
    "preprocessed_data[preprocessed_data[\"review_body\"].str.len() == 0].groupby(\"star_rating\").count()\n",
    "preprocessed_data[\"review_body\"].isnull().values.any(), preprocessed_data[\"review_body\"].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             review_body\n",
       "star_rating             \n",
       "1                  24986\n",
       "2                  24998\n",
       "3                  24999\n",
       "4                  24988\n",
       "5                  24975"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.groupby([\"star_rating\"]).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove Checkpoint ...\n",
    "preprocessed_data.to_csv(\"./data/data.tsv\", sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove this block\n",
    "# Retrieve checkpoint\n",
    "# data = pd.read_csv(\"./data/data.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data.\n",
    "data = preprocessed_data.groupby(\"star_rating\", group_keys=False).apply(lambda x: x.sample(20000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data 80-20 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, stratify=data[\"star_rating\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train[\"review_body\"].str.len() == 0).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             review_body\n",
       "star_rating             \n",
       "1                  20000\n",
       "2                  20000\n",
       "3                  20000\n",
       "4                  20000\n",
       "5                  20000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby([\"star_rating\"]).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(train[\"review_body\"])\n",
    "\n",
    "X_tfidf_train = vectorizer.transform(train[\"review_body\"])\n",
    "X_tfidf_test = vectorizer.transform(test[\"review_body\"])\n",
    "y_train = train[\"star_rating\"]\n",
    "y_test = test[\"star_rating\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaaaa',\n",
       " 'aaaaaaaaaa',\n",
       " 'aaah',\n",
       " 'aaahhhhh',\n",
       " 'aaallll',\n",
       " 'aadjustable',\n",
       " 'aagaard',\n",
       " 'aahhhs',\n",
       " 'aahs',\n",
       " 'aandi',\n",
       " 'aarp',\n",
       " 'ab',\n",
       " 'aback',\n",
       " 'abalone',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abaout',\n",
       " 'abase',\n",
       " 'abbey',\n",
       " 'abble',\n",
       " 'abbott',\n",
       " 'abc',\n",
       " 'abd',\n",
       " 'abdolutely',\n",
       " 'abdomen',\n",
       " 'abhor',\n",
       " 'abide',\n",
       " 'abilites',\n",
       " 'ability',\n",
       " 'abit',\n",
       " 'able',\n",
       " 'ablt',\n",
       " 'abmber',\n",
       " 'abnormal',\n",
       " 'abnormally',\n",
       " 'abnoxious',\n",
       " 'aboard',\n",
       " 'abodomen',\n",
       " 'abolutely',\n",
       " 'abominable',\n",
       " 'abosolutely',\n",
       " 'abot',\n",
       " 'abou',\n",
       " 'abound',\n",
       " 'abour',\n",
       " 'about',\n",
       " 'aboutthe',\n",
       " 'above',\n",
       " 'abrade',\n",
       " 'abraided',\n",
       " 'abrasion',\n",
       " 'abrasive',\n",
       " 'abreast',\n",
       " 'abrfrcrombie',\n",
       " 'abrin',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abrus',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'abslolutly',\n",
       " 'absoloute',\n",
       " 'absoloutly',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutelylove',\n",
       " 'absolutemente',\n",
       " 'absolutey',\n",
       " 'absolutley',\n",
       " 'absolutly',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbent',\n",
       " 'absorber',\n",
       " 'absorbs',\n",
       " 'absoulete',\n",
       " 'absouletly',\n",
       " 'absoultely',\n",
       " 'absoulute',\n",
       " 'absoulutely',\n",
       " 'absoulutey',\n",
       " 'abstract',\n",
       " 'absultely',\n",
       " 'absulutely',\n",
       " 'absulutlley',\n",
       " 'absurd',\n",
       " 'absurdly',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abut',\n",
       " 'abyss',\n",
       " 'ac',\n",
       " 'academy',\n",
       " 'acanthus',\n",
       " 'acc',\n",
       " 'accaccurate',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accenting',\n",
       " 'accentuate',\n",
       " 'accentuated',\n",
       " 'accentuates',\n",
       " 'accentuation',\n",
       " 'accentz',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptably',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'acces',\n",
       " 'accesaory',\n",
       " 'accesorie',\n",
       " 'accesories',\n",
       " 'accesory',\n",
       " 'access',\n",
       " 'accessary',\n",
       " 'accessdata',\n",
       " 'accessible',\n",
       " 'accessibly',\n",
       " 'accessorie',\n",
       " 'accessorize',\n",
       " 'accessorized',\n",
       " 'accessorizes',\n",
       " 'accessorizing',\n",
       " 'accessory',\n",
       " 'accet',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidently',\n",
       " 'acclaim',\n",
       " 'acclimate',\n",
       " 'accomadation',\n",
       " 'accommodate',\n",
       " 'accommodated',\n",
       " 'accommodates',\n",
       " 'accommodating',\n",
       " 'accommodation',\n",
       " 'accomodate',\n",
       " 'accomodating',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishing',\n",
       " 'accomplishment',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accounted',\n",
       " 'accouple',\n",
       " 'accoutrement',\n",
       " 'accrual',\n",
       " 'acctually',\n",
       " 'accually',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulates',\n",
       " 'accumulating',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accursed',\n",
       " 'accused',\n",
       " 'accustom',\n",
       " 'accustomed',\n",
       " 'ace',\n",
       " 'acent',\n",
       " 'aceptable',\n",
       " 'acessory',\n",
       " 'acfually',\n",
       " 'achain',\n",
       " 'ache',\n",
       " 'acheived',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achieves',\n",
       " 'achilles',\n",
       " 'aching',\n",
       " 'achually',\n",
       " 'acid',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledging',\n",
       " 'ackward',\n",
       " 'aclown',\n",
       " 'acorn',\n",
       " 'acorss',\n",
       " 'acouple',\n",
       " 'acquaintance',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquires',\n",
       " 'acquisition',\n",
       " 'acrlyic',\n",
       " 'acronym',\n",
       " 'across',\n",
       " 'acrylic',\n",
       " 'acryllic',\n",
       " 'act',\n",
       " 'actaul',\n",
       " 'actaully',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'activated',\n",
       " 'activates',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activist',\n",
       " 'activites',\n",
       " 'activity',\n",
       " 'activty',\n",
       " 'actor',\n",
       " 'actotal',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actuallly',\n",
       " 'actually',\n",
       " 'actuallyi',\n",
       " 'actualy',\n",
       " 'actully',\n",
       " 'actural',\n",
       " 'acual',\n",
       " 'acuality',\n",
       " 'acually',\n",
       " 'acura',\n",
       " 'acurate',\n",
       " 'acurately',\n",
       " 'acutal',\n",
       " 'acutally',\n",
       " 'acute',\n",
       " 'acutually',\n",
       " 'ad',\n",
       " 'adage',\n",
       " 'adamant',\n",
       " 'adaptable',\n",
       " 'adaptation',\n",
       " 'adapted',\n",
       " 'adapter',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addendum',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addiction',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additiong',\n",
       " 'addititon',\n",
       " 'addittion',\n",
       " 'addorable',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addressee',\n",
       " 'addressing',\n",
       " 'ade',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adhere',\n",
       " 'adhered',\n",
       " 'adheres',\n",
       " 'adhering',\n",
       " 'adhesion',\n",
       " 'adhesive',\n",
       " 'adid',\n",
       " 'adjacent',\n",
       " 'adjective',\n",
       " 'adjoining',\n",
       " 'adjument',\n",
       " 'adjust',\n",
       " 'adjustability',\n",
       " 'adjustable',\n",
       " 'adjustale',\n",
       " 'adjusted',\n",
       " 'adjuster',\n",
       " 'adjustible',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'adjusts',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admires',\n",
       " 'admiring',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admittely',\n",
       " 'admitting',\n",
       " 'admonition',\n",
       " 'adn',\n",
       " 'adolescent',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adoptive',\n",
       " 'adorable',\n",
       " 'adorableand',\n",
       " 'adorably',\n",
       " 'adorbs',\n",
       " 'adore',\n",
       " 'adoreable',\n",
       " 'adored',\n",
       " 'adoree',\n",
       " 'adores',\n",
       " 'adorn',\n",
       " 'adorned',\n",
       " 'adornment',\n",
       " 'adorns',\n",
       " 'adquisicion',\n",
       " 'adress',\n",
       " 'adter',\n",
       " 'adul',\n",
       " 'adularesence',\n",
       " 'adulating',\n",
       " 'adulescence',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advent',\n",
       " 'adventure',\n",
       " 'adventurer',\n",
       " 'adverse',\n",
       " 'advert',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertiser',\n",
       " 'advertises',\n",
       " 'advertising',\n",
       " 'advertisment',\n",
       " 'advertived',\n",
       " 'advertize',\n",
       " 'advertized',\n",
       " 'advertizing',\n",
       " 'adveryising',\n",
       " 'advice',\n",
       " 'adviced',\n",
       " 'advid',\n",
       " 'advirsement',\n",
       " 'advirtized',\n",
       " 'advisable',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advisement',\n",
       " 'adviser',\n",
       " 'advises',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advocate',\n",
       " 'ae',\n",
       " 'aee',\n",
       " 'aegean',\n",
       " 'aend',\n",
       " 'aer',\n",
       " 'aereola',\n",
       " 'aerobics',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'aew',\n",
       " 'af',\n",
       " 'afar',\n",
       " 'afarid',\n",
       " 'afbs',\n",
       " 'afd',\n",
       " 'afer',\n",
       " 'afew',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affence',\n",
       " 'affiliated',\n",
       " 'affiliation',\n",
       " 'affinity',\n",
       " 'affirm',\n",
       " 'affirmation',\n",
       " 'affirmative',\n",
       " 'affix',\n",
       " 'affixed',\n",
       " 'affixing',\n",
       " 'afforable',\n",
       " 'afforadable',\n",
       " 'afford',\n",
       " 'affordability',\n",
       " 'affordable',\n",
       " 'affords',\n",
       " 'affraid',\n",
       " 'afganistan',\n",
       " 'afghanisatn',\n",
       " 'afghanistan',\n",
       " 'afhganistan',\n",
       " 'aficionado',\n",
       " 'afixed',\n",
       " 'afixing',\n",
       " 'aflame',\n",
       " 'aforementioned',\n",
       " 'afraid',\n",
       " 'afrait',\n",
       " 'afriad',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afte',\n",
       " 'after',\n",
       " 'afterall',\n",
       " 'aftercare',\n",
       " 'afterhought',\n",
       " 'aftering',\n",
       " 'aftermarket',\n",
       " 'afternoon',\n",
       " 'afterthought',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'aftet',\n",
       " 'afteter',\n",
       " 'aftr',\n",
       " 'aftter',\n",
       " 'afuly',\n",
       " 'ag',\n",
       " 'agaim',\n",
       " 'again',\n",
       " 'againg',\n",
       " 'against',\n",
       " 'againt',\n",
       " 'agate',\n",
       " 'agc',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'ageless',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'ager',\n",
       " 'aggggggh',\n",
       " 'aggravated',\n",
       " 'aggravates',\n",
       " 'aggravating',\n",
       " 'aggravation',\n",
       " 'aggregate',\n",
       " 'aggressive',\n",
       " 'aggrevation',\n",
       " 'aggrivating',\n",
       " 'aghast',\n",
       " 'agian',\n",
       " 'agift',\n",
       " 'agile',\n",
       " 'agin',\n",
       " 'aging',\n",
       " 'agitate',\n",
       " 'agitated',\n",
       " 'agitates',\n",
       " 'aglow',\n",
       " 'agnew',\n",
       " 'ago',\n",
       " 'agonized',\n",
       " 'agonizing',\n",
       " 'agony',\n",
       " 'agrado',\n",
       " 'agravating',\n",
       " 'agre',\n",
       " 'agreat',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahas',\n",
       " 'ahd',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahh',\n",
       " 'ahhed',\n",
       " 'ahhh',\n",
       " 'ahipping',\n",
       " 'ahold',\n",
       " 'ahols',\n",
       " 'ahs',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aiding',\n",
       " 'ailiang',\n",
       " 'ailing',\n",
       " 'ailver',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'air',\n",
       " 'airborne',\n",
       " 'aircraft',\n",
       " 'aired',\n",
       " 'airflow',\n",
       " 'airing',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airsoft',\n",
       " 'airy',\n",
       " 'aisle',\n",
       " 'aiyaya',\n",
       " 'ajk',\n",
       " 'ajustable',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'aker',\n",
       " 'akin',\n",
       " 'akoya',\n",
       " 'akoyas',\n",
       " 'akron',\n",
       " 'akward',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alaska',\n",
       " 'alba',\n",
       " 'albalone',\n",
       " 'albanian',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'albolone',\n",
       " 'album',\n",
       " 'alchemist',\n",
       " 'alchemy',\n",
       " 'alco',\n",
       " 'alcohol',\n",
       " 'alcole',\n",
       " 'aldulte',\n",
       " 'alec',\n",
       " 'aleksia',\n",
       " 'alergic',\n",
       " 'alergies',\n",
       " 'alergy',\n",
       " 'alert',\n",
       " 'alerted',\n",
       " 'alerting',\n",
       " 'aleve',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandriat',\n",
       " 'alexandrite',\n",
       " 'alexis',\n",
       " 'alfit',\n",
       " 'algum',\n",
       " 'alhambra',\n",
       " 'alhough',\n",
       " 'ali',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'alienated',\n",
       " 'aliened',\n",
       " 'alienish',\n",
       " 'alight',\n",
       " 'aligment',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'alignment',\n",
       " 'aligns',\n",
       " 'alike',\n",
       " 'alikes',\n",
       " 'alil',\n",
       " 'alilang',\n",
       " 'alisa',\n",
       " 'alisha',\n",
       " 'alitte',\n",
       " 'alittle',\n",
       " 'alive',\n",
       " 'alkali',\n",
       " 'alkalinity',\n",
       " 'all',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allegic',\n",
       " 'allegies',\n",
       " 'allen',\n",
       " 'allergen',\n",
       " 'allergenic',\n",
       " 'allerges',\n",
       " 'allergic',\n",
       " 'allergist',\n",
       " 'allergy',\n",
       " 'alleviate',\n",
       " 'alleviates',\n",
       " 'alley',\n",
       " 'alleyway',\n",
       " 'alliance',\n",
       " 'allieygator',\n",
       " 'alligator',\n",
       " 'allison',\n",
       " 'allittle',\n",
       " 'alll',\n",
       " 'allllll',\n",
       " 'allot',\n",
       " 'allotted',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alloy',\n",
       " 'alloyed',\n",
       " 'allr',\n",
       " 'allready',\n",
       " 'allure',\n",
       " 'allurez',\n",
       " 'alluring',\n",
       " 'ally',\n",
       " 'almighty',\n",
       " 'almost',\n",
       " 'almostlookd',\n",
       " 'almosy',\n",
       " 'almsot',\n",
       " 'aloe',\n",
       " 'alog',\n",
       " 'aloha',\n",
       " 'alomost',\n",
       " 'alomst',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'aloof',\n",
       " 'alot',\n",
       " 'alothough',\n",
       " 'alotted',\n",
       " 'aloud',\n",
       " 'alov',\n",
       " 'alow',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'alphabetic',\n",
       " 'alread',\n",
       " 'already',\n",
       " 'alredy',\n",
       " 'alresady',\n",
       " 'alright',\n",
       " 'alseo',\n",
       " 'alsmost',\n",
       " 'also',\n",
       " 'alsodid',\n",
       " 'alsome',\n",
       " 'alt',\n",
       " 'altar',\n",
       " 'alter',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'althogh',\n",
       " 'although',\n",
       " 'althought',\n",
       " 'althouth',\n",
       " 'altitude',\n",
       " 'alto',\n",
       " 'altogether',\n",
       " 'alum',\n",
       " 'aluminium',\n",
       " 'aluminum',\n",
       " 'aluminumn',\n",
       " 'alwasys',\n",
       " 'alway',\n",
       " 'always',\n",
       " 'alzheimer',\n",
       " 'alzheimers',\n",
       " 'am',\n",
       " 'ama',\n",
       " 'amaaazing',\n",
       " 'amagin',\n",
       " 'amaizing',\n",
       " 'amall',\n",
       " 'amanda',\n",
       " 'amarth',\n",
       " 'amased',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amathyst',\n",
       " 'amathysts',\n",
       " 'amatrine',\n",
       " 'amature',\n",
       " 'amazan',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazin',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazom',\n",
       " 'amazon',\n",
       " 'amazone',\n",
       " 'amazonians',\n",
       " 'amazonions',\n",
       " 'amazonite',\n",
       " 'amazonprime',\n",
       " 'ambassador',\n",
       " 'amber',\n",
       " 'ambient',\n",
       " 'ambulance',\n",
       " 'amd',\n",
       " 'amehtyst',\n",
       " 'amen',\n",
       " 'amend',\n",
       " 'amended',\n",
       " 'amending',\n",
       " 'amendment',\n",
       " 'amends',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'amesthyst',\n",
       " 'amethist',\n",
       " 'amethyst',\n",
       " 'ameythest',\n",
       " 'ameythst',\n",
       " 'amidst',\n",
       " 'amithyst',\n",
       " 'aml',\n",
       " 'amles',\n",
       " 'ammonia',\n",
       " 'ammonite',\n",
       " 'ammount',\n",
       " 'amnd',\n",
       " 'amoazon',\n",
       " 'amodification',\n",
       " 'amon',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amont',\n",
       " 'amonzan',\n",
       " 'amorphous',\n",
       " 'amother',\n",
       " 'amount',\n",
       " 'amour',\n",
       " 'amout',\n",
       " 'amozom',\n",
       " 'amozon',\n",
       " 'amp',\n",
       " 'ampersand',\n",
       " 'ample',\n",
       " 'amplifies',\n",
       " 'amputation',\n",
       " 'amrita',\n",
       " 'amt',\n",
       " 'amtches',\n",
       " 'amu',\n",
       " 'amulent',\n",
       " 'amulet',\n",
       " 'amun',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'amy',\n",
       " 'amyethyst',\n",
       " 'amysthest',\n",
       " 'amythest',\n",
       " 'amzon',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'anal',\n",
       " 'analog',\n",
       " 'analogy',\n",
       " 'analysis',\n",
       " 'analyze',\n",
       " 'analyzed',\n",
       " 'anarchy',\n",
       " 'anastasia',\n",
       " 'anatometal',\n",
       " 'anatomically',\n",
       " 'anatomy',\n",
       " 'anaversary',\n",
       " 'anazing',\n",
       " 'ancestor',\n",
       " 'ancestry',\n",
       " 'anchor',\n",
       " 'anchored',\n",
       " 'ancient',\n",
       " 'ancklet',\n",
       " 'ancle',\n",
       " 'and',\n",
       " 'andbut',\n",
       " 'andcits',\n",
       " 'andd',\n",
       " 'andeearrings',\n",
       " 'anderson',\n",
       " 'andi',\n",
       " 'andit',\n",
       " 'andl',\n",
       " 'andnot',\n",
       " 'andodized',\n",
       " 'andpakaging',\n",
       " 'andree',\n",
       " 'andrew',\n",
       " 'ands',\n",
       " 'andthe',\n",
       " 'andthere',\n",
       " 'andthey',\n",
       " 'andv',\n",
       " 'andy',\n",
       " 'anemone',\n",
       " 'anew',\n",
       " 'anf',\n",
       " 'ang',\n",
       " 'angel',\n",
       " 'angeles',\n",
       " 'angeley',\n",
       " 'angelina',\n",
       " 'angeline',\n",
       " 'anger',\n",
       " 'angered',\n",
       " 'angie',\n",
       " 'angle',\n",
       " 'angled',\n",
       " 'anglican',\n",
       " 'angling',\n",
       " 'angry',\n",
       " 'angular',\n",
       " 'ani',\n",
       " 'animal',\n",
       " 'animate',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'anime',\n",
       " 'animee',\n",
       " 'animenext',\n",
       " 'aniticipated',\n",
       " 'aniversario',\n",
       " 'aniversary',\n",
       " 'aniversery',\n",
       " 'anjd',\n",
       " 'anjoying',\n",
       " 'anju',\n",
       " 'ankers',\n",
       " 'ankh',\n",
       " 'ankhs',\n",
       " 'ankle',\n",
       " 'anklet',\n",
       " 'anklete',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'annalyze',\n",
       " 'annd',\n",
       " 'anne',\n",
       " 'annenberg',\n",
       " 'annie',\n",
       " 'anniversary',\n",
       " 'anniversay',\n",
       " 'anniversery',\n",
       " 'anniversry',\n",
       " 'annivesary',\n",
       " 'annotate',\n",
       " 'announce',\n",
       " 'announcement',\n",
       " 'announcing',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoyingly',\n",
       " 'annoys',\n",
       " 'annual',\n",
       " 'annular',\n",
       " 'annv',\n",
       " 'anodization',\n",
       " 'anodized',\n",
       " 'anodizing',\n",
       " 'anomaly',\n",
       " 'anonymous',\n",
       " 'anorexic',\n",
       " 'anot',\n",
       " 'anothe',\n",
       " 'another',\n",
       " 'anotherone',\n",
       " 'anothervbroke',\n",
       " 'anoyed',\n",
       " 'anready',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'ant',\n",
       " 'antagonizing',\n",
       " 'antenna',\n",
       " 'anthony',\n",
       " 'anthother',\n",
       " 'anthropology',\n",
       " 'anti',\n",
       " 'antibiotic',\n",
       " 'antic',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'anticipation',\n",
       " 'anticpated',\n",
       " 'anties',\n",
       " 'antihistamine',\n",
       " 'antimony',\n",
       " 'antipater',\n",
       " 'antique',\n",
       " 'antiqued',\n",
       " 'antiqueish',\n",
       " 'antiquey',\n",
       " 'antiquing',\n",
       " 'antiquity',\n",
       " 'antiseptic',\n",
       " 'antisipated',\n",
       " 'antler',\n",
       " 'antone',\n",
       " 'antonio',\n",
       " 'antsy',\n",
       " 'anu',\n",
       " 'anubis',\n",
       " 'anuschka',\n",
       " 'anversarry',\n",
       " 'anvil',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anxiously',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyboy',\n",
       " 'anyhoooo',\n",
       " 'anyhow',\n",
       " 'anyhting',\n",
       " 'anymore',\n",
       " 'anyon',\n",
       " 'anyone',\n",
       " 'anyones',\n",
       " 'anyother',\n",
       " 'anyplace',\n",
       " 'anything',\n",
       " 'anythng',\n",
       " 'anytime',\n",
       " 'anyting',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywere',\n",
       " 'anywhere',\n",
       " 'anywho',\n",
       " 'anywhos',\n",
       " 'aol',\n",
       " 'aollars',\n",
       " 'aone',\n",
       " 'aout',\n",
       " 'aparently',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apatite',\n",
       " 'ape',\n",
       " 'apear',\n",
       " 'aperture',\n",
       " 'apiece',\n",
       " 'aplatinum',\n",
       " 'apo',\n",
       " 'apocalypse',\n",
       " 'apologetic',\n",
       " 'apologise',\n",
       " 'apologize',\n",
       " 'apologized',\n",
       " 'apologizing',\n",
       " 'apology',\n",
       " 'apon',\n",
       " 'apop',\n",
       " 'apostle',\n",
       " 'apostrophe',\n",
       " 'apothecary',\n",
       " 'app',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " ...]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred):\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "    accuracy_score = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=None)\n",
    "    recall = recall_score(y_true, y_pred, average=None)\n",
    "    f1 = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "    print(f\"{accuracy_score}\")\n",
    "\n",
    "    for rating_precision, rating_recall, rating_f1 in zip(precision, recall, f1):\n",
    "        print(f\"{rating_precision},{rating_recall},{rating_f1}\")\n",
    "\n",
    "    print(f\"{np.mean(precision)},{np.mean(recall)},{np.mean(f1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4153\n",
      "0.5993046501521078,0.34475,0.43770830026979846\n",
      "0.3385942760942761,0.40225,0.3676873857404022\n",
      "0.31728748806112705,0.41525,0.3597184623714131\n",
      "0.3599188915174045,0.26625,0.30607845954878576\n",
      "0.5453397853986955,0.648,0.5922540843139494\n",
      "0.43208901824472223,0.41530000000000006,0.4126893384488698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron()\n",
    "clf.fit(X_tfidf_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_tfidf_test)\n",
    "\n",
    "calc_metrics(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5071\n",
      "0.5611404435058078,0.66425,0.6083571837435604\n",
      "0.40142150803461063,0.32475,0.35903814262023215\n",
      "0.4189002486874827,0.379,0.39795248720304505\n",
      "0.4601041952289553,0.4195,0.43886491434549496\n",
      "0.628175519630485,0.748,0.682871162843775\n",
      "0.4939483830174683,0.5071,0.49741677815122154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(dual=True)\n",
    "clf.fit(X_tfidf_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_tfidf_test)\n",
    "\n",
    "calc_metrics(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500, multi_class='multinomial')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.527\n",
      "0.589334548769371,0.6465,0.6165951359084406\n",
      "0.42097902097902096,0.37625,0.39735973597359736\n",
      "0.4307848615697231,0.424,0.427365503338793\n",
      "0.48879287064542265,0.4525,0.46994677398416207\n",
      "0.6693199909028883,0.73575,0.7009646302250804\n",
      "0.5198422585732853,0.5269999999999999,0.5224463558860146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver=\"lbfgs\", max_iter=500, multi_class=\"multinomial\")\n",
    "\n",
    "clf.fit(X_tfidf_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_tfidf_test)\n",
    "\n",
    "calc_metrics(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5017\n",
      "0.5915983097191151,0.595,0.5932942789480244\n",
      "0.4109306522299562,0.3985,0.4046198756187334\n",
      "0.40478446234012316,0.42725,0.4157139382145463\n",
      "0.4404077365394668,0.42125,0.4306158957321748\n",
      "0.6582716049382716,0.6665,0.662360248447205\n",
      "0.5011985531533866,0.5017,0.5013208473921368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_tfidf_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_tfidf_test)\n",
    "\n",
    "calc_metrics(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('csci544-assignment-01')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "94e57c780941729b66a50fa43f276db225d69de54eca80cd479b96d3e11990ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
