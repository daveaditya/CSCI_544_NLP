{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import json\n",
    "from typing import List, Dict, Tuple, Set, Any, Callable, Optional\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "### Constants                                      ###\n",
    "######################################################\n",
    "# Base Paths\n",
    "INPUT_PATH = \"./data\"\n",
    "MODEL_PATH = \"./model\"\n",
    "OUTPUT_PATH = \"./output\"\n",
    "\n",
    "# Model File names\n",
    "VANILLA_MODEL_FILENAME = \"vanillamodel.txt\"\n",
    "AVERAGED_MODEL_FILENAME = \"averagedmodel.txt\"\n",
    "OUTPUT_FILENAME = \"percepoutput.txt\"\n",
    "\n",
    "# Class Identifiers\n",
    "TRUTHFUL = \"True\"\n",
    "DECEPTIVE = \"Fake\"\n",
    "POSITIVE = \"Pos\"\n",
    "NEGATIVE = \"Neg\"\n",
    "\n",
    "TYPE_VANILLA_PERPCETRON = \"vanilla_perceptron\"\n",
    "TYPE_AVERAGED_PERCEPTRON = \"averaged_perceptron\"\n",
    "\n",
    "# File paths\n",
    "TRAIN_FILE_PATH = f\"{INPUT_PATH}/train-labeled.txt\"\n",
    "CLEANED_DATA_FILE_PATH = f\"{INPUT_PATH}/cleaned-data.txt\"\n",
    "PREPROCESSED_DATA_FILE_PATH = f\"{INPUT_PATH}/preprocessed-data.txt\"\n",
    "\n",
    "VANILLA_MODEL_FILE_PATH = f\"{MODEL_PATH}/{VANILLA_MODEL_FILENAME}\"\n",
    "AVERAGED_MODEL_FILE_PATH = f\"{MODEL_PATH}/{AVERAGED_MODEL_FILENAME}\"\n",
    "\n",
    "OUTPUT_FILE_PATH = f\"{OUTPUT_PATH}/{OUTPUT_FILENAME}\"\n",
    "\n",
    "DEV_DATA_FILE_PATH = f\"{INPUT_PATH}/dev-text.txt\"\n",
    "DEV_KEY_FILE_PATH = f\"{INPUT_PATH}/dev-key.txt\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "DATA_ID_COL = 0\n",
    "TRAIN_DATA_COL = 3\n",
    "DEV_DATA_COL = 1\n",
    "SENTIMENT_TARGET_COL = 2\n",
    "TRUTHFULNESS_TARGET_COL = 1\n",
    "\n",
    "VAL_SIZE = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_line = \"07Zfn0z If you're looking for an elegant hotel in downtown Chicago, you have to stay here. The Ambassador East Hotel has very comfortable and beautiful large rooms and is like a home away from home. The perfect place for a business person, and if you have a small pet you can bring them too! I would give this place four stars and would definitely stay here again.\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_regex = re.compile(r\"(\\w*) (.*)\\n?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('07Zfn0z',\n",
       " \"If you're looking for an elegant hotel in downtown Chicago, you have to stay here. The Ambassador East Hotel has very comfortable and beautiful large rooms and is like a home away from home. The perfect place for a business person, and if you have a small pet you can bring them too! I would give this place four stars and would definitely stay here again.\")"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(dev_regex, dev_line).groups()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"07Zfn0z Fake Pos If you're looking for an elegant hotel in downtown Chicago, you have to stay here. The Ambassador East Hotel has very comfortable and beautiful large rooms and is like a home away from home. The perfect place for a business person, and if you have a small pet you can bring them too! I would give this place four stars and would definitely stay here again.\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_regex = re.compile(r\"(\\w*) (\\w*) (\\w*) (.*)\\n?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('07Zfn0z',\n",
       " 'Fake',\n",
       " 'Pos',\n",
       " \"If you're looking for an elegant hotel in downtown Chicago, you have to stay here. The Ambassador East Hotel has very comfortable and beautiful large rooms and is like a home away from home. The perfect place for a business person, and if you have a small pet you can bring them too! I would give this place four stars and would definitely stay here again.\")"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(input_regex, line).groups()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('07Zfn0z',\n",
       "  'Fake',\n",
       "  'Pos',\n",
       "  \"If you're looking for an elegant hotel in downtown Chicago, you have to stay here. The Ambassador East Hotel has very comfortable and beautiful large rooms and is like a home away from home. The perfect place for a business person, and if you have a small pet you can bring them too! I would give this place four stars and would definitely stay here again.\")]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "data.append(re.match(input_regex, line).groups())\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fake'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data)[0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_data(input_file_path: str, type: str = \"TRAIN\") -> npt.NDArray:\n",
    "    input_data = list()\n",
    "    regex = r\"(\\w*) (\\w*) (\\w*) (.*)\\n?\"\n",
    "    if type == \"DEV\":\n",
    "        regex = r\"(\\w*) (.*)\\n?\"\n",
    "    elif type == \"KEY\":\n",
    "        regex = r\"(\\w*) (\\w*) (\\w*)\\n?\"\n",
    "    input_regex = re.compile(regex)\n",
    "    with open(input_file_path, mode=\"r\") as input_file:\n",
    "        for line in input_file:\n",
    "            input_data.append(re.match(input_regex, line).groups())\n",
    "    return np.array(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Data\n",
    "def store_data(date_file_path: str, data: npt.NDArray) -> None:\n",
    "    with open(date_file_path, mode=\"w\") as data_file:\n",
    "        for row in data:\n",
    "            data_file.write(f\"{row[0]} {row[1]} {row[2]} {row[3]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Model\n",
    "def store_model(model_file_path: str, model_data: Any) -> None:\n",
    "    with open(model_file_path, mode=\"w\") as model_file:\n",
    "        json.dump(model_data, model_file, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "def load_model(model_file_path: str) -> npt.NDArray:\n",
    "    with open(model_file_path, mode=\"r\") as model_file:\n",
    "        model_data = json.load(model_file)\n",
    "\n",
    "    return (model_data[\"tf_idf_model\"], model_data[\"sentiment_classifier\"], model_data[\"truthfulness_classifier\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Predictions\n",
    "def store_predictions(output_file_path: str, predictions: List[Tuple[str, str, str]]) -> None:\n",
    "    with open(output_file_path, mode=\"w\") as output_file:\n",
    "        for prediction in predictions:\n",
    "            output_file.write(f\"{prediction[0]} {prediction[1]} {prediction[2]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_score(y_true: npt.NDArray, y_pred: npt.NDArray):\n",
    "    return (y_true == y_pred).sum() / y_true.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_score(y_true: npt.NDArray, y_pred: npt.NDArray, average: str = \"macro\"):\n",
    "    def calculate_f1(y_true, y_pred, label):\n",
    "        tp = np.sum((y_true == label) & (y_pred == label))\n",
    "        fp = np.sum((y_true != label) & (y_pred == label))\n",
    "        fn = np.sum((y_pred != label) & (y_true == label))\n",
    "\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "\n",
    "    def macro_f1(y_true, y_pred):\n",
    "        return np.mean([calculate_f1(y_true, y_pred, label) for label in np.unique(y_true)])\n",
    "\n",
    "    def micro_f1(y_true, y_pred):\n",
    "        return {label: calculate_f1(y_true, y_pred, label) for label in np.unique(y_true)}\n",
    "\n",
    "    if average == \"macro\":\n",
    "        return macro_f1(y_true, y_pred)\n",
    "    elif average == \"micro\":\n",
    "        return micro_f1(y_true, y_pred)\n",
    "    else:\n",
    "        return {\"micro\": micro_f1(y_true, y_pred), \"macro\": macro_f1(y_true, y_pred)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Scores\n",
    "def calculate_scores(y_true, y_pred, title: str):\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    print(f\"------------------------ {title} ------------------------\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler\n",
    "def learning_rate_scheduler(learning_rate: float, epoch: int, decay: float = 1e-2):\n",
    "    return learning_rate * 1 / (1 + decay * epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(TRAIN_FILE_PATH, type=\"TRAIN\")\n",
    "\n",
    "dev_raw_data = load_data(DEV_DATA_FILE_PATH, type=\"DEV\")\n",
    "dev_key_data = load_data(DEV_KEY_FILE_PATH, type=\"KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all reviews to lower case (optional according to study)\n",
    "def to_lower(data: npt.NDArray):\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = result[i].lower()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_encodings(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"&#\\d+;\", \" \", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"<[a-zA-Z]+\\s?/?>\", \"\", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"https?://([\\w\\-\\._]+){2,}/[\\w\\-\\.\\-/=\\+_\\?]+\", \"\", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_and_url(data):\n",
    "    \"\"\"Function to remove\n",
    "             1. HTML encodings\n",
    "             2. HTML tags (both closed and open)\n",
    "             3. URLs\n",
    "\n",
    "    Args:\n",
    "        data (npt.NDArray): A Numpy Array of type string\n",
    "\n",
    "    Returns:\n",
    "        _type_: npt.NDArray\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        # Remove HTML encodings\n",
    "        result[i] = re.sub(r\"&#\\d+;\", \"\", result[i])\n",
    "\n",
    "        # Remove HTML tags (both open and closed)\n",
    "        result[i] = re.sub(r\"<[a-zA-Z]+\\s?/?>\", \"\", result[i])\n",
    "\n",
    "        # Remove URLs\n",
    "        result[i] = re.sub(r\"https?://([\\w\\-\\._]+){2,}/[\\w\\-\\.\\-/=\\+_\\?]+\", \"\", result[i])\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_digits_with_tag(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"\\d+\", \" NUM \", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-alphabetical characters\n",
    "def remove_non_alpha_characters(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"_+|\\\\|[^a-zA-Z0-9\\s]\", \" \", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "def remove_extra_spaces(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"^\\s*|\\s\\s*\", \" \", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding contractions\n",
    "def fix_contractions(data: npt.NDArray):\n",
    "    from contractions import fix\n",
    "\n",
    "    def contraction_fixer(txt: str):\n",
    "        return \" \".join([fix(word) for word in txt.split()])\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = contraction_fixer(result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: to_lower\n",
      "Ended: to_lower\n",
      "Starting: remove_html_encodings\n",
      "Ended: remove_html_encodings\n",
      "Starting: remove_html_tags\n",
      "Ended: remove_html_tags\n",
      "Starting: remove_url\n",
      "Ended: remove_url\n",
      "Starting: fix_contractions\n",
      "Ended: fix_contractions\n",
      "Starting: remove_non_alpha_characters\n",
      "Ended: remove_non_alpha_characters\n",
      "Starting: remove_extra_spaces\n",
      "Ended: remove_extra_spaces\n"
     ]
    }
   ],
   "source": [
    "# A dictionary containing the columns and a list of functions to perform on it in order\n",
    "data_cleaning_pipeline = {\n",
    "    TRAIN_DATA_COL: [\n",
    "        to_lower,\n",
    "        remove_html_encodings,\n",
    "        remove_html_tags,\n",
    "        remove_url,\n",
    "        fix_contractions,\n",
    "        remove_non_alpha_characters,\n",
    "        remove_extra_spaces,\n",
    "    ]\n",
    "}\n",
    "\n",
    "cleaned_data = data.copy()\n",
    "\n",
    "# Process all the cleaning instructions\n",
    "for col, pipeline in data_cleaning_pipeline.items():\n",
    "    # Get the column to perform cleaning on\n",
    "    temp_data = cleaned_data[:, col].copy()\n",
    "\n",
    "    # Perform all the cleaning functions sequencially\n",
    "    for func in pipeline:\n",
    "        print(f\"Starting: {func.__name__}\")\n",
    "        temp_data = func(temp_data)\n",
    "        print(f\"Ended: {func.__name__}\")\n",
    "\n",
    "    # Replace the old column with cleaned one.\n",
    "    cleaned_data[:, col] = temp_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data(CLEANED_DATA_FILE_PATH, cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: to_lower\n",
      "Ended: to_lower\n",
      "Starting: remove_html_encodings\n",
      "Ended: remove_html_encodings\n",
      "Starting: remove_html_tags\n",
      "Ended: remove_html_tags\n",
      "Starting: remove_url\n",
      "Ended: remove_url\n",
      "Starting: fix_contractions\n",
      "Ended: fix_contractions\n",
      "Starting: remove_non_alpha_characters\n",
      "Ended: remove_non_alpha_characters\n",
      "Starting: remove_extra_spaces\n",
      "Ended: remove_extra_spaces\n"
     ]
    }
   ],
   "source": [
    "# A dictionary containing the columns and a list of functions to perform on it in order\n",
    "data_cleaning_pipeline = {\n",
    "    DEV_DATA_COL: [\n",
    "        to_lower,\n",
    "        remove_html_encodings,\n",
    "        remove_html_tags,\n",
    "        remove_url,\n",
    "        fix_contractions,\n",
    "        remove_non_alpha_characters,\n",
    "        remove_extra_spaces,\n",
    "    ]\n",
    "}\n",
    "\n",
    "dev_cleaned_data = dev_raw_data.copy()\n",
    "\n",
    "# Process all the cleaning instructions\n",
    "for col, pipeline in data_cleaning_pipeline.items():\n",
    "    # Get the column to perform cleaning on\n",
    "    temp_data = dev_cleaned_data[:, col].copy()\n",
    "\n",
    "    # Perform all the cleaning functions sequencially\n",
    "    for func in pipeline:\n",
    "        print(f\"Starting: {func.__name__}\")\n",
    "        temp_data = func(temp_data)\n",
    "        print(f\"Ended: {func.__name__}\")\n",
    "\n",
    "    # Replace the old column with cleaned one.\n",
    "    dev_cleaned_data[:, col] = temp_data.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not Applicable since everything has to be implemented from scratch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIdf:\n",
    "    # Implement low frequency terms and other techniques\n",
    "    def __init__(self) -> None:\n",
    "        self.n_docs: int = None\n",
    "        self.vocab: List = list()\n",
    "        self.vocab_size: int = None\n",
    "        self.vocab_index: Dict[str, int] = dict()\n",
    "        self.word_document_count: Dict[str, int] = dict()\n",
    "\n",
    "    def __create_vocab__(self, documents: npt.NDArray) -> Set:\n",
    "        vocab = set()\n",
    "\n",
    "        for document in documents:\n",
    "            for word in document:\n",
    "                vocab.add(word)\n",
    "\n",
    "        return list(vocab)\n",
    "\n",
    "    def __get_word_document_count__(self, documents: npt.NDArray):\n",
    "        word_document_count = dict()\n",
    "\n",
    "        for document in documents:\n",
    "            for word in document:\n",
    "                if word in self.vocab:\n",
    "                    if word not in word_document_count:\n",
    "                        word_document_count[word] = 1\n",
    "                    else:\n",
    "                        word_document_count[word] += 1\n",
    "\n",
    "        return word_document_count\n",
    "\n",
    "    def __term_frequency__(self, word: str, document: npt.NDArray):\n",
    "        word_occurences = (document == word).sum()\n",
    "        return word_occurences / self.n_docs\n",
    "\n",
    "    def __inverse_document_frequency__(self, word: str):\n",
    "        word_occurrences = 1\n",
    "\n",
    "        if word in self.word_document_count:\n",
    "            word_occurrences += self.word_document_count[word]\n",
    "\n",
    "        return np.log(self.n_docs / word_occurrences)\n",
    "\n",
    "    def __tf_idf__(self, document: npt.NDArray):\n",
    "        tf_idf_vector = np.zeros(shape=(self.vocab_size,))\n",
    "        for word in document:\n",
    "            # ignore word not in vocab\n",
    "            if word in self.vocab:\n",
    "                tf = self.__term_frequency__(word, document)\n",
    "                idf = self.__inverse_document_frequency__(word)\n",
    "\n",
    "                tf_idf_vector[self.vocab_index[word]] = tf * idf\n",
    "        return tf_idf_vector\n",
    "\n",
    "    def fit(self, documents: npt.NDArray):\n",
    "        self.n_docs = documents.shape[0]\n",
    "        self.vocab = self.__create_vocab__(documents)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.vocab_index = {word: idx for idx, word in enumerate(self.vocab)}\n",
    "        self.word_document_count = self.__get_word_document_count__(documents)\n",
    "\n",
    "    def transform(self, documents: npt.NDArray):\n",
    "        tf_idf_vectors = list()\n",
    "        for document in documents:\n",
    "            tf_idf_vectors.append(self.__tf_idf__(document))\n",
    "        return np.array(tf_idf_vectors)\n",
    "\n",
    "    def export(self):\n",
    "        return {\n",
    "            \"n_docs\": self.n_docs,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"vocab\": self.vocab,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"vocab_index\": self.vocab_index,\n",
    "            \"word_document_count\": self.word_document_count,\n",
    "        }\n",
    "\n",
    "    def load(self, tf_idf_model_data):\n",
    "        self.n_docs = tf_idf_model_data[\"n_docs\"]\n",
    "        self.vocab_size = tf_idf_model_data[\"vocab_size\"]\n",
    "        self.vocab = tf_idf_model_data[\"vocab\"]\n",
    "        self.vocab_size = tf_idf_model_data[\"vocab_size\"]\n",
    "        self.vocab_index = tf_idf_model_data[\"vocab_index\"]\n",
    "        self.word_document_count = tf_idf_model_data[\"word_document_count\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data: npt.NDArray):\n",
    "    tokenized_documents = list()\n",
    "    for document in data:\n",
    "        tokenized_documents.append(np.array(document.split()))\n",
    "    return np.array(tokenized_documents, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = load_data(CLEANED_DATA_FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = tokenize(final_data[:, TRAIN_DATA_COL])\n",
    "dev_tokenized = tokenize(dev_cleaned_data[:, DEV_DATA_COL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model = TfIdf()\n",
    "tf_idf_model.fit(train_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = tf_idf_model.transform(train_tokenized)\n",
    "X_dev = tf_idf_model.transform(dev_tokenized)\n",
    "\n",
    "tf_idf_model_data = tf_idf_model.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_sentiment = np.where(final_data[:, SENTIMENT_TARGET_COL] == POSITIVE, 1, -1)\n",
    "y_all_truthfulness = np.where(final_data[:, TRUTHFULNESS_TARGET_COL] == TRUTHFUL, 1, -1)\n",
    "\n",
    "y_dev_sentiment = np.where(dev_key_data[:, SENTIMENT_TARGET_COL] == POSITIVE, 1, -1)\n",
    "y_dev_truthfulness = np.where(dev_key_data[:, TRUTHFULNESS_TARGET_COL] == TRUTHFUL, 1, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(\n",
    "    X: npt.NDArray,\n",
    "    y_sentiment: npt.NDArray,\n",
    "    y_truthfulness: npt.NDArray,\n",
    "    test_size: float = 0.2,\n",
    "    rng=np.random.default_rng(seed=RANDOM_SEED),\n",
    "):\n",
    "    n_max = X.shape[0]\n",
    "    sample = int((1 - test_size) * n_max)\n",
    "\n",
    "    # Shuffle the data\n",
    "    all_idx = np.arange(n_max)\n",
    "    rng.shuffle(all_idx)\n",
    "\n",
    "    train_idx, test_idx = all_idx[:sample], all_idx[sample:]\n",
    "\n",
    "    X_train, X_test, y_train_sentiment, y_test_sentiment, y_train_truthfulness, y_test_truthfulness = (\n",
    "        X[train_idx],\n",
    "        X[test_idx],\n",
    "        y_sentiment[train_idx],\n",
    "        y_sentiment[test_idx],\n",
    "        y_truthfulness[train_idx],\n",
    "        y_truthfulness[test_idx],\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train_sentiment, y_test_sentiment, y_train_truthfulness, y_test_truthfulness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train_sentiment, y_val_sentiment, y_train_truthfulness, y_val_truthfulness = train_test_split(\n",
    "    X_all, y_all_sentiment, y_all_truthfulness, VAL_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaPerceptron:\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_iterations: int = 1000,\n",
    "        learning_rate: float = 1e-2,\n",
    "        shuffle: bool = True,\n",
    "        class_weights = None,\n",
    "        lr_scheduler_func = None,\n",
    "        score_func = calculate_f1_score,\n",
    "        rng=np.random.default_rng(seed=RANDOM_SEED),\n",
    "        debug: bool = False,\n",
    "        debug_at: int = 50,\n",
    "    ) -> None:\n",
    "        self.type = TYPE_VANILLA_PERPCETRON\n",
    "        self.max_iterations = max_iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.shuffle = shuffle\n",
    "        self.class_weights = class_weights\n",
    "        self.learning_rate_scheduler = lr_scheduler_func\n",
    "        self.calculate_score = score_func\n",
    "        self.rng = rng\n",
    "        self.debug = debug\n",
    "        self.debug_at = debug_at\n",
    "\n",
    "        self.best_epoch = 0\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_val = None,\n",
    "        y_val = None,\n",
    "    ):\n",
    "        n_epoch = 0\n",
    "\n",
    "        self.weights = self.rng.random(size=(X_train.shape[-1],))\n",
    "        self.bias: float = 0.0\n",
    "\n",
    "        learning_rate = self.learning_rate\n",
    "\n",
    "        best_epoch = 0\n",
    "        best_val_score = -1\n",
    "        best_weights = self.weights.copy()\n",
    "        best_bias = self.bias\n",
    "\n",
    "        for n_epoch in range(1, self.max_iterations + 1):\n",
    "\n",
    "            if self.shuffle:\n",
    "                idxs = np.arange(X_train.shape[0])\n",
    "                self.rng.shuffle(idxs)\n",
    "\n",
    "                X_train = X_train[idxs]\n",
    "                y_train = y_train[idxs]\n",
    "\n",
    "            for x, y_true in zip(X_train, y_train):\n",
    "\n",
    "                if y_true * self._activation(x) <= 0:\n",
    "                    if self.class_weights is None:\n",
    "                        self.weights = self.weights + y_true * x * self.learning_rate\n",
    "                    else:\n",
    "                        self.weights = self.weights + y_true * x * self.learning_rate * self.class_weights[y_true]\n",
    "                    self.bias = self.bias + y_true\n",
    "\n",
    "            if X_val is not None and y_val is not None:\n",
    "                train_score = self.calculate_score(y_train, self.predict(X_train))\n",
    "                val_score = self.calculate_score(y_val, self.predict(X_val))\n",
    "\n",
    "                if val_score > best_val_score:\n",
    "                    best_val_score = val_score\n",
    "\n",
    "                    # Record the current best wegiths and bias\n",
    "                    best_epoch = n_epoch\n",
    "                    best_weights = self.weights\n",
    "                    best_bias = self.bias\n",
    "\n",
    "                if self.debug and (n_epoch == self.max_iterations or n_epoch % self.debug_at == 0):\n",
    "                    print(\"Epoch #\", n_epoch, \" Train: \", train_score, \" Val: \", val_score)\n",
    "            else:\n",
    "                best_epoch = n_epoch\n",
    "                best_weights = self.weights\n",
    "                best_bias = self.bias\n",
    "\n",
    "            # Update learning rate\n",
    "            if self.learning_rate_scheduler:\n",
    "                learning_rate = self.learning_rate_scheduler(learning_rate, n_epoch)\n",
    "\n",
    "        # Set the best weights and bias found if Val provided\n",
    "        self.best_epoch = best_epoch\n",
    "        self.weights = best_weights\n",
    "        self.bias = best_bias\n",
    "\n",
    "    def _activation(self, x):\n",
    "        return np.dot(self.weights, x) + self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = list()\n",
    "        for x in X:\n",
    "            pred = np.sign(self._activation(x))\n",
    "            predictions.append(pred)\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def export(\n",
    "        self,\n",
    "    ):\n",
    "        return {\n",
    "            \"type\": self.type,\n",
    "            \"max_iterations\": self.max_iterations,\n",
    "            \"weights\": self.weights.tolist(),\n",
    "            \"bias\": float(self.bias),\n",
    "            \"best_epoch\": self.best_epoch,\n",
    "        }\n",
    "\n",
    "    def load(self, model_data):\n",
    "        self.type = model_data[\"type\"]\n",
    "        self.max_iterations = (model_data[\"max_iterations\"],)\n",
    "        self.weights = np.array(model_data[\"weights\"])\n",
    "        self.bias = model_data[\"bias\"]\n",
    "        self.best_epoch = model_data[\"best_epoch\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/gcxbjppx70qfkdwy32kg04dh0000gn/T/ipykernel_38168/2355303260.py:7: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp / (tp + fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 50  Train:  0.5617643363836851  Val:  0.5095361567271679\n",
      "Epoch # 100  Train:  0.5708063957080639  Val:  0.5186511036742499\n",
      "Epoch # 150  Train:  0.6962993540010654  Val:  0.5826587515740241\n",
      "Epoch # 200  Train:  0.5134502923976608  Val:  0.49220785372554593\n",
      "Epoch # 250  Train:  0.885136077085284  Val:  0.7780588307290605\n",
      "Epoch # 300  Train:  0.9193505273528491  Val:  0.8026668284151679\n",
      "Epoch # 350  Train:  0.9383537714235337  Val:  0.8130238555770471\n",
      "Epoch # 400  Train:  0.9614181019922032  Val:  0.8266730861819933\n",
      "Epoch # 450  Train:  0.9645487129358097  Val:  0.8232772037633922\n",
      "Epoch # 500  Train:  0.9729024357409926  Val:  0.8164528301886793\n",
      "Epoch # 550  Train:  0.9718559135698579  Val:  0.81259340037966\n",
      "Epoch # 600  Train:  0.9812447902195054  Val:  0.802186888801062\n",
      "Epoch # 650  Train:  0.960360924216346  Val:  0.7951864758053866\n",
      "Epoch # 700  Train:  0.9540787705634483  Val:  0.7951864758053866\n",
      "Epoch # 750  Train:  0.9895826099034655  Val:  0.7986931287795771\n",
      "Epoch # 800  Train:  0.9927081355288501  Val:  0.802186888801062\n",
      "Epoch # 850  Train:  0.9927081355288501  Val:  0.805668016194332\n",
      "Epoch # 900  Train:  0.9937498914911718  Val:  0.802186888801062\n",
      "Epoch # 950  Train:  0.9947916158035397  Val:  0.802186888801062\n",
      "Epoch # 1000  Train:  0.9947916158035397  Val:  0.802186888801062\n",
      "Epoch # 1050  Train:  0.9958333152487642  Val:  0.81259340037966\n",
      "Epoch # 1100  Train:  0.9968749694821238  Val:  0.8300584174190123\n",
      "Epoch # 1150  Train:  0.9968749694821238  Val:  0.8600898286895345\n",
      "Epoch # 1200  Train:  0.9958332609941145  Val:  0.9088184721198724\n",
      "Epoch # 1250  Train:  0.9916660879227723  Val:  0.9280681007437523\n",
      "Epoch # 1300  Train:  0.9895822029300054  Val:  0.9406197810354425\n",
      "Epoch # 1350  Train:  0.988540162065549  Val:  0.9468495666871843\n",
      "Epoch # 1400  Train:  0.986455849651249  Val:  0.9437148217636022\n",
      "Epoch # 1450  Train:  0.9874980465697765  Val:  0.9374389051808407\n",
      "Epoch # 1500  Train:  0.99479152537775  Val:  0.9374389051808407\n",
      "Epoch # 1550  Train:  0.988540162065549  Val:  0.9311181558451723\n",
      "Epoch # 1600  Train:  0.9958332609941145  Val:  0.9184921039225675\n",
      "Epoch # 1650  Train:  0.9968749694821238  Val:  0.9184921039225675\n",
      "Epoch # 1700  Train:  0.9968749694821238  Val:  0.915326492811572\n",
      "Epoch # 1750  Train:  0.9895822029300054  Val:  0.9120844617135682\n",
      "Epoch # 1800  Train:  0.9958332609941145  Val:  0.9057196731615336\n",
      "Epoch # 1850  Train:  0.9979166576243821  Val:  0.9057196731615336\n",
      "Epoch # 1900  Train:  0.9958332609941145  Val:  0.9025300908867601\n",
      "Epoch # 1950  Train:  0.99479152537775  Val:  0.8929302472051646\n",
      "Epoch # 2000  Train:  0.9958332609941145  Val:  0.8929302472051646\n"
     ]
    }
   ],
   "source": [
    "vanilla_perceptron_sentiment = VanillaPerceptron(\n",
    "    max_iterations=2000,\n",
    "    learning_rate=0.815,\n",
    "    shuffle=True,\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    "    rng=rng,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    ")\n",
    "\n",
    "vanilla_perceptron_sentiment.fit(X_all, y_all_sentiment, X_dev, y_dev_sentiment)\n",
    "\n",
    "# Export the model\n",
    "vanilla_perceptron_sentiment_data = vanilla_perceptron_sentiment.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1327"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_perceptron_sentiment_data[\"best_epoch\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Whole ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.97      0.99       480\n",
      "           1       0.98      1.00      0.99       480\n",
      "\n",
      "    accuracy                           0.99       960\n",
      "   macro avg       0.99      0.99      0.99       960\n",
      "weighted avg       0.99      0.99      0.99       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.93      0.95       160\n",
      "           1       0.93      0.97      0.95       160\n",
      "\n",
      "    accuracy                           0.95       320\n",
      "   macro avg       0.95      0.95      0.95       320\n",
      "weighted avg       0.95      0.95      0.95       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Classify and predict with the best model\n",
    "y_dev_sentiment_pred = vanilla_perceptron_sentiment.predict(X_dev)\n",
    "\n",
    "calculate_scores(y_all_sentiment, vanilla_perceptron_sentiment.predict(X_all), title=\"Whole\")\n",
    "calculate_scores(y_dev_sentiment, y_dev_sentiment_pred, title=\"Dev\")\n",
    "\n",
    "del vanilla_perceptron_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Whole ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.97      0.99       480\n",
      "           1       0.98      1.00      0.99       480\n",
      "\n",
      "    accuracy                           0.99       960\n",
      "   macro avg       0.99      0.99      0.99       960\n",
      "weighted avg       0.99      0.99      0.99       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.93      0.95       160\n",
      "           1       0.93      0.97      0.95       160\n",
      "\n",
      "    accuracy                           0.95       320\n",
      "   macro avg       0.95      0.95      0.95       320\n",
      "weighted avg       0.95      0.95      0.95       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vanilla_perceptron_sentiment = VanillaPerceptron()\n",
    "vanilla_perceptron_sentiment.load(vanilla_perceptron_sentiment_data)\n",
    "\n",
    "y_dev_sentiment_pred = vanilla_perceptron_sentiment.predict(X_dev)\n",
    "\n",
    "calculate_scores(y_all_sentiment, vanilla_perceptron_sentiment.predict(X_all), title=\"Whole\")\n",
    "calculate_scores(y_dev_sentiment, y_dev_sentiment_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truthfulness Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 50  Train:  0.7544590885578256  Val:  0.6302335878357217\n",
      "Epoch # 100  Train:  0.9054555641151341  Val:  0.6794297223481773\n",
      "Epoch # 150  Train:  0.3627391753647064  Val:  0.35383467736749363\n",
      "Epoch # 200  Train:  0.9572210647129213  Val:  0.6620836044415527\n",
      "Epoch # 250  Train:  0.9979166576243821  Val:  0.6620836044415527\n",
      "Epoch # 300  Train:  0.9916660879227723  Val:  0.8184947582537945\n",
      "Epoch # 350  Train:  0.9011354523184525  Val:  0.68101802757158\n",
      "Epoch # 400  Train:  0.9739406607128315  Val:  0.6729688298415942\n",
      "Epoch # 450  Train:  1.0  Val:  0.6702047408068509\n",
      "Epoch # 500  Train:  1.0  Val:  0.6702047408068509\n",
      "Epoch # 550  Train:  1.0  Val:  0.6702047408068509\n",
      "Epoch # 600  Train:  1.0  Val:  0.6702047408068509\n",
      "Epoch # 650  Train:  1.0  Val:  0.6702047408068509\n",
      "Epoch # 700  Train:  1.0  Val:  0.6702047408068509\n",
      "Epoch # 750  Train:  1.0  Val:  0.6702047408068509\n",
      "Epoch # 800  Train:  1.0  Val:  0.6702047408068509\n",
      "Epoch # 850  Train:  1.0  Val:  0.6702047408068509\n",
      "Epoch # 900  Train:  1.0  Val:  0.6702047408068509\n"
     ]
    }
   ],
   "source": [
    "vanilla_perceptron_truthfulness = VanillaPerceptron(\n",
    "    max_iterations=900,\n",
    "    learning_rate=3.2,\n",
    "    shuffle=True,\n",
    "    class_weights={-1: 1.04275, 1: 1.0},\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    "    rng=np.random.default_rng(seed=RANDOM_SEED),\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    ")\n",
    "\n",
    "vanilla_perceptron_truthfulness.fit(X_all, y_all_truthfulness, X_dev, y_dev_truthfulness)\n",
    "\n",
    "# Export the model\n",
    "vanilla_perceptron_truthfulness_data = vanilla_perceptron_truthfulness.export()\n",
    "\n",
    "del vanilla_perceptron_truthfulness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_perceptron_truthfulness_data[\"best_epoch\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Whole ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.97      0.99       480\n",
      "           1       0.98      1.00      0.99       480\n",
      "\n",
      "    accuracy                           0.99       960\n",
      "   macro avg       0.99      0.99      0.99       960\n",
      "weighted avg       0.99      0.99      0.99       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.88      0.84       160\n",
      "           1       0.87      0.78      0.82       160\n",
      "\n",
      "    accuracy                           0.83       320\n",
      "   macro avg       0.83      0.83      0.83       320\n",
      "weighted avg       0.83      0.83      0.83       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vanilla_perceptron_truthfulness = VanillaPerceptron()\n",
    "vanilla_perceptron_truthfulness.load(vanilla_perceptron_truthfulness_data)\n",
    "\n",
    "y_dev_truthfulness_pred = vanilla_perceptron_truthfulness.predict(X_dev)\n",
    "\n",
    "calculate_scores(y_all_truthfulness, vanilla_perceptron_truthfulness.predict(X_all), title=\"Whole\")\n",
    "calculate_scores(y_dev_truthfulness, y_dev_truthfulness_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging the Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_f1_score = calculate_f1_score(y_dev_sentiment, y_dev_sentiment_pred, average=\"macro\")\n",
    "truthfulness_f1_score = calculate_f1_score(y_dev_truthfulness, y_dev_truthfulness_pred, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8937126333476613"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([sentiment_f1_score, truthfulness_f1_score])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Vanilla Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_model_file_data = {\n",
    "    \"tf_idf_model\": tf_idf_model_data,\n",
    "    \"sentiment_classifier\": vanilla_perceptron_sentiment_data,\n",
    "    \"truthfulness_classifier\": vanilla_perceptron_truthfulness_data,\n",
    "}\n",
    "\n",
    "store_model(VANILLA_MODEL_FILE_PATH, vanilla_model_file_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Vanilla Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model_data, vanilla_perceptron_sentiment_data, vanilla_perceptron_truthfulness_data = load_model(\n",
    "    VANILLA_MODEL_FILE_PATH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_saved_model = TfIdf()\n",
    "tf_idf_saved_model.load(tf_idf_model_data)\n",
    "\n",
    "vanilla_perceptron_sentiment_saved = VanillaPerceptron()\n",
    "vanilla_perceptron_sentiment_saved.load(vanilla_perceptron_sentiment_data)\n",
    "\n",
    "vanilla_perceptron_truthfulness_saved = VanillaPerceptron()\n",
    "vanilla_perceptron_truthfulness_saved.load(vanilla_perceptron_truthfulness_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Loaded Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_tf_idf_vectors_saved = tf_idf_saved_model.transform(dev_tokenized)\n",
    "X_dev_tf_idf_vectors_saved.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sentiment = vanilla_perceptron_sentiment_saved.predict(X_dev_tf_idf_vectors_saved)\n",
    "\n",
    "calculate_scores(y_all_sentiment, vanilla_perceptron_sentiment_saved.predict(X_all), title=\"Train\")\n",
    "calculate_scores(y_dev_sentiment, y_dev_sentiment_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_truthfulness = vanilla_perceptron_truthfulness_saved.predict(X_dev_tf_idf_vectors_saved)\n",
    "\n",
    "calculate_scores(y_all_truthfulness, vanilla_perceptron_truthfulness_saved.predict(X_all), title=\"Train\")\n",
    "calculate_scores(y_dev_truthfulness, y_dev_truthfulness_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list()\n",
    "for (id, truthfulness, sentiment) in zip(\n",
    "    dev_raw_data[:, 0],\n",
    "    np.where(y_pred_truthfulness == -1, DECEPTIVE, TRUTHFUL),\n",
    "    np.where(y_pred_sentiment == -1, NEGATIVE, POSITIVE),\n",
    "):\n",
    "    output.append((id, truthfulness, sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_predictions(OUTPUT_FILE_PATH, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------- **\\*\\*\\*\\***\\*\\***\\*\\*\\*\\***\\*\\*\\***\\*\\*\\*\\***\\*\\***\\*\\*\\*\\*** -------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaged Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragedPerceptron:\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_iterations: int = 1000,\n",
    "        learning_rate: float = 1e-2,\n",
    "        shuffle: bool = True,\n",
    "        class_weights = None,\n",
    "        lr_scheduler_func = None,\n",
    "        score_func = calculate_f1_score,\n",
    "        rng=np.random.default_rng(seed=RANDOM_SEED),\n",
    "        debug: bool = False,\n",
    "        debug_at: int = 50,\n",
    "    ) -> None:\n",
    "        self.type = TYPE_AVERAGED_PERCEPTRON\n",
    "        self.max_iterations = max_iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.shuffle = shuffle\n",
    "        self.class_weights = class_weights\n",
    "        self.learning_rate_scheduler = lr_scheduler_func\n",
    "        self.calculate_score = score_func\n",
    "        self.rng = rng\n",
    "        self.debug = debug\n",
    "        self.debug_at = debug_at\n",
    "\n",
    "        self.best_epoch = 0\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_val = None,\n",
    "        y_val = None,\n",
    "    ):\n",
    "        n_epoch = 0\n",
    "\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        current_weights = self.rng.random(size=(X_train.shape[-1],))\n",
    "        current_bias: float = 0.0\n",
    "        self.cache = {\"weights\": current_weights, \"bias\": current_bias}\n",
    "\n",
    "        c = 1\n",
    "\n",
    "        best_val_score = -1\n",
    "        best_epoch = 0\n",
    "        best_weights = current_weights.copy()\n",
    "        best_bias = current_bias\n",
    "        best_cache = self.cache\n",
    "\n",
    "        for n_epoch in range(1, self.max_iterations + 1):\n",
    "\n",
    "            if self.shuffle:\n",
    "                idxs = np.arange(X_train.shape[0])\n",
    "                self.rng.shuffle(idxs)\n",
    "\n",
    "                X_train = X_train[idxs]\n",
    "                y_train = y_train[idxs]\n",
    "\n",
    "            for x, y_true in zip(X_train, y_train):\n",
    "\n",
    "                a = np.dot(current_weights, x) + current_bias\n",
    "                if y_true * a <= 0:\n",
    "                    if self.class_weights is None:\n",
    "                        current_weights = current_weights + y_true * x * self.learning_rate\n",
    "                        self.cache[\"weights\"] = self.cache[\"weights\"] + y_true * c * x * self.learning_rate\n",
    "                    else:\n",
    "                        current_weights = current_weights + y_true * x * self.learning_rate * self.class_weights[y_true]\n",
    "                        self.cache[\"weights\"] = (\n",
    "                            self.cache[\"weights\"] + y_true * c * x * self.learning_rate * self.class_weights[y_true]\n",
    "                        )\n",
    "\n",
    "                    current_bias = current_bias + y_true\n",
    "                    self.cache[\"bias\"] = self.cache[\"bias\"] + y_true * c\n",
    "\n",
    "                c += 1\n",
    "\n",
    "            self.weights = current_weights - (1 / c) * self.cache[\"weights\"]\n",
    "            self.bias = current_bias - (1 / c) * self.cache[\"bias\"]\n",
    "\n",
    "            if X_val is not None and y_val is not None:\n",
    "                train_score = self.calculate_score(y_train, self.predict(X_train))\n",
    "                val_score = self.calculate_score(y_val, self.predict(X_val))\n",
    "\n",
    "                if val_score > best_val_score:\n",
    "                    best_val_score = val_score\n",
    "\n",
    "                    best_epoch = n_epoch\n",
    "                    best_weights = self.weights\n",
    "                    best_bias = self.bias\n",
    "                    best_cache = self.cache\n",
    "\n",
    "                if self.debug and (n_epoch == self.max_iterations or n_epoch % self.debug_at == 0):\n",
    "                    print(\"Epoch #\", n_epoch, \" Train: \", train_score, \" Val: \", val_score)\n",
    "\n",
    "            # Update learning rate\n",
    "            if self.learning_rate_scheduler:\n",
    "                learning_rate = self.learning_rate_scheduler(learning_rate, n_epoch)\n",
    "\n",
    "        # Set best epochs, weight, bias and cache\n",
    "        if  X_val is not None and y_val is not None:\n",
    "            self.best_epoch = best_epoch\n",
    "            self.weights = best_weights\n",
    "            self.bias = best_bias\n",
    "            self.cache = best_cache\n",
    "\n",
    "    def _activation(self, x):\n",
    "        return np.dot(self.weights, x) + self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = list()\n",
    "        for x in X:\n",
    "            pred = np.sign(self._activation(x))\n",
    "            predictions.append(pred)\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def export(\n",
    "        self,\n",
    "    ):\n",
    "        return {\n",
    "            \"type\": self.type,\n",
    "            \"max_iterations\": self.max_iterations,\n",
    "            \"weights\": self.weights.tolist(),\n",
    "            \"bias\": float(self.bias),\n",
    "            \"best_epoch\": self.best_epoch,\n",
    "        }\n",
    "\n",
    "    def load(self, model_data):\n",
    "        self.type = model_data[\"type\"]\n",
    "        self.max_iterations = (model_data[\"max_iterations\"],)\n",
    "        self.weights = np.array(model_data[\"weights\"])\n",
    "        self.bias = model_data[\"bias\"]\n",
    "        self.best_epoch = model_data[\"best_epoch\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_perceptron_sentiment = AveragedPerceptron(\n",
    "    max_iterations=2000,\n",
    "    learning_rate=3,\n",
    "    shuffle=True,\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    "    rng=rng,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    ")\n",
    "\n",
    "averaged_perceptron_sentiment.fit(X_all, y_all_sentiment, X_dev, y_dev_sentiment)\n",
    "\n",
    "averaged_perceptron_sentiment_data = averaged_perceptron_sentiment.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_perceptron_sentiment_data[\"best_epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_sentiment_pred = averaged_perceptron_sentiment.predict(X_dev)\n",
    "\n",
    "calculate_scores(y_all_sentiment, averaged_perceptron_sentiment.predict(X_all), title=\"All\")\n",
    "calculate_scores(y_dev_sentiment, y_dev_sentiment_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truthful Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/gcxbjppx70qfkdwy32kg04dh0000gn/T/ipykernel_38168/2355303260.py:7: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp / (tp + fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 50  Train:  0.7826047573325603  Val:  0.656089900771085\n",
      "Epoch # 100  Train:  0.9404294695588276  Val:  0.7811730686569497\n",
      "Epoch # 150  Train:  0.9718559135698579  Val:  0.815406877267083\n",
      "Epoch # 200  Train:  0.9822861118558228  Val:  0.8343345543345543\n",
      "Epoch # 250  Train:  0.9822861118558228  Val:  0.8305882352941176\n",
      "Epoch # 300  Train:  0.9822861118558228  Val:  0.8236498189261534\n",
      "Epoch # 350  Train:  0.9843711843711844  Val:  0.8164266497863586\n",
      "Epoch # 400  Train:  0.9854135645167592  Val:  0.8031746031746032\n",
      "Epoch # 450  Train:  0.9854135645167592  Val:  0.7961458831024049\n",
      "Epoch # 500  Train:  0.9854135645167592  Val:  0.7860087233384235\n",
      "Epoch # 550  Train:  0.986455849651249  Val:  0.7791977919779198\n",
      "Epoch # 600  Train:  0.9874980465697765  Val:  0.77137106918239\n",
      "Epoch # 650  Train:  0.9874980465697765  Val:  0.7673573246092331\n",
      "Epoch # 700  Train:  0.9874980465697765  Val:  0.7673573246092331\n",
      "Epoch # 750  Train:  0.9874980465697765  Val:  0.7673573246092331\n",
      "Epoch # 800  Train:  0.988540162065549  Val:  0.7703171281553595\n"
     ]
    }
   ],
   "source": [
    "averaged_perceptron_truthfulness = AveragedPerceptron(\n",
    "    max_iterations=800,\n",
    "    learning_rate=815e-2,\n",
    "    shuffle=True,\n",
    "    class_weights={-1:1.0095, 1:1.0},\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    "    rng=rng,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    ")\n",
    "\n",
    "averaged_perceptron_truthfulness.fit(X_all, y_all_truthfulness, X_dev, y_dev_truthfulness)\n",
    "averaged_perceptron_truthfulness_data = averaged_perceptron_truthfulness.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_perceptron_truthfulness_data[\"best_epoch\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Whole ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      1.00      0.98       480\n",
      "           1       1.00      0.96      0.98       480\n",
      "\n",
      "    accuracy                           0.98       960\n",
      "   macro avg       0.98      0.98      0.98       960\n",
      "weighted avg       0.98      0.98      0.98       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.85      0.84       160\n",
      "           1       0.85      0.82      0.84       160\n",
      "\n",
      "    accuracy                           0.84       320\n",
      "   macro avg       0.84      0.84      0.84       320\n",
      "weighted avg       0.84      0.84      0.84       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_dev_truthfulness_pred = averaged_perceptron_truthfulness.predict(X_dev)\n",
    "\n",
    "calculate_scores(y_all_truthfulness, averaged_perceptron_truthfulness.predict(X_all), title=\"Whole\")\n",
    "calculate_scores(y_dev_truthfulness, y_dev_truthfulness_pred, title=\"Dev\")\n",
    "\n",
    "del averaged_perceptron_truthfulness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging the Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_f1_score = calculate_f1_score(y_dev_sentiment, y_dev_sentiment_pred, average=\"macro\")\n",
    "truthfulness_f1_score = calculate_f1_score(y_dev_truthfulness, y_dev_truthfulness_pred, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([sentiment_f1_score, truthfulness_f1_score])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Averaged Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_model_file_data = {\n",
    "    \"tf_idf_model\": tf_idf_model_data,\n",
    "    \"sentiment_classifier\": averaged_perceptron_sentiment_data,\n",
    "    \"truthfulness_classifier\": averaged_perceptron_truthfulness_data,\n",
    "}\n",
    "\n",
    "store_model(AVERAGED_MODEL_FILE_PATH, averaged_model_file_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Loaded Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model_data, averaged_perceptron_sentiment_data, averaged_perceptron_truthfulness_data = load_model(\n",
    "    AVERAGED_MODEL_FILE_PATH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_saved_model = TfIdf()\n",
    "tf_idf_saved_model.load(tf_idf_model_data)\n",
    "\n",
    "averaged_perceptron_sentiment_saved = AveragedPerceptron()\n",
    "averaged_perceptron_sentiment_saved.load(averaged_perceptron_sentiment_data)\n",
    "\n",
    "averaged_perceptron_truthfulness_saved = AveragedPerceptron()\n",
    "averaged_perceptron_truthfulness_saved.load(averaged_perceptron_truthfulness_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_tf_idf_vectors_saved = tf_idf_saved_model.transform(dev_tokenized)\n",
    "X_dev_tf_idf_vectors_saved.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sentiment = averaged_perceptron_sentiment_saved.predict(X_dev_tf_idf_vectors_saved)\n",
    "\n",
    "calculate_scores(y_all_sentiment, averaged_perceptron_sentiment_saved.predict(X_all), title=\"Whole\")\n",
    "calculate_scores(y_dev_sentiment, y_dev_sentiment_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_truthfulness = averaged_perceptron_truthfulness_saved.predict(X_dev_tf_idf_vectors_saved)\n",
    "\n",
    "calculate_scores(y_all_truthfulness, averaged_perceptron_truthfulness_saved.predict(X_all), title=\"Whole\")\n",
    "calculate_scores(y_dev_truthfulness, y_dev_truthfulness_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list()\n",
    "for (id, truthfulness, sentiment) in zip(\n",
    "    dev_raw_data[:, 0],\n",
    "    np.where(y_pred_truthfulness == -1, DECEPTIVE, TRUTHFUL),\n",
    "    np.where(y_pred_sentiment == -1, NEGATIVE, POSITIVE),\n",
    "):\n",
    "    output.append((id, truthfulness, sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_predictions(OUTPUT_FILE_PATH, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('csci544')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e78917e7f90f3892e7e12462ef46781cf5994bd706032ea53be00d0b1f29dcb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
