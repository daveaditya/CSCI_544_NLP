{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import json\n",
    "from typing import List, Dict, Tuple, Set, Any, Callable\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "### Constants                                      ###\n",
    "######################################################\n",
    "# Base Paths\n",
    "INPUT_PATH = \"./data\"\n",
    "MODEL_PATH = \"./model\"\n",
    "OUTPUT_PATH = \"./output\"\n",
    "\n",
    "# Model File names\n",
    "VANILLA_MODEL_FILENAME = \"vanillamodel.txt\"\n",
    "AVERAGED_MODEL_FILENAME = \"averagedmodel.txt\"\n",
    "OUTPUT_FILENAME = \"output.txt\"\n",
    "\n",
    "# Class Identifiers\n",
    "TRUTHFUL = \"True\"\n",
    "DECEPTIVE = \"Fake\"\n",
    "POSITIVE = \"Pos\"\n",
    "NEGATIVE = \"Neg\"\n",
    "\n",
    "TYPE_VANILLA_PERPCETRON = \"vanilla_perceptron\"\n",
    "TYPE_AVERAGED_PERCEPTRON = \"averaged_perceptron\"\n",
    "\n",
    "# File paths\n",
    "TRAIN_FILE_PATH = f\"{INPUT_PATH}/train-labeled.txt\"\n",
    "CLEANED_DATA_FILE_PATH = f\"{INPUT_PATH}/cleaned-data.txt\"\n",
    "PREPROCESSED_DATA_FILE_PATH = f\"{INPUT_PATH}/preprocessed-data.txt\"\n",
    "\n",
    "VANILLA_MODEL_FILE_PATH = f\"{MODEL_PATH}/{VANILLA_MODEL_FILENAME}\"\n",
    "AVERAGED_MODEL_FILE_PATH = f\"{MODEL_PATH}/{AVERAGED_MODEL_FILENAME}\"\n",
    "\n",
    "OUTPUT_FILE_PATH = f\"{OUTPUT_PATH}/{OUTPUT_FILENAME}\"\n",
    "\n",
    "DEV_DATA_FILE_PATH = f\"{INPUT_PATH}/dev-text.txt\"\n",
    "DEV_KEY_FILE_PATH = f\"{INPUT_PATH}/dev-key.txt\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "DATA_ID_COL = 0\n",
    "TRAIN_DATA_COL = 3\n",
    "DEV_DATA_COL = 1\n",
    "SENTIMENT_TARGET_COL = 2\n",
    "TRUTHFULNESS_TARGET_COL = 1\n",
    "TEST_SIZE = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"07Zfn0z Fake Pos If you're looking for an elegant hotel in downtown Chicago, you have to stay here. The Ambassador East Hotel has very comfortable and beautiful large rooms and is like a home away from home. The perfect place for a business person, and if you have a small pet you can bring them too! I would give this place four stars and would definitely stay here again.\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_regex = re.compile(\"(\\w*) (\\w*) (\\w*) (.*)\\n?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('07Zfn0z',\n",
       " 'Fake',\n",
       " 'Pos',\n",
       " \"If you're looking for an elegant hotel in downtown Chicago, you have to stay here. The Ambassador East Hotel has very comfortable and beautiful large rooms and is like a home away from home. The perfect place for a business person, and if you have a small pet you can bring them too! I would give this place four stars and would definitely stay here again.\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(input_regex, line).groups()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('07Zfn0z',\n",
       "  'Fake',\n",
       "  'Pos',\n",
       "  \"If you're looking for an elegant hotel in downtown Chicago, you have to stay here. The Ambassador East Hotel has very comfortable and beautiful large rooms and is like a home away from home. The perfect place for a business person, and if you have a small pet you can bring them too! I would give this place four stars and would definitely stay here again.\")]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "data.append(re.match(input_regex, line).groups())\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fake'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data)[0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_data(input_file_path: str, type: str = \"TRAIN\") -> npt.NDArray:\n",
    "    input_data = list()\n",
    "    regex = \"(\\w*) (\\w*) (\\w*) (.*)\\n?\"\n",
    "    if type == \"DEV\":\n",
    "        regex = \"(\\w*) (.*)\\n?\"\n",
    "    elif type == \"KEY\":\n",
    "        regex = \"(\\w*) (\\w*) (\\w*)\\n?\"\n",
    "    input_regex = re.compile(regex)\n",
    "    with open(input_file_path, mode=\"r\") as input_file:\n",
    "        for line in input_file:\n",
    "            input_data.append(re.match(input_regex, line).groups())\n",
    "    return np.array(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Data\n",
    "def store_data(date_file_path: str, data: npt.NDArray) -> None:\n",
    "    with open(date_file_path, mode=\"w\") as data_file:\n",
    "        for row in data:\n",
    "            data_file.write(f\"{row[0]} {row[1]} {row[2]} {row[3]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Model\n",
    "def store_model(model_file_path: str, model_data: Any) -> None:\n",
    "    with open(model_file_path, mode=\"w\") as model_file:\n",
    "        json.dump(model_data, model_file, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "def load_model(model_file_path: str) -> npt.NDArray:\n",
    "    with open(model_file_path, mode=\"r\") as model_file:\n",
    "        model_data = json.load(model_file)\n",
    "\n",
    "    return (model_data[\"tf_idf_model\"], model_data[\"sentiment_classifier\"], model_data[\"truthfulness_classifier\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Predictions\n",
    "def store_predictions(output_file_path: str, predictions: List[Tuple[str, str, str]]) -> None:\n",
    "    with open(output_file_path, mode=\"w\") as output_file:\n",
    "        for prediction in predictions:\n",
    "            output_file.write(f\"{prediction[0]} {prediction[1]} {prediction[2]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_score(y_true: npt.NDArray, y_pred: npt.NDArray):\n",
    "    return (y_true == y_pred).sum() / y_true.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_score(y_true: npt.NDArray, y_pred: npt.NDArray, average: str = \"macro\"):\n",
    "    def calculate_f1(y_true, y_pred, label):\n",
    "        tp = np.sum((y_true == label) & (y_pred == label))\n",
    "        fp = np.sum((y_true != label) & (y_pred == label))\n",
    "        fn = np.sum((y_pred != label) & (y_true == label))\n",
    "\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "\n",
    "    def macro_f1(y_true, y_pred):\n",
    "        return np.mean([calculate_f1(y_true, y_pred, label) for label in np.unique(y_true)])\n",
    "\n",
    "    def micro_f1(y_true, y_pred):\n",
    "        return {label: calculate_f1(y_true, y_pred, label) for label in np.unique(y_true)}\n",
    "\n",
    "    if average == \"macro\":\n",
    "        return macro_f1(y_true, y_pred)\n",
    "    elif average == \"micro\":\n",
    "        return micro_f1(y_true, y_pred)\n",
    "    else:\n",
    "        return {\"micro\": micro_f1(y_true, y_pred), \"macro\": macro_f1(y_true, y_pred)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Scores\n",
    "def calculate_scores(y_true, y_pred, title: str):\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    print(f\"------------------------ {title} ------------------------\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(TRAIN_FILE_PATH, type=\"TRAIN\")\n",
    "\n",
    "dev_raw_data = load_data(DEV_DATA_FILE_PATH, type=\"DEV\")\n",
    "dev_key_data = load_data(DEV_KEY_FILE_PATH, type=\"KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all reviews to lower case (optional according to study)\n",
    "def to_lower(data: npt.NDArray):\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = result[i].lower()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_encodings(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"&#\\d+;\", \" \", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"<[a-zA-Z]+\\s?/?>\", \"\", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"https?://([\\w\\-\\._]+){2,}/[\\w\\-\\.\\-/=\\+_\\?]+\", \"\", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_and_url(data):\n",
    "    \"\"\"Function to remove\n",
    "             1. HTML encodings\n",
    "             2. HTML tags (both closed and open)\n",
    "             3. URLs\n",
    "\n",
    "    Args:\n",
    "        data (npt.NDArray): A Numpy Array of type string\n",
    "\n",
    "    Returns:\n",
    "        _type_: npt.NDArray\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        # Remove HTML encodings\n",
    "        result[i] = re.sub(r\"&#\\d+;\", \"\", result[i])\n",
    "\n",
    "        # Remove HTML tags (both open and closed)\n",
    "        result[i] = re.sub(r\"<[a-zA-Z]+\\s?/?>\", \"\", result[i])\n",
    "\n",
    "        # Remove URLs\n",
    "        result[i] = re.sub(r\"https?://([\\w\\-\\._]+){2,}/[\\w\\-\\.\\-/=\\+_\\?]+\", \"\", result[i])\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_digits_with_tag(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"\\d+\", \" NUM \", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-alphabetical characters\n",
    "def remove_non_alpha_characters(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"_+|\\\\|[^a-zA-Z0-9\\s]\", \" \", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "def remove_extra_spaces(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"^\\s*|\\s\\s*\", \" \", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding contractions\n",
    "def fix_contractions(data: npt.NDArray):\n",
    "    from contractions import fix\n",
    "\n",
    "    def contraction_fixer(txt: str):\n",
    "        return \" \".join([fix(word) for word in txt.split()])\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = contraction_fixer(result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: to_lower\n",
      "Ended: to_lower\n",
      "Starting: remove_html_encodings\n",
      "Ended: remove_html_encodings\n",
      "Starting: remove_html_tags\n",
      "Ended: remove_html_tags\n",
      "Starting: remove_url\n",
      "Ended: remove_url\n",
      "Starting: fix_contractions\n",
      "Ended: fix_contractions\n",
      "Starting: remove_non_alpha_characters\n",
      "Ended: remove_non_alpha_characters\n",
      "Starting: remove_extra_spaces\n",
      "Ended: remove_extra_spaces\n"
     ]
    }
   ],
   "source": [
    "# A dictionary containing the columns and a list of functions to perform on it in order\n",
    "data_cleaning_pipeline = {\n",
    "    TRAIN_DATA_COL: [\n",
    "        to_lower,\n",
    "        remove_html_encodings,\n",
    "        remove_html_tags,\n",
    "        remove_url,\n",
    "        fix_contractions,\n",
    "        remove_non_alpha_characters,\n",
    "        remove_extra_spaces,\n",
    "    ]\n",
    "}\n",
    "\n",
    "cleaned_data = data.copy()\n",
    "\n",
    "# Process all the cleaning instructions\n",
    "for col, pipeline in data_cleaning_pipeline.items():\n",
    "    # Get the column to perform cleaning on\n",
    "    temp_data = cleaned_data[:, col].copy()\n",
    "\n",
    "    # Perform all the cleaning functions sequencially\n",
    "    for func in pipeline:\n",
    "        print(f\"Starting: {func.__name__}\")\n",
    "        temp_data = func(temp_data)\n",
    "        print(f\"Ended: {func.__name__}\")\n",
    "\n",
    "    # Replace the old column with cleaned one.\n",
    "    cleaned_data[:, col] = temp_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data(CLEANED_DATA_FILE_PATH, cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: to_lower\n",
      "Ended: to_lower\n",
      "Starting: remove_html_encodings\n",
      "Ended: remove_html_encodings\n",
      "Starting: remove_html_tags\n",
      "Ended: remove_html_tags\n",
      "Starting: remove_url\n",
      "Ended: remove_url\n",
      "Starting: fix_contractions\n",
      "Ended: fix_contractions\n",
      "Starting: remove_non_alpha_characters\n",
      "Ended: remove_non_alpha_characters\n",
      "Starting: remove_extra_spaces\n",
      "Ended: remove_extra_spaces\n"
     ]
    }
   ],
   "source": [
    "# A dictionary containing the columns and a list of functions to perform on it in order\n",
    "data_cleaning_pipeline = {\n",
    "    DEV_DATA_COL: [\n",
    "        to_lower,\n",
    "        remove_html_encodings,\n",
    "        remove_html_tags,\n",
    "        remove_url,\n",
    "        fix_contractions,\n",
    "        remove_non_alpha_characters,\n",
    "        remove_extra_spaces,\n",
    "    ]\n",
    "}\n",
    "\n",
    "dev_cleaned_data = dev_raw_data.copy()\n",
    "\n",
    "# Process all the cleaning instructions\n",
    "for col, pipeline in data_cleaning_pipeline.items():\n",
    "    # Get the column to perform cleaning on\n",
    "    temp_data = dev_cleaned_data[:, col].copy()\n",
    "\n",
    "    # Perform all the cleaning functions sequencially\n",
    "    for func in pipeline:\n",
    "        print(f\"Starting: {func.__name__}\")\n",
    "        temp_data = func(temp_data)\n",
    "        print(f\"Ended: {func.__name__}\")\n",
    "\n",
    "    # Replace the old column with cleaned one.\n",
    "    dev_cleaned_data[:, col] = temp_data.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not Applicable since everything has to be implemented from scratch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIdf:\n",
    "    # Implement low frequency terms and other techniques\n",
    "    def __init__(self) -> None:\n",
    "        self.n_docs: int = None\n",
    "        self.vocab: List = list()\n",
    "        self.vocab_size: int = None\n",
    "        self.vocab_index: Dict[str, int] = dict()\n",
    "        self.word_document_count: Dict[str, int] = dict()\n",
    "\n",
    "    def __create_vocab__(self, documents: npt.NDArray) -> Set:\n",
    "        vocab = set()\n",
    "\n",
    "        for document in documents:\n",
    "            for word in document:\n",
    "                vocab.add(word)\n",
    "\n",
    "        return list(vocab)\n",
    "\n",
    "    def __get_word_document_count__(self, documents: npt.NDArray):\n",
    "        word_document_count = dict()\n",
    "\n",
    "        for document in documents:\n",
    "            for word in document:\n",
    "                if word in self.vocab:\n",
    "                    if word not in word_document_count:\n",
    "                        word_document_count[word] = 1\n",
    "                    else:\n",
    "                        word_document_count[word] += 1\n",
    "\n",
    "        return word_document_count\n",
    "\n",
    "    def __term_frequency__(self, word: str, document: npt.NDArray):\n",
    "        word_occurences = (document == word).sum()\n",
    "        return word_occurences / self.n_docs\n",
    "\n",
    "    def __inverse_document_frequency__(self, word: str):\n",
    "        word_occurrences = 1\n",
    "\n",
    "        if word in self.word_document_count:\n",
    "            word_occurrences += self.word_document_count[word]\n",
    "\n",
    "        return np.log(self.n_docs / word_occurrences)\n",
    "\n",
    "    def __tf_idf__(self, document: npt.NDArray):\n",
    "        tf_idf_vector = np.zeros(shape=(self.vocab_size,))\n",
    "        for word in document:\n",
    "            # ignore word not in vocab\n",
    "            if word in self.vocab:\n",
    "                tf = self.__term_frequency__(word, document)\n",
    "                idf = self.__inverse_document_frequency__(word)\n",
    "\n",
    "                tf_idf_vector[self.vocab_index[word]] = tf * idf\n",
    "        return tf_idf_vector\n",
    "\n",
    "    def fit(self, documents: npt.NDArray):\n",
    "        self.n_docs = documents.shape[0]\n",
    "        self.vocab = self.__create_vocab__(documents)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.vocab_index = {word: idx for idx, word in enumerate(self.vocab)}\n",
    "        self.word_document_count = self.__get_word_document_count__(documents)\n",
    "\n",
    "    def transform(self, documents: npt.NDArray):\n",
    "        tf_idf_vectors = list()\n",
    "        for document in documents:\n",
    "            tf_idf_vectors.append(self.__tf_idf__(document))\n",
    "        return np.array(tf_idf_vectors)\n",
    "\n",
    "    def export(self):\n",
    "        return {\n",
    "            \"n_docs\": self.n_docs,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"vocab\": self.vocab,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"vocab_index\": self.vocab_index,\n",
    "            \"word_document_count\": self.word_document_count,\n",
    "        }\n",
    "\n",
    "    def load(self, tf_idf_model_data):\n",
    "        self.n_docs = tf_idf_model_data[\"n_docs\"]\n",
    "        self.vocab_size = tf_idf_model_data[\"vocab_size\"]\n",
    "        self.vocab = tf_idf_model_data[\"vocab\"]\n",
    "        self.vocab_size = tf_idf_model_data[\"vocab_size\"]\n",
    "        self.vocab_index = tf_idf_model_data[\"vocab_index\"]\n",
    "        self.word_document_count = tf_idf_model_data[\"word_document_count\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data: npt.NDArray):\n",
    "    tokenized_documents = list()\n",
    "    for document in data:\n",
    "        tokenized_documents.append(np.array(document.split()))\n",
    "    return np.array(tokenized_documents, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = load_data(CLEANED_DATA_FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = tokenize(final_data[:, TRAIN_DATA_COL])\n",
    "dev_tokenized = tokenize(dev_cleaned_data[:, DEV_DATA_COL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model = TfIdf()\n",
    "tf_idf_model.fit(train_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_idf_vectors = tf_idf_model.transform(train_tokenized)\n",
    "X_dev_tf_idf_vectors = tf_idf_model.transform(dev_tokenized)\n",
    "\n",
    "X_train_tf_idf_vectors.shape, X_dev_tf_idf_vectors.shape\n",
    "\n",
    "tf_idf_model_data = tf_idf_model.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sentiment = np.where(final_data[:, SENTIMENT_TARGET_COL] == POSITIVE, 1, -1)\n",
    "y_train_truthfulness = np.where(final_data[:, TRUTHFULNESS_TARGET_COL] == TRUTHFUL, 1, -1)\n",
    "\n",
    "y_dev_sentiment = np.where(dev_key_data[:, SENTIMENT_TARGET_COL] == POSITIVE, 1, -1)\n",
    "y_dev_truthfulness = np.where(dev_key_data[:, TRUTHFULNESS_TARGET_COL] == TRUTHFUL, 1, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X: npt.NDArray, y: npt.NDArray, test_size: float = 0.2):\n",
    "    if 0 == test_size:\n",
    "        return X, None, y, None\n",
    "\n",
    "    n_max = X.shape[0]\n",
    "    sample = int((1 - test_size) * n_max)\n",
    "\n",
    "    # Shuffle the data\n",
    "    all_idx = np.random.permutation(n_max)\n",
    "    train_idx, test_idx = all_idx[:sample], all_idx[sample:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = (\n",
    "        X[train_idx],\n",
    "        X[test_idx],\n",
    "        y[train_idx],\n",
    "        y[test_idx],\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaPerceptron:\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_iterations: int,\n",
    "        learning_rate: float = 1e-2,\n",
    "        tolerance: float = 1e-2,\n",
    "        val_ratio: float = 0.2,\n",
    "        shuffle: bool = True,\n",
    "        class_weights: dict = None,\n",
    "        debug: bool = False,\n",
    "        debug_at: int = 50,\n",
    "        score_func: Callable[[npt.NDArray, npt.NDArray], float] = calculate_f1_score,\n",
    "    ) -> None:\n",
    "        self.type= TYPE_VANILLA_PERPCETRON\n",
    "        self.max_iterations = max_iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.val_ratio = val_ratio\n",
    "        self.shuffle = shuffle\n",
    "        self.class_weights = class_weights\n",
    "        self.debug = debug\n",
    "        self.debug_at = debug_at\n",
    "        self.calculate_score = score_func\n",
    "        self.best_epoch = 0\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X: npt.NDArray,\n",
    "        y: npt.NDArray,\n",
    "    ):\n",
    "        n_epoch = 0\n",
    "\n",
    "        self.weights: npt.NDArray = np.random.rand(X.shape[-1])\n",
    "        self.bias: float = 0.0\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, self.val_ratio)\n",
    "        best_val_score = -1\n",
    "\n",
    "        for n_epoch in range(1, self.max_iterations + 1):\n",
    "\n",
    "            if self.shuffle:\n",
    "                idxs = np.random.permutation(X.shape[0])\n",
    "                X = X[idxs]\n",
    "                y = y[idxs]\n",
    "\n",
    "            for x, y_true in zip(X_train, y_train):\n",
    "\n",
    "                a = np.dot(self.weights, x) + self.bias\n",
    "                if y_true * a <= 0:\n",
    "                    if self.class_weights is None:\n",
    "                        self.weights = self.weights + y_true * x * self.learning_rate\n",
    "                    else:\n",
    "                        self.weights = self.weights + y_true * x * self.class_weights[y_true] * self.learning_rate\n",
    "                    self.bias = self.bias + y_true\n",
    "\n",
    "            if self.val_ratio != 0:\n",
    "                train_score = self.calculate_score(y_train, self.predict(X_train))\n",
    "                val_score = self.calculate_score(y_val, self.predict(X_val))\n",
    "\n",
    "                if val_score > best_val_score:\n",
    "                    best_val_score = val_score\n",
    "                    self.best_epoch = n_epoch\n",
    "\n",
    "                if self.debug and (n_epoch == self.max_iterations or n_epoch % self.debug_at == 0):\n",
    "                    print(\"Epoch #\", n_epoch, \" Train: \", train_score, \" Val: \", val_score)\n",
    "\n",
    "        return self.best_epoch, best_val_score\n",
    "\n",
    "    def predict(self, X: npt.NDArray):\n",
    "        predictions = list()\n",
    "        for x in X:\n",
    "            pred = np.sign(np.dot(self.weights, x) + self.bias)\n",
    "            predictions.append(pred)\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def export(\n",
    "        self,\n",
    "    ):\n",
    "        return {\"type\": self.type, \"max_iterations\": self.best_epoch, \"weights\": self.weights.tolist(), \"bias\": float(self.bias)}\n",
    "\n",
    "    def load(self, model_data: Dict[str, Any]):\n",
    "        self.type = model_data[\"type\"]\n",
    "        self.max_iterations = (model_data[\"max_iterations\"],)\n",
    "        self.weights = np.array(model_data[\"weights\"])\n",
    "        self.bias = model_data[\"bias\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/gcxbjppx70qfkdwy32kg04dh0000gn/T/ipykernel_3621/2355303260.py:7: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp / (tp + fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 50  Train:  0.5520319275490234  Val:  0.5096385963684708\n",
      "Epoch # 100  Train:  0.4334052225991996  Val:  0.3700463201235203\n",
      "Epoch # 150  Train:  0.6389837169696457  Val:  0.5104364326375711\n",
      "Epoch # 200  Train:  0.6957097041871314  Val:  0.5475433015199718\n",
      "Epoch # 250  Train:  0.7517271439468235  Val:  0.6000000000000001\n",
      "Epoch # 300  Train:  0.835522943510164  Val:  0.6713712505962568\n",
      "Epoch # 350  Train:  0.9330213087589756  Val:  0.8333333333333334\n",
      "Epoch # 400  Train:  0.9555252759231503  Val:  0.885104994015885\n",
      "Epoch # 450  Train:  0.9673548779803551  Val:  0.8901212699277831\n",
      "Epoch # 500  Train:  0.9739130434782608  Val:  0.8952765353987129\n",
      "Epoch # 550  Train:  0.9765266825600587  Val:  0.9055944055944056\n",
      "Epoch # 600  Train:  0.981758462498982  Val:  0.9207375808449154\n",
      "Epoch # 650  Train:  0.9895731508634735  Val:  0.9205276083777145\n",
      "Epoch # 700  Train:  0.993483739044112  Val:  0.9093912222746579\n",
      "Epoch # 750  Train:  0.9921810839243899  Val:  0.9090883770158482\n",
      "Epoch # 800  Train:  0.993483739044112  Val:  0.9090883770158482\n",
      "Epoch # 850  Train:  0.9869735128093791  Val:  0.9090883770158482\n",
      "Epoch # 900  Train:  0.9960908271870752  Val:  0.9090883770158482\n",
      "Epoch # 950  Train:  0.9960908271870752  Val:  0.9090883770158482\n",
      "Epoch # 1000  Train:  0.9921832061068702  Val:  0.8980293501048218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "vanilla_perceptron_sentiment = VanillaPerceptron(\n",
    "    max_iterations=1000,\n",
    "    learning_rate=0.815,\n",
    "    tolerance=1e-8,\n",
    "    shuffle=True,\n",
    "    val_ratio=0.2,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    ")\n",
    "\n",
    "best_epoch, val_score = vanilla_perceptron_sentiment.fit(X_train_tf_idf_vectors, y_train_sentiment)\n",
    "\n",
    "del vanilla_perceptron_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(602, 0.9259259259259259)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch, val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_perceptron_sentiment = VanillaPerceptron(\n",
    "    max_iterations=602,\n",
    "    learning_rate=0.815,\n",
    "    tolerance=1e-8,\n",
    "    shuffle=True,\n",
    "    val_ratio=0.0,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    ")\n",
    "vanilla_perceptron_sentiment.fit(X_train_tf_idf_vectors, y_train_sentiment)\n",
    "\n",
    "vanilla_perceptron_sentiment_data = vanilla_perceptron_sentiment.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Train ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.99      0.99       480\n",
      "           1       0.99      0.99      0.99       480\n",
      "\n",
      "    accuracy                           0.99       960\n",
      "   macro avg       0.99      0.99      0.99       960\n",
      "weighted avg       0.99      0.99      0.99       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.97      0.92       160\n",
      "           1       0.97      0.86      0.91       160\n",
      "\n",
      "    accuracy                           0.92       320\n",
      "   macro avg       0.92      0.92      0.92       320\n",
      "weighted avg       0.92      0.92      0.92       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_dev_sentiment_pred = vanilla_perceptron_sentiment.predict(X_dev_tf_idf_vectors)\n",
    "\n",
    "calculate_scores(y_train_sentiment, vanilla_perceptron_sentiment.predict(X_train_tf_idf_vectors), title=\"Train\")\n",
    "calculate_scores(y_dev_sentiment, y_dev_sentiment_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_f1_score = calculate_f1_score(y_dev_sentiment, y_dev_sentiment_pred, average=\"macro\")\n",
    "pos_f1_score = calculate_f1_score(y_dev_sentiment, y_dev_sentiment_pred, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truthfulness Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 50  Train:  0.4444846292947558  Val:  0.41711426188490414\n",
      "Epoch # 100  Train:  0.5774456627775394  Val:  0.5194593918157928\n",
      "Epoch # 150  Train:  0.750784803409211  Val:  0.56640625\n",
      "Epoch # 200  Train:  0.7965052604803324  Val:  0.5552123552123552\n",
      "Epoch # 250  Train:  0.8241533903711538  Val:  0.578125\n",
      "Epoch # 300  Train:  0.8647065325522272  Val:  0.6002775850104094\n",
      "Epoch # 350  Train:  0.8960909067554954  Val:  0.6031513045562111\n",
      "Epoch # 400  Train:  0.9556991232118135  Val:  0.7677844969763605\n",
      "Epoch # 450  Train:  0.9713510580575149  Val:  0.8176638176638176\n",
      "Epoch # 500  Train:  0.9817703388221253  Val:  0.8226086956521741\n",
      "Epoch # 550  Train:  0.99088527758704  Val:  0.827558990828185\n",
      "Epoch # 600  Train:  0.9947916666666666  Val:  0.8326797385620914\n",
      "Epoch # 650  Train:  0.9934895722954173  Val:  0.8219701101778117\n",
      "Epoch # 700  Train:  0.9947916666666666  Val:  0.8219701101778117\n",
      "Epoch # 750  Train:  0.9960937433772504  Val:  0.8270695160894129\n",
      "Epoch # 800  Train:  0.9960937433772504  Val:  0.8321678321678323\n",
      "Epoch # 850  Train:  0.9986978967981486  Val:  0.8264252253239459\n",
      "Epoch # 900  Train:  0.9986978967981486  Val:  0.831505046072839\n",
      "Epoch # 950  Train:  0.9986978967981486  Val:  0.8260439831974302\n",
      "Epoch # 1000  Train:  1.0  Val:  0.8205607476635515\n"
     ]
    }
   ],
   "source": [
    "vanilla_perceptron_truthfulness = VanillaPerceptron(\n",
    "    max_iterations=1000,\n",
    "    learning_rate=0.815,\n",
    "    tolerance=1e-8,\n",
    "    shuffle=True,\n",
    "    val_ratio=0.2,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    ")\n",
    "\n",
    "best_epoch, best_val_score = vanilla_perceptron_truthfulness.fit(X_train_tf_idf_vectors, y_train_truthfulness)\n",
    "\n",
    "del vanilla_perceptron_truthfulness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533, 0.8381861185873909)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch, best_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_perceptron_truthfulness = VanillaPerceptron(\n",
    "    max_iterations=533,\n",
    "    learning_rate=0.815,\n",
    "    tolerance=1e-8,\n",
    "    shuffle=True,\n",
    "    val_ratio=0.0,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    ")\n",
    "vanilla_perceptron_truthfulness.fit(\n",
    "    X_train_tf_idf_vectors,\n",
    "    y_train_truthfulness,\n",
    ")\n",
    "\n",
    "vanilla_perceptron_truthfulness_data = vanilla_perceptron_truthfulness.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Train ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.97      0.98       480\n",
      "           1       0.97      0.98      0.98       480\n",
      "\n",
      "    accuracy                           0.98       960\n",
      "   macro avg       0.98      0.98      0.98       960\n",
      "weighted avg       0.98      0.98      0.98       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.77      0.82       160\n",
      "           1       0.79      0.89      0.84       160\n",
      "\n",
      "    accuracy                           0.83       320\n",
      "   macro avg       0.84      0.83      0.83       320\n",
      "weighted avg       0.84      0.83      0.83       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_dev_truthfulness_pred = vanilla_perceptron_truthfulness.predict(X_dev_tf_idf_vectors)\n",
    "\n",
    "calculate_scores(y_train_truthfulness, vanilla_perceptron_truthfulness.predict(X_train_tf_idf_vectors), title=\"Train\")\n",
    "calculate_scores(y_dev_truthfulness, y_dev_truthfulness_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging the Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_f1_score = calculate_f1_score(y_dev_truthfulness, y_dev_truthfulness_pred, average=\"macro\")\n",
    "truth_f1_score = calculate_f1_score(y_dev_truthfulness, y_dev_truthfulness_pred, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9198813056379822,\n",
       " 0.9108910891089109,\n",
       " 0.8200000000000001,\n",
       " 0.8411764705882352)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_f1_score, pos_f1_score, fake_f1_score, truth_f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872987216333782"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([neg_f1_score, pos_f1_score, fake_f1_score, truth_f1_score])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Vanilla Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_model_file_data = {\n",
    "    \"tf_idf_model\": tf_idf_model_data,\n",
    "    \"sentiment_classifier\": vanilla_perceptron_sentiment_data,\n",
    "    \"truthfulness_classifier\": vanilla_perceptron_truthfulness_data,\n",
    "}\n",
    "\n",
    "store_model(VANILLA_MODEL_FILE_PATH, vanilla_model_file_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Vanilla Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model_data, vanilla_perceptron_sentiment_data, vanilla_perceptron_truthfulness_data = load_model(\n",
    "    VANILLA_MODEL_FILE_PATH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_saved_model = TfIdf()\n",
    "tf_idf_saved_model.load(tf_idf_model_data)\n",
    "\n",
    "vanilla_perceptron_sentiment_saved = VanillaPerceptron(vanilla_perceptron_sentiment_data[\"max_iterations\"])\n",
    "vanilla_perceptron_sentiment_saved.load(vanilla_perceptron_sentiment_data)\n",
    "\n",
    "vanilla_perceptron_truthfulness_saved = VanillaPerceptron(vanilla_perceptron_truthfulness_data[\"max_iterations\"])\n",
    "vanilla_perceptron_truthfulness_saved.load(vanilla_perceptron_truthfulness_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Loaded Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 7675)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev_tf_idf_vectors_saved = tf_idf_saved_model.transform(dev_tokenized)\n",
    "X_dev_tf_idf_vectors_saved.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Train ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.99      0.99       480\n",
      "           1       0.99      0.99      0.99       480\n",
      "\n",
      "    accuracy                           0.99       960\n",
      "   macro avg       0.99      0.99      0.99       960\n",
      "weighted avg       0.99      0.99      0.99       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.97      0.92       160\n",
      "           1       0.97      0.86      0.91       160\n",
      "\n",
      "    accuracy                           0.92       320\n",
      "   macro avg       0.92      0.92      0.92       320\n",
      "weighted avg       0.92      0.92      0.92       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_pred_sentiment = vanilla_perceptron_sentiment_saved.predict(X_dev_tf_idf_vectors_saved)\n",
    "\n",
    "calculate_scores(y_train_sentiment, vanilla_perceptron_sentiment_saved.predict(X_train_tf_idf_vectors), title=\"Train\")\n",
    "calculate_scores(y_dev_sentiment, y_dev_sentiment_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Train ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.97      0.98       480\n",
      "           1       0.97      0.98      0.98       480\n",
      "\n",
      "    accuracy                           0.98       960\n",
      "   macro avg       0.98      0.98      0.98       960\n",
      "weighted avg       0.98      0.98      0.98       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.77      0.82       160\n",
      "           1       0.79      0.89      0.84       160\n",
      "\n",
      "    accuracy                           0.83       320\n",
      "   macro avg       0.84      0.83      0.83       320\n",
      "weighted avg       0.84      0.83      0.83       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_pred_truthfulness = vanilla_perceptron_truthfulness_saved.predict(X_dev_tf_idf_vectors_saved)\n",
    "\n",
    "calculate_scores(\n",
    "    y_train_truthfulness, vanilla_perceptron_truthfulness_saved.predict(X_train_tf_idf_vectors), title=\"Train\"\n",
    ")\n",
    "calculate_scores(y_dev_truthfulness, y_dev_truthfulness_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list()\n",
    "for (id, truthfulness, sentiment) in zip(\n",
    "    dev_raw_data[:, 0],\n",
    "    np.where(y_pred_truthfulness == -1, DECEPTIVE, TRUTHFUL),\n",
    "    np.where(y_pred_sentiment == -1, NEGATIVE, POSITIVE),\n",
    "):\n",
    "    output.append((id, truthfulness, sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_predictions(OUTPUT_FILE_PATH, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------- **\\*\\*\\*\\***\\*\\***\\*\\*\\*\\***\\*\\*\\***\\*\\*\\*\\***\\*\\***\\*\\*\\*\\*** -------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaged Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragedPerceptron:\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_iterations: int,\n",
    "        learning_rate: float = 1e-2,\n",
    "        tolerance: float = 1e-2,\n",
    "        val_ratio: float = 0.2,\n",
    "        shuffle: bool = True,\n",
    "        class_weights: dict = None,\n",
    "        debug: bool = False,\n",
    "        debug_at: int = 50,\n",
    "        score_func: Callable[[npt.NDArray, npt.NDArray], float] = calculate_f1_score,\n",
    "    ) -> None:\n",
    "        self.type = TYPE_AVERAGED_PERCEPTRON\n",
    "        self.max_iterations = max_iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.val_ratio = val_ratio\n",
    "        self.shuffle = shuffle\n",
    "        self.class_weights = class_weights\n",
    "        self.debug = debug\n",
    "        self.debug_at = debug_at\n",
    "        self.calculate_score = score_func\n",
    "        self.best_epoch = 0\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X: npt.NDArray,\n",
    "        y: npt.NDArray,\n",
    "    ):\n",
    "        n_epoch = 0\n",
    "\n",
    "        self.weights: npt.NDArray = np.random.rand(X.shape[-1])\n",
    "        self.bias: float = 0.0\n",
    "\n",
    "        c = 1\n",
    "        self.cache = {\"weights\": np.zeros(shape=(X.shape[-1],)), \"bias\": 0.0}\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, self.val_ratio)\n",
    "        best_val_score = -1\n",
    "\n",
    "        for n_epoch in range(1, self.max_iterations + 1):\n",
    "\n",
    "            if self.shuffle:\n",
    "                idxs = np.random.permutation(X.shape[0])\n",
    "                X = X[idxs]\n",
    "                y = y[idxs]\n",
    "\n",
    "            for x, y_true in zip(X_train, y_train):\n",
    "\n",
    "                a = np.dot(self.weights, x) + self.bias\n",
    "                if y_true * a <= 0:\n",
    "                    if self.class_weights is None:\n",
    "                        self.weights = self.weights + y_true * x * self.learning_rate\n",
    "                    else:\n",
    "                        self.weights = self.weights + y_true * x * self.class_weights[y_true] * self.learning_rate\n",
    "                    self.bias = self.bias + y_true\n",
    "\n",
    "                self.cache[\"weights\"] = self.cache[\"weights\"] + y_true * c * x * self.learning_rate\n",
    "                self.cache[\"bias\"] = self.cache[\"bias\"] + y_true * c\n",
    "\n",
    "            if self.val_ratio != 0:\n",
    "                train_score = self.calculate_score(y_train, self.predict(X_train))\n",
    "                val_score = self.calculate_score(y_val, self.predict(X_val))\n",
    "\n",
    "                if val_score > best_val_score:\n",
    "                    best_val_score = val_score\n",
    "                    self.best_epoch = n_epoch\n",
    "\n",
    "                if self.debug and (n_epoch == self.max_iterations or n_epoch % self.debug_at == 0):\n",
    "                    print(\"Epoch #\", n_epoch, \" Train: \", train_score, \" Val: \", val_score)\n",
    "\n",
    "        return self.best_epoch, best_val_score\n",
    "\n",
    "    def predict(self, X: npt.NDArray):\n",
    "        predictions = list()\n",
    "        for x in X:\n",
    "            pred = np.sign(np.dot(self.weights, x) + self.bias)\n",
    "            predictions.append(pred)\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def export(\n",
    "        self,\n",
    "    ):\n",
    "        return {\"type\": self.type, \"max_iterations\": self.best_epoch, \"weights\": self.weights.tolist(), \"bias\": float(self.bias)}\n",
    "\n",
    "    def load(self, model_data: Dict[str, Any]):\n",
    "        self.type = model_data[\"type\"]\n",
    "        self.max_iterations = (model_data[\"max_iterations\"],)\n",
    "        self.weights = np.array(model_data[\"weights\"])\n",
    "        self.bias = model_data[\"bias\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 50  Train:  0.3583959899749373  Val:  0.3685844141447733\n",
      "Epoch # 100  Train:  0.4176368259065971  Val:  0.413772046409713\n",
      "Epoch # 150  Train:  0.5495051453856874  Val:  0.5141536489085328\n",
      "Epoch # 200  Train:  0.6675324675324676  Val:  0.6042492468685587\n",
      "Epoch # 250  Train:  0.7673729016213113  Val:  0.6556315549475604\n",
      "Epoch # 300  Train:  0.8530265179139448  Val:  0.7444444444444445\n",
      "Epoch # 350  Train:  0.8936729890627163  Val:  0.7871699400278543\n",
      "Epoch # 400  Train:  0.9294765840220386  Val:  0.7998591350894493\n",
      "Epoch # 450  Train:  0.9504724666014988  Val:  0.8171838243530861\n",
      "Epoch # 500  Train:  0.97265397821203  Val:  0.823524496560176\n",
      "Epoch # 550  Train:  0.9804687168862523  Val:  0.8291624958291626\n",
      "Epoch # 600  Train:  0.9856764762232557  Val:  0.8403547671840355\n",
      "Epoch # 650  Train:  0.9895826975116482  Val:  0.8459111664591117\n",
      "Epoch # 700  Train:  0.9895822029300054  Val:  0.868215138785932\n",
      "Epoch # 750  Train:  0.9921861752277337  Val:  0.868215138785932\n",
      "Epoch # 800  Train:  0.9934882474737283  Val:  0.868503958578747\n",
      "Epoch # 850  Train:  0.9973951973951973  Val:  0.8792617908407383\n",
      "Epoch # 900  Train:  0.9986976494947457  Val:  0.8794726930320151\n",
      "Epoch # 950  Train:  0.9986976494947457  Val:  0.884804188938584\n",
      "Epoch # 1000  Train:  0.9986976494947457  Val:  0.884804188938584\n",
      "Epoch # 1050  Train:  0.9986976494947457  Val:  0.884804188938584\n",
      "Epoch # 1100  Train:  0.9986976494947457  Val:  0.884804188938584\n",
      "Epoch # 1150  Train:  0.9973951973951973  Val:  0.884804188938584\n",
      "Epoch # 1200  Train:  0.9960926304364417  Val:  0.884967320261438\n",
      "Epoch # 1250  Train:  0.9986976494947457  Val:  0.884967320261438\n",
      "Epoch # 1300  Train:  0.9986976494947457  Val:  0.9008237501019494\n",
      "Epoch # 1350  Train:  0.9973951973951973  Val:  0.8956521739130434\n",
      "Epoch # 1400  Train:  0.9986976494947457  Val:  0.900909955181312\n",
      "Epoch # 1450  Train:  0.9986976494947457  Val:  0.906158357771261\n",
      "Epoch # 1500  Train:  0.9986976494947457  Val:  0.906158357771261\n",
      "Epoch # 1550  Train:  0.9986976494947457  Val:  0.906158357771261\n",
      "Epoch # 1600  Train:  0.9960926304364417  Val:  0.906158357771261\n",
      "Epoch # 1650  Train:  0.9986976494947457  Val:  0.906158357771261\n",
      "Epoch # 1700  Train:  0.9986976494947457  Val:  0.911398246423627\n",
      "Epoch # 1750  Train:  0.9973951973951973  Val:  0.911398246423627\n",
      "Epoch # 1800  Train:  0.9986976494947457  Val:  0.911398246423627\n",
      "Epoch # 1850  Train:  0.9973951973951973  Val:  0.911398246423627\n",
      "Epoch # 1900  Train:  0.9973951973951973  Val:  0.911398246423627\n",
      "Epoch # 1950  Train:  0.9986976494947457  Val:  0.911398246423627\n",
      "Epoch # 2000  Train:  0.9986976494947457  Val:  0.9062092922275292\n"
     ]
    }
   ],
   "source": [
    "averaged_perceptron_sentiment = AveragedPerceptron(\n",
    "    max_iterations=2000,\n",
    "    learning_rate=0.815,\n",
    "    tolerance=1e-8,\n",
    "    shuffle=True,\n",
    "    val_ratio=0.2,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    ")\n",
    "\n",
    "best_epoch, val_score = averaged_perceptron_sentiment.fit(X_train_tf_idf_vectors, y_train_sentiment)\n",
    "\n",
    "del averaged_perceptron_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1648, 0.911398246423627)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch, val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_perceptron_sentiment = AveragedPerceptron(\n",
    "    max_iterations=1648,\n",
    "    learning_rate=0.815,\n",
    "    tolerance=1e-8,\n",
    "    shuffle=True,\n",
    "    val_ratio=0.0,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    ")\n",
    "averaged_perceptron_sentiment.fit(X_train_tf_idf_vectors, y_train_sentiment)\n",
    "\n",
    "averaged_perceptron_sentiment_data = averaged_perceptron_sentiment.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Train ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00       480\n",
      "           1       1.00      1.00      1.00       480\n",
      "\n",
      "    accuracy                           1.00       960\n",
      "   macro avg       1.00      1.00      1.00       960\n",
      "weighted avg       1.00      1.00      1.00       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.86      0.91       160\n",
      "           1       0.87      0.97      0.92       160\n",
      "\n",
      "    accuracy                           0.91       320\n",
      "   macro avg       0.92      0.91      0.91       320\n",
      "weighted avg       0.92      0.91      0.91       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_dev_sentiment_pred = averaged_perceptron_sentiment.predict(X_dev_tf_idf_vectors)\n",
    "\n",
    "calculate_scores(y_train_sentiment, averaged_perceptron_sentiment.predict(X_train_tf_idf_vectors), title=\"Train\")\n",
    "calculate_scores(y_dev_sentiment, y_dev_sentiment_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_f1_score = calculate_f1_score(y_dev_sentiment, y_dev_sentiment_pred, average=\"macro\")\n",
    "pos_f1_score = calculate_f1_score(y_dev_sentiment, y_dev_sentiment_pred, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truthful Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 50  Train:  0.33506493506493507  Val:  0.3263157894736842\n",
      "Epoch # 100  Train:  0.5764059287266491  Val:  0.5390377412849323\n",
      "Epoch # 150  Train:  0.6624326720355208  Val:  0.5636363636363636\n",
      "Epoch # 200  Train:  0.8035530326921057  Val:  0.5795269678388186\n",
      "Epoch # 250  Train:  0.7695679576745879  Val:  0.6026563706563707\n",
      "Epoch # 300  Train:  0.9082562544796751  Val:  0.6176353442201047\n",
      "Epoch # 350  Train:  0.9373772652836574  Val:  0.6322845417236662\n",
      "Epoch # 400  Train:  0.9320478877265581  Val:  0.63671875\n",
      "Epoch # 450  Train:  0.9595925994443304  Val:  0.63671875\n",
      "Epoch # 500  Train:  0.9596238478432304  Val:  0.7948717948717949\n",
      "Epoch # 550  Train:  0.9212937342433745  Val:  0.8488558321344228\n",
      "Epoch # 600  Train:  0.9292557111274871  Val:  0.827069516089413\n",
      "Epoch # 650  Train:  0.9358690113650501  Val:  0.8213464696223316\n",
      "Epoch # 700  Train:  0.9542968291724971  Val:  0.8209741114523914\n",
      "Epoch # 750  Train:  0.9647787204769548  Val:  0.8369449086376461\n",
      "Epoch # 800  Train:  0.9700093211518839  Val:  0.8311159978009897\n",
      "Epoch # 850  Train:  0.977844712749981  Val:  0.8420359806932864\n",
      "Epoch # 900  Train:  0.993488689140863  Val:  0.8435972629521018\n",
      "Epoch # 950  Train:  0.9934894839907429  Val:  0.8800488931142196\n",
      "Epoch # 1000  Train:  0.9934894839907429  Val:  0.885104994015885\n",
      "Epoch # 1050  Train:  0.997395762688875  Val:  0.8792617908407382\n",
      "Epoch # 1100  Train:  0.9960936903944457  Val:  0.868215138785932\n",
      "Epoch # 1150  Train:  0.9947916313451561  Val:  0.8518518518518519\n",
      "Epoch # 1200  Train:  0.997395762688875  Val:  0.8184851518184852\n",
      "Epoch # 1250  Train:  0.9359972787958671  Val:  0.7422818791946308\n",
      "Epoch # 1300  Train:  0.9817688551275096  Val:  0.7347761022217105\n",
      "Epoch # 1350  Train:  0.9882810711833371  Val:  0.7285240225075746\n",
      "Epoch # 1400  Train:  0.9934895722954173  Val:  0.7483760683760683\n",
      "Epoch # 1450  Train:  0.9986978614748414  Val:  0.7483760683760683\n",
      "Epoch # 1500  Train:  0.9986978614748414  Val:  0.7361429225836005\n",
      "Epoch # 1550  Train:  0.9986978614748414  Val:  0.7237251064809485\n",
      "Epoch # 1600  Train:  1.0  Val:  0.7237251064809485\n",
      "Epoch # 1650  Train:  1.0  Val:  0.7237251064809485\n",
      "Epoch # 1700  Train:  1.0  Val:  0.7237251064809485\n",
      "Epoch # 1750  Train:  1.0  Val:  0.7237251064809485\n",
      "Epoch # 1800  Train:  1.0  Val:  0.7237251064809485\n",
      "Epoch # 1850  Train:  1.0  Val:  0.7237251064809485\n",
      "Epoch # 1900  Train:  1.0  Val:  0.7237251064809485\n",
      "Epoch # 1950  Train:  1.0  Val:  0.7237251064809485\n",
      "Epoch # 2000  Train:  1.0  Val:  0.7237251064809485\n"
     ]
    }
   ],
   "source": [
    "averaged_perceptron_truthfulness = AveragedPerceptron(\n",
    "    max_iterations=2000,\n",
    "    learning_rate=0.815,\n",
    "    tolerance=1e-8,\n",
    "    shuffle=True,\n",
    "    val_ratio=0.2,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    ")\n",
    "\n",
    "best_epoch, best_val_score = averaged_perceptron_truthfulness.fit(X_train_tf_idf_vectors, y_train_truthfulness)\n",
    "\n",
    "del averaged_perceptron_truthfulness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(941, 0.8853046594982079)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch, best_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_perceptron_truthfulness = AveragedPerceptron(\n",
    "    max_iterations=941,\n",
    "    learning_rate=0.815,\n",
    "    tolerance=1e-8,\n",
    "    shuffle=True,\n",
    "    val_ratio=0.0,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    ")\n",
    "averaged_perceptron_truthfulness.fit(\n",
    "    X_train_tf_idf_vectors,\n",
    "    y_train_truthfulness,\n",
    ")\n",
    "\n",
    "averaged_perceptron_truthfulness_data = averaged_perceptron_truthfulness.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Train ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      1.00      0.96       480\n",
      "           1       1.00      0.92      0.96       480\n",
      "\n",
      "    accuracy                           0.96       960\n",
      "   macro avg       0.96      0.96      0.96       960\n",
      "weighted avg       0.96      0.96      0.96       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.92      0.84       160\n",
      "           1       0.90      0.74      0.82       160\n",
      "\n",
      "    accuracy                           0.83       320\n",
      "   macro avg       0.84      0.83      0.83       320\n",
      "weighted avg       0.84      0.83      0.83       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_dev_truthfulness_pred = averaged_perceptron_truthfulness.predict(X_dev_tf_idf_vectors)\n",
    "\n",
    "calculate_scores(y_train_truthfulness, averaged_perceptron_truthfulness.predict(X_train_tf_idf_vectors), title=\"Train\")\n",
    "calculate_scores(y_dev_truthfulness, y_dev_truthfulness_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging the Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_f1_score = calculate_f1_score(y_dev_truthfulness, y_dev_truthfulness_pred, average=\"macro\")\n",
    "truth_f1_score = calculate_f1_score(y_dev_truthfulness, y_dev_truthfulness_pred, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9072847682119205, 0.9171597633136095, 0.8448275862068966, 0.815068493150685)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_f1_score, pos_f1_score, fake_f1_score, truth_f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8710851527207779"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([neg_f1_score, pos_f1_score, fake_f1_score, truth_f1_score])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Averaged Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_model_file_data = {\n",
    "    \"tf_idf_model\": tf_idf_model_data,\n",
    "    \"sentiment_classifier\": averaged_perceptron_sentiment_data,\n",
    "    \"truthfulness_classifier\": averaged_perceptron_truthfulness_data,\n",
    "}\n",
    "\n",
    "store_model(AVERAGED_MODEL_FILE_PATH, averaged_model_file_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Loaded Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model_data, averaged_perceptron_sentiment_data, averaged_perceptron_truthfulness_data = load_model(\n",
    "    AVERAGED_MODEL_FILE_PATH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_saved_model = TfIdf()\n",
    "tf_idf_saved_model.load(tf_idf_model_data)\n",
    "\n",
    "averaged_perceptron_sentiment_saved = AveragedPerceptron(averaged_perceptron_sentiment_data[\"max_iterations\"])\n",
    "averaged_perceptron_sentiment_saved.load(averaged_perceptron_sentiment_data)\n",
    "\n",
    "averaged_perceptron_truthfulness_saved = AveragedPerceptron(averaged_perceptron_truthfulness_data[\"max_iterations\"])\n",
    "averaged_perceptron_truthfulness_saved.load(averaged_perceptron_truthfulness_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 7675)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev_tf_idf_vectors_saved = tf_idf_saved_model.transform(dev_tokenized)\n",
    "X_dev_tf_idf_vectors_saved.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Train ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00       480\n",
      "           1       1.00      1.00      1.00       480\n",
      "\n",
      "    accuracy                           1.00       960\n",
      "   macro avg       1.00      1.00      1.00       960\n",
      "weighted avg       1.00      1.00      1.00       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.86      0.91       160\n",
      "           1       0.87      0.97      0.92       160\n",
      "\n",
      "    accuracy                           0.91       320\n",
      "   macro avg       0.92      0.91      0.91       320\n",
      "weighted avg       0.92      0.91      0.91       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_pred_sentiment = averaged_perceptron_sentiment_saved.predict(X_dev_tf_idf_vectors_saved)\n",
    "\n",
    "calculate_scores(y_train_sentiment, averaged_perceptron_sentiment_saved.predict(X_train_tf_idf_vectors), title=\"Train\")\n",
    "calculate_scores(y_dev_sentiment, y_dev_sentiment_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Train ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      1.00      0.96       480\n",
      "           1       1.00      0.92      0.96       480\n",
      "\n",
      "    accuracy                           0.96       960\n",
      "   macro avg       0.96      0.96      0.96       960\n",
      "weighted avg       0.96      0.96      0.96       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.92      0.84       160\n",
      "           1       0.90      0.74      0.82       160\n",
      "\n",
      "    accuracy                           0.83       320\n",
      "   macro avg       0.84      0.83      0.83       320\n",
      "weighted avg       0.84      0.83      0.83       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_pred_truthfulness = averaged_perceptron_truthfulness_saved.predict(X_dev_tf_idf_vectors_saved)\n",
    "\n",
    "calculate_scores(\n",
    "    y_train_truthfulness, averaged_perceptron_truthfulness_saved.predict(X_train_tf_idf_vectors), title=\"Train\"\n",
    ")\n",
    "calculate_scores(y_dev_truthfulness, y_dev_truthfulness_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list()\n",
    "for (id, truthfulness, sentiment) in zip(\n",
    "    dev_raw_data[:, 0],\n",
    "    np.where(y_pred_truthfulness == -1, DECEPTIVE, TRUTHFUL),\n",
    "    np.where(y_pred_sentiment == -1, NEGATIVE, POSITIVE),\n",
    "):\n",
    "    output.append((id, truthfulness, sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_predictions(OUTPUT_FILE_PATH, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('csci544')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e78917e7f90f3892e7e12462ef46781cf5994bd706032ea53be00d0b1f29dcb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
