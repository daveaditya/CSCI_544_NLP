{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import json\n",
    "from typing import List, Dict, Tuple, Set, Any, Callable, Optional\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "### Constants                                      ###\n",
    "######################################################\n",
    "# Base Paths\n",
    "INPUT_PATH = \"./data\"\n",
    "MODEL_PATH = \"./model\"\n",
    "OUTPUT_PATH = \"./output\"\n",
    "\n",
    "# Model File names\n",
    "VANILLA_MODEL_FILENAME = \"vanillamodel.txt\"\n",
    "AVERAGED_MODEL_FILENAME = \"averagedmodel.txt\"\n",
    "OUTPUT_FILENAME = \"output.txt\"\n",
    "\n",
    "# Class Identifiers\n",
    "TRUTHFUL = \"True\"\n",
    "DECEPTIVE = \"Fake\"\n",
    "POSITIVE = \"Pos\"\n",
    "NEGATIVE = \"Neg\"\n",
    "\n",
    "TYPE_VANILLA_PERPCETRON = \"vanilla_perceptron\"\n",
    "TYPE_AVERAGED_PERCEPTRON = \"averaged_perceptron\"\n",
    "\n",
    "# File paths\n",
    "TRAIN_FILE_PATH = f\"{INPUT_PATH}/train-labeled.txt\"\n",
    "CLEANED_DATA_FILE_PATH = f\"{INPUT_PATH}/cleaned-data.txt\"\n",
    "PREPROCESSED_DATA_FILE_PATH = f\"{INPUT_PATH}/preprocessed-data.txt\"\n",
    "\n",
    "VANILLA_MODEL_FILE_PATH = f\"{MODEL_PATH}/{VANILLA_MODEL_FILENAME}\"\n",
    "AVERAGED_MODEL_FILE_PATH = f\"{MODEL_PATH}/{AVERAGED_MODEL_FILENAME}\"\n",
    "\n",
    "OUTPUT_FILE_PATH = f\"{OUTPUT_PATH}/{OUTPUT_FILENAME}\"\n",
    "\n",
    "DEV_DATA_FILE_PATH = f\"{INPUT_PATH}/dev-text.txt\"\n",
    "DEV_KEY_FILE_PATH = f\"{INPUT_PATH}/dev-key.txt\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "DATA_ID_COL = 0\n",
    "TRAIN_DATA_COL = 3\n",
    "DEV_DATA_COL = 1\n",
    "SENTIMENT_TARGET_COL = 2\n",
    "TRUTHFULNESS_TARGET_COL = 1\n",
    "\n",
    "VAL_SIZE = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_line = \"07Zfn0z If you're looking for an elegant hotel in downtown Chicago, you have to stay here. The Ambassador East Hotel has very comfortable and beautiful large rooms and is like a home away from home. The perfect place for a business person, and if you have a small pet you can bring them too! I would give this place four stars and would definitely stay here again.\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_regex = re.compile(r\"(\\w*) (.*)\\n?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('07Zfn0z',\n",
       " \"If you're looking for an elegant hotel in downtown Chicago, you have to stay here. The Ambassador East Hotel has very comfortable and beautiful large rooms and is like a home away from home. The perfect place for a business person, and if you have a small pet you can bring them too! I would give this place four stars and would definitely stay here again.\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(dev_regex, dev_line).groups()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"07Zfn0z Fake Pos If you're looking for an elegant hotel in downtown Chicago, you have to stay here. The Ambassador East Hotel has very comfortable and beautiful large rooms and is like a home away from home. The perfect place for a business person, and if you have a small pet you can bring them too! I would give this place four stars and would definitely stay here again.\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_regex = re.compile(r\"(\\w*) (\\w*) (\\w*) (.*)\\n?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('07Zfn0z',\n",
       " 'Fake',\n",
       " 'Pos',\n",
       " \"If you're looking for an elegant hotel in downtown Chicago, you have to stay here. The Ambassador East Hotel has very comfortable and beautiful large rooms and is like a home away from home. The perfect place for a business person, and if you have a small pet you can bring them too! I would give this place four stars and would definitely stay here again.\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(input_regex, line).groups()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('07Zfn0z',\n",
       "  'Fake',\n",
       "  'Pos',\n",
       "  \"If you're looking for an elegant hotel in downtown Chicago, you have to stay here. The Ambassador East Hotel has very comfortable and beautiful large rooms and is like a home away from home. The perfect place for a business person, and if you have a small pet you can bring them too! I would give this place four stars and would definitely stay here again.\")]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "data.append(re.match(input_regex, line).groups())\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fake'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data)[0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_data(input_file_path: str, type: str = \"TRAIN\") -> npt.NDArray:\n",
    "    input_data = list()\n",
    "    regex = r\"(\\w*) (\\w*) (\\w*) (.*)\\n?\"\n",
    "    if type == \"DEV\":\n",
    "        regex = r\"(\\w*) (.*)\\n?\"\n",
    "    elif type == \"KEY\":\n",
    "        regex = r\"(\\w*) (\\w*) (\\w*)\\n?\"\n",
    "    input_regex = re.compile(regex)\n",
    "    with open(input_file_path, mode=\"r\") as input_file:\n",
    "        for line in input_file:\n",
    "            input_data.append(re.match(input_regex, line).groups())\n",
    "    return np.array(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Data\n",
    "def store_data(date_file_path: str, data: npt.NDArray) -> None:\n",
    "    with open(date_file_path, mode=\"w\") as data_file:\n",
    "        for row in data:\n",
    "            data_file.write(f\"{row[0]} {row[1]} {row[2]} {row[3]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Model\n",
    "def store_model(model_file_path: str, model_data: Any) -> None:\n",
    "    with open(model_file_path, mode=\"w\") as model_file:\n",
    "        json.dump(model_data, model_file, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "def load_model(model_file_path: str) -> npt.NDArray:\n",
    "    with open(model_file_path, mode=\"r\") as model_file:\n",
    "        model_data = json.load(model_file)\n",
    "\n",
    "    return (model_data[\"tf_idf_model\"], model_data[\"sentiment_classifier\"], model_data[\"truthfulness_classifier\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Predictions\n",
    "def store_predictions(output_file_path: str, predictions: List[Tuple[str, str, str]]) -> None:\n",
    "    with open(output_file_path, mode=\"w\") as output_file:\n",
    "        for prediction in predictions:\n",
    "            output_file.write(f\"{prediction[0]} {prediction[1]} {prediction[2]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_score(y_true: npt.NDArray, y_pred: npt.NDArray):\n",
    "    return (y_true == y_pred).sum() / y_true.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_score(y_true: npt.NDArray, y_pred: npt.NDArray, average: str = \"macro\"):\n",
    "    def calculate_f1(y_true, y_pred, label):\n",
    "        tp = np.sum((y_true == label) & (y_pred == label))\n",
    "        fp = np.sum((y_true != label) & (y_pred == label))\n",
    "        fn = np.sum((y_pred != label) & (y_true == label))\n",
    "\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "\n",
    "    def macro_f1(y_true, y_pred):\n",
    "        return np.mean([calculate_f1(y_true, y_pred, label) for label in np.unique(y_true)])\n",
    "\n",
    "    def micro_f1(y_true, y_pred):\n",
    "        return {label: calculate_f1(y_true, y_pred, label) for label in np.unique(y_true)}\n",
    "\n",
    "    if average == \"macro\":\n",
    "        return macro_f1(y_true, y_pred)\n",
    "    elif average == \"micro\":\n",
    "        return micro_f1(y_true, y_pred)\n",
    "    else:\n",
    "        return {\"micro\": micro_f1(y_true, y_pred), \"macro\": macro_f1(y_true, y_pred)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Scores\n",
    "def calculate_scores(y_true, y_pred, title: str):\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    print(f\"------------------------ {title} ------------------------\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"---------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler\n",
    "def learning_rate_scheduler(learning_rate: float, epoch: int, decay: float = 1e-2):\n",
    "    return learning_rate * 1 / (1 + decay * epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(TRAIN_FILE_PATH, type=\"TRAIN\")\n",
    "\n",
    "dev_raw_data = load_data(DEV_DATA_FILE_PATH, type=\"DEV\")\n",
    "dev_key_data = load_data(DEV_KEY_FILE_PATH, type=\"KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all reviews to lower case (optional according to study)\n",
    "def to_lower(data: npt.NDArray):\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = result[i].lower()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_encodings(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"&#\\d+;\", \" \", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"<[a-zA-Z]+\\s?/?>\", \"\", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"https?://([\\w\\-\\._]+){2,}/[\\w\\-\\.\\-/=\\+_\\?]+\", \"\", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_and_url(data):\n",
    "    \"\"\"Function to remove\n",
    "             1. HTML encodings\n",
    "             2. HTML tags (both closed and open)\n",
    "             3. URLs\n",
    "\n",
    "    Args:\n",
    "        data (npt.NDArray): A Numpy Array of type string\n",
    "\n",
    "    Returns:\n",
    "        _type_: npt.NDArray\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        # Remove HTML encodings\n",
    "        result[i] = re.sub(r\"&#\\d+;\", \"\", result[i])\n",
    "\n",
    "        # Remove HTML tags (both open and closed)\n",
    "        result[i] = re.sub(r\"<[a-zA-Z]+\\s?/?>\", \"\", result[i])\n",
    "\n",
    "        # Remove URLs\n",
    "        result[i] = re.sub(r\"https?://([\\w\\-\\._]+){2,}/[\\w\\-\\.\\-/=\\+_\\?]+\", \"\", result[i])\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_digits_with_tag(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"\\d+\", \" NUM \", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-alphabetical characters\n",
    "def remove_non_alpha_characters(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"_+|\\\\|[^a-zA-Z0-9\\s]\", \" \", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "def remove_extra_spaces(data: npt.NDArray):\n",
    "    import re\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = re.sub(r\"^\\s*|\\s\\s*\", \" \", result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding contractions\n",
    "def fix_contractions(data: npt.NDArray):\n",
    "    from contractions import fix\n",
    "\n",
    "    def contraction_fixer(txt: str):\n",
    "        return \" \".join([fix(word) for word in txt.split()])\n",
    "\n",
    "    n_data = data.shape[0]\n",
    "    result = data.copy()\n",
    "    for i in range(n_data):\n",
    "        result[i] = contraction_fixer(result[i])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: to_lower\n",
      "Ended: to_lower\n",
      "Starting: remove_html_encodings\n",
      "Ended: remove_html_encodings\n",
      "Starting: remove_html_tags\n",
      "Ended: remove_html_tags\n",
      "Starting: remove_url\n",
      "Ended: remove_url\n",
      "Starting: fix_contractions\n",
      "Ended: fix_contractions\n",
      "Starting: remove_non_alpha_characters\n",
      "Ended: remove_non_alpha_characters\n",
      "Starting: remove_extra_spaces\n",
      "Ended: remove_extra_spaces\n"
     ]
    }
   ],
   "source": [
    "# A dictionary containing the columns and a list of functions to perform on it in order\n",
    "data_cleaning_pipeline = {\n",
    "    TRAIN_DATA_COL: [\n",
    "        to_lower,\n",
    "        remove_html_encodings,\n",
    "        remove_html_tags,\n",
    "        remove_url,\n",
    "        fix_contractions,\n",
    "        remove_non_alpha_characters,\n",
    "        remove_extra_spaces,\n",
    "    ]\n",
    "}\n",
    "\n",
    "cleaned_data = data.copy()\n",
    "\n",
    "# Process all the cleaning instructions\n",
    "for col, pipeline in data_cleaning_pipeline.items():\n",
    "    # Get the column to perform cleaning on\n",
    "    temp_data = cleaned_data[:, col].copy()\n",
    "\n",
    "    # Perform all the cleaning functions sequencially\n",
    "    for func in pipeline:\n",
    "        print(f\"Starting: {func.__name__}\")\n",
    "        temp_data = func(temp_data)\n",
    "        print(f\"Ended: {func.__name__}\")\n",
    "\n",
    "    # Replace the old column with cleaned one.\n",
    "    cleaned_data[:, col] = temp_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data(CLEANED_DATA_FILE_PATH, cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: to_lower\n",
      "Ended: to_lower\n",
      "Starting: remove_html_encodings\n",
      "Ended: remove_html_encodings\n",
      "Starting: remove_html_tags\n",
      "Ended: remove_html_tags\n",
      "Starting: remove_url\n",
      "Ended: remove_url\n",
      "Starting: fix_contractions\n",
      "Ended: fix_contractions\n",
      "Starting: remove_non_alpha_characters\n",
      "Ended: remove_non_alpha_characters\n",
      "Starting: remove_extra_spaces\n",
      "Ended: remove_extra_spaces\n"
     ]
    }
   ],
   "source": [
    "# A dictionary containing the columns and a list of functions to perform on it in order\n",
    "data_cleaning_pipeline = {\n",
    "    DEV_DATA_COL: [\n",
    "        to_lower,\n",
    "        remove_html_encodings,\n",
    "        remove_html_tags,\n",
    "        remove_url,\n",
    "        fix_contractions,\n",
    "        remove_non_alpha_characters,\n",
    "        remove_extra_spaces,\n",
    "    ]\n",
    "}\n",
    "\n",
    "dev_cleaned_data = dev_raw_data.copy()\n",
    "\n",
    "# Process all the cleaning instructions\n",
    "for col, pipeline in data_cleaning_pipeline.items():\n",
    "    # Get the column to perform cleaning on\n",
    "    temp_data = dev_cleaned_data[:, col].copy()\n",
    "\n",
    "    # Perform all the cleaning functions sequencially\n",
    "    for func in pipeline:\n",
    "        print(f\"Starting: {func.__name__}\")\n",
    "        temp_data = func(temp_data)\n",
    "        print(f\"Ended: {func.__name__}\")\n",
    "\n",
    "    # Replace the old column with cleaned one.\n",
    "    dev_cleaned_data[:, col] = temp_data.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not Applicable since everything has to be implemented from scratch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIdf:\n",
    "    # Implement low frequency terms and other techniques\n",
    "    def __init__(self) -> None:\n",
    "        self.n_docs: int = None\n",
    "        self.vocab: List = list()\n",
    "        self.vocab_size: int = None\n",
    "        self.vocab_index: Dict[str, int] = dict()\n",
    "        self.word_document_count: Dict[str, int] = dict()\n",
    "\n",
    "    def __create_vocab__(self, documents: npt.NDArray) -> Set:\n",
    "        vocab = set()\n",
    "\n",
    "        for document in documents:\n",
    "            for word in document:\n",
    "                vocab.add(word)\n",
    "\n",
    "        return list(vocab)\n",
    "\n",
    "    def __get_word_document_count__(self, documents: npt.NDArray):\n",
    "        word_document_count = dict()\n",
    "\n",
    "        for document in documents:\n",
    "            for word in document:\n",
    "                if word in self.vocab:\n",
    "                    if word not in word_document_count:\n",
    "                        word_document_count[word] = 1\n",
    "                    else:\n",
    "                        word_document_count[word] += 1\n",
    "\n",
    "        return word_document_count\n",
    "\n",
    "    def __term_frequency__(self, word: str, document: npt.NDArray):\n",
    "        word_occurences = (document == word).sum()\n",
    "        return word_occurences / self.n_docs\n",
    "\n",
    "    def __inverse_document_frequency__(self, word: str):\n",
    "        word_occurrences = 1\n",
    "\n",
    "        if word in self.word_document_count:\n",
    "            word_occurrences += self.word_document_count[word]\n",
    "\n",
    "        return np.log(self.n_docs / word_occurrences)\n",
    "\n",
    "    def __tf_idf__(self, document: npt.NDArray):\n",
    "        tf_idf_vector = np.zeros(shape=(self.vocab_size,))\n",
    "        for word in document:\n",
    "            # ignore word not in vocab\n",
    "            if word in self.vocab:\n",
    "                tf = self.__term_frequency__(word, document)\n",
    "                idf = self.__inverse_document_frequency__(word)\n",
    "\n",
    "                tf_idf_vector[self.vocab_index[word]] = tf * idf\n",
    "        return tf_idf_vector\n",
    "\n",
    "    def fit(self, documents: npt.NDArray):\n",
    "        self.n_docs = documents.shape[0]\n",
    "        self.vocab = self.__create_vocab__(documents)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.vocab_index = {word: idx for idx, word in enumerate(self.vocab)}\n",
    "        self.word_document_count = self.__get_word_document_count__(documents)\n",
    "\n",
    "    def transform(self, documents: npt.NDArray):\n",
    "        tf_idf_vectors = list()\n",
    "        for document in documents:\n",
    "            tf_idf_vectors.append(self.__tf_idf__(document))\n",
    "        return np.array(tf_idf_vectors)\n",
    "\n",
    "    def export(self):\n",
    "        return {\n",
    "            \"n_docs\": self.n_docs,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"vocab\": self.vocab,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"vocab_index\": self.vocab_index,\n",
    "            \"word_document_count\": self.word_document_count,\n",
    "        }\n",
    "\n",
    "    def load(self, tf_idf_model_data):\n",
    "        self.n_docs = tf_idf_model_data[\"n_docs\"]\n",
    "        self.vocab_size = tf_idf_model_data[\"vocab_size\"]\n",
    "        self.vocab = tf_idf_model_data[\"vocab\"]\n",
    "        self.vocab_size = tf_idf_model_data[\"vocab_size\"]\n",
    "        self.vocab_index = tf_idf_model_data[\"vocab_index\"]\n",
    "        self.word_document_count = tf_idf_model_data[\"word_document_count\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data: npt.NDArray):\n",
    "    tokenized_documents = list()\n",
    "    for document in data:\n",
    "        tokenized_documents.append(np.array(document.split()))\n",
    "    return np.array(tokenized_documents, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = load_data(CLEANED_DATA_FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = tokenize(final_data[:, TRAIN_DATA_COL])\n",
    "dev_tokenized = tokenize(dev_cleaned_data[:, DEV_DATA_COL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model = TfIdf()\n",
    "tf_idf_model.fit(train_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = tf_idf_model.transform(train_tokenized)\n",
    "X_dev = tf_idf_model.transform(dev_tokenized)\n",
    "\n",
    "tf_idf_model_data = tf_idf_model.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_sentiment = np.where(final_data[:, SENTIMENT_TARGET_COL] == POSITIVE, 1, -1)\n",
    "y_all_truthfulness = np.where(final_data[:, TRUTHFULNESS_TARGET_COL] == TRUTHFUL, 1, -1)\n",
    "\n",
    "y_dev_sentiment = np.where(dev_key_data[:, SENTIMENT_TARGET_COL] == POSITIVE, 1, -1)\n",
    "y_dev_truthfulness = np.where(dev_key_data[:, TRUTHFULNESS_TARGET_COL] == TRUTHFUL, 1, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(\n",
    "    X: npt.NDArray,\n",
    "    y_sentiment: npt.NDArray,\n",
    "    y_truthfulness: npt.NDArray,\n",
    "    test_size: float = 0.2,\n",
    "    rng=np.random.default_rng(seed=RANDOM_SEED),\n",
    "):\n",
    "    n_max = X.shape[0]\n",
    "    sample = int((1 - test_size) * n_max)\n",
    "\n",
    "    # Shuffle the data\n",
    "    all_idx = np.arange(n_max)\n",
    "    rng.shuffle(all_idx)\n",
    "\n",
    "    train_idx, test_idx = all_idx[:sample], all_idx[sample:]\n",
    "\n",
    "    X_train, X_test, y_train_sentiment, y_test_sentiment, y_train_truthfulness, y_test_truthfulness = (\n",
    "        X[train_idx],\n",
    "        X[test_idx],\n",
    "        y_sentiment[train_idx],\n",
    "        y_sentiment[test_idx],\n",
    "        y_truthfulness[train_idx],\n",
    "        y_truthfulness[test_idx],\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train_sentiment, y_test_sentiment, y_train_truthfulness, y_test_truthfulness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train_sentiment, y_val_sentiment, y_train_truthfulness, y_val_truthfulness = train_test_split(\n",
    "    X_all, y_all_sentiment, y_all_truthfulness, VAL_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaPerceptron:\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_iterations: int = 1000,\n",
    "        learning_rate: float = 1e-2,\n",
    "        shuffle: bool = True,\n",
    "        class_weights: dict = None,\n",
    "        lr_scheduler_func: Optional[Callable[[float, int], float]] = None,\n",
    "        score_func: Callable[[npt.NDArray, npt.NDArray], float] = calculate_f1_score,\n",
    "        rng=np.random.default_rng(seed=RANDOM_SEED),\n",
    "        debug: bool = False,\n",
    "        debug_at: int = 50,\n",
    "    ) -> None:\n",
    "        self.type = TYPE_VANILLA_PERPCETRON\n",
    "        self.max_iterations = max_iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.shuffle = shuffle\n",
    "        self.class_weights = class_weights\n",
    "        self.learning_rate_scheduler = lr_scheduler_func\n",
    "        self.calculate_score = score_func\n",
    "        self.rng = rng\n",
    "        self.debug = debug\n",
    "        self.debug_at = debug_at\n",
    "\n",
    "        self.best_epoch = 0\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X_train: npt.NDArray,\n",
    "        y_train: npt.NDArray,\n",
    "        X_val: npt.NDArray = None,\n",
    "        y_val: npt.NDArray = None,\n",
    "    ):\n",
    "        n_epoch = 0\n",
    "\n",
    "        self.weights: npt.NDArray = self.rng.random(size=(X_train.shape[-1],))\n",
    "        self.bias: float = 0.0\n",
    "\n",
    "        learning_rate = self.learning_rate\n",
    "\n",
    "        best_epoch = 0\n",
    "        best_val_score = -1\n",
    "        best_weights = self.weights.copy()\n",
    "        best_bias = self.bias\n",
    "\n",
    "        for n_epoch in range(1, self.max_iterations + 1):\n",
    "\n",
    "            if self.shuffle:\n",
    "                idxs = np.arange(X_train.shape[0])\n",
    "                self.rng.shuffle(idxs)\n",
    "\n",
    "                X_train = X_train[idxs]\n",
    "                y_train = y_train[idxs]\n",
    "\n",
    "            for x, y_true in zip(X_train, y_train):\n",
    "\n",
    "                if y_true * self._activation(x) <= 0:\n",
    "                    if self.class_weights is None:\n",
    "                        self.weights = self.weights + y_true * x * self.learning_rate\n",
    "                    else:\n",
    "                        self.weights = self.weights + y_true * x * self.class_weights[y_true] * self.learning_rate\n",
    "                    self.bias = self.bias + y_true\n",
    "\n",
    "            if X_val is not None and y_val is not None:\n",
    "                train_score = self.calculate_score(y_train, self.predict(X_train))\n",
    "                val_score = self.calculate_score(y_val, self.predict(X_val))\n",
    "\n",
    "                if val_score > best_val_score:\n",
    "                    best_val_score = val_score\n",
    "\n",
    "                    # Record the current best wegiths and bias\n",
    "                    best_epoch = n_epoch\n",
    "                    best_weights = self.weights\n",
    "                    best_bias = self.bias\n",
    "\n",
    "                if self.debug and (n_epoch == self.max_iterations or n_epoch % self.debug_at == 0):\n",
    "                    print(\"Epoch #\", n_epoch, \" Train: \", train_score, \" Val: \", val_score)\n",
    "\n",
    "            # Update learning rate\n",
    "            if self.learning_rate_scheduler:\n",
    "                learning_rate = self.learning_rate_scheduler(learning_rate, n_epoch)\n",
    "\n",
    "        # Set the best weights and bias found\n",
    "        self.best_epoch = best_epoch\n",
    "        self.weights = best_weights\n",
    "        self.bias = best_bias\n",
    "\n",
    "    def _activation(self, x: npt.NDArray):\n",
    "        return np.dot(self.weights, x) + self.bias\n",
    "\n",
    "    def predict(self, X: npt.NDArray):\n",
    "        predictions = list()\n",
    "        for x in X:\n",
    "            pred = np.sign(self._activation(x))\n",
    "            predictions.append(pred)\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def export(\n",
    "        self,\n",
    "    ):\n",
    "        return {\n",
    "            \"type\": self.type,\n",
    "            \"max_iterations\": self.best_epoch,\n",
    "            \"weights\": self.weights.tolist(),\n",
    "            \"bias\": float(self.bias),\n",
    "            \"best_epoch\": self.best_epoch,\n",
    "        }\n",
    "\n",
    "    def load(self, model_data: Dict[str, Any]):\n",
    "        self.type = model_data[\"type\"]\n",
    "        self.max_iterations = (model_data[\"max_iterations\"],)\n",
    "        self.weights = np.array(model_data[\"weights\"])\n",
    "        self.bias = model_data[\"bias\"]\n",
    "        self.best_epoch = model_data[\"best_epoch\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/gcxbjppx70qfkdwy32kg04dh0000gn/T/ipykernel_38168/2355303260.py:7: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp / (tp + fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 50  Train:  0.5617643363836851  Val:  0.5095361567271679\n",
      "Epoch # 100  Train:  0.5708063957080639  Val:  0.5186511036742499\n",
      "Epoch # 150  Train:  0.6962993540010654  Val:  0.5826587515740241\n",
      "Epoch # 200  Train:  0.5134502923976608  Val:  0.49220785372554593\n",
      "Epoch # 250  Train:  0.885136077085284  Val:  0.7780588307290605\n",
      "Epoch # 300  Train:  0.9193505273528491  Val:  0.8026668284151679\n",
      "Epoch # 350  Train:  0.9383537714235337  Val:  0.8130238555770471\n",
      "Epoch # 400  Train:  0.9614181019922032  Val:  0.8266730861819933\n",
      "Epoch # 450  Train:  0.9645487129358097  Val:  0.8232772037633922\n",
      "Epoch # 500  Train:  0.9729024357409926  Val:  0.8164528301886793\n",
      "Epoch # 550  Train:  0.9718559135698579  Val:  0.81259340037966\n",
      "Epoch # 600  Train:  0.9812447902195054  Val:  0.802186888801062\n",
      "Epoch # 650  Train:  0.960360924216346  Val:  0.7951864758053866\n",
      "Epoch # 700  Train:  0.9540787705634483  Val:  0.7951864758053866\n",
      "Epoch # 750  Train:  0.9895826099034655  Val:  0.7986931287795771\n",
      "Epoch # 800  Train:  0.9927081355288501  Val:  0.802186888801062\n",
      "Epoch # 850  Train:  0.9927081355288501  Val:  0.805668016194332\n",
      "Epoch # 900  Train:  0.9937498914911718  Val:  0.802186888801062\n",
      "Epoch # 950  Train:  0.9947916158035397  Val:  0.802186888801062\n",
      "Epoch # 1000  Train:  0.9947916158035397  Val:  0.802186888801062\n",
      "Epoch # 1050  Train:  0.9958333152487642  Val:  0.81259340037966\n",
      "Epoch # 1100  Train:  0.9968749694821238  Val:  0.8300584174190123\n",
      "Epoch # 1150  Train:  0.9968749694821238  Val:  0.8600898286895345\n",
      "Epoch # 1200  Train:  0.9958332609941145  Val:  0.9088184721198724\n",
      "Epoch # 1250  Train:  0.9916660879227723  Val:  0.9280681007437523\n",
      "Epoch # 1300  Train:  0.9895822029300054  Val:  0.9406197810354425\n",
      "Epoch # 1350  Train:  0.988540162065549  Val:  0.9468495666871843\n",
      "Epoch # 1400  Train:  0.986455849651249  Val:  0.9437148217636022\n",
      "Epoch # 1450  Train:  0.9874980465697765  Val:  0.9374389051808407\n",
      "Epoch # 1500  Train:  0.99479152537775  Val:  0.9374389051808407\n",
      "Epoch # 1550  Train:  0.988540162065549  Val:  0.9311181558451723\n",
      "Epoch # 1600  Train:  0.9958332609941145  Val:  0.9184921039225675\n",
      "Epoch # 1650  Train:  0.9968749694821238  Val:  0.9184921039225675\n",
      "Epoch # 1700  Train:  0.9968749694821238  Val:  0.915326492811572\n",
      "Epoch # 1750  Train:  0.9895822029300054  Val:  0.9120844617135682\n",
      "Epoch # 1800  Train:  0.9958332609941145  Val:  0.9057196731615336\n",
      "Epoch # 1850  Train:  0.9979166576243821  Val:  0.9057196731615336\n",
      "Epoch # 1900  Train:  0.9958332609941145  Val:  0.9025300908867601\n",
      "Epoch # 1950  Train:  0.99479152537775  Val:  0.8929302472051646\n",
      "Epoch # 2000  Train:  0.9958332609941145  Val:  0.8929302472051646\n"
     ]
    }
   ],
   "source": [
    "vanilla_perceptron_sentiment = VanillaPerceptron(\n",
    "    max_iterations=2000,\n",
    "    learning_rate=0.815,\n",
    "    shuffle=True,\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    "    rng=rng,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    ")\n",
    "\n",
    "vanilla_perceptron_sentiment.fit(X_all, y_all_sentiment, X_dev, y_dev_sentiment)\n",
    "\n",
    "# Export the model\n",
    "vanilla_perceptron_sentiment_data = vanilla_perceptron_sentiment.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1327"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_perceptron_sentiment_data[\"best_epoch\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Whole ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.97      0.99       480\n",
      "           1       0.98      1.00      0.99       480\n",
      "\n",
      "    accuracy                           0.99       960\n",
      "   macro avg       0.99      0.99      0.99       960\n",
      "weighted avg       0.99      0.99      0.99       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.93      0.95       160\n",
      "           1       0.93      0.97      0.95       160\n",
      "\n",
      "    accuracy                           0.95       320\n",
      "   macro avg       0.95      0.95      0.95       320\n",
      "weighted avg       0.95      0.95      0.95       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Classify and predict with the best model\n",
    "y_dev_sentiment_pred = vanilla_perceptron_sentiment.predict(X_dev)\n",
    "\n",
    "calculate_scores(y_all_sentiment, vanilla_perceptron_sentiment.predict(X_all), title=\"Whole\")\n",
    "calculate_scores(y_dev_sentiment, y_dev_sentiment_pred, title=\"Dev\")\n",
    "\n",
    "del vanilla_perceptron_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Whole ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.97      0.99       480\n",
      "           1       0.98      1.00      0.99       480\n",
      "\n",
      "    accuracy                           0.99       960\n",
      "   macro avg       0.99      0.99      0.99       960\n",
      "weighted avg       0.99      0.99      0.99       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.93      0.95       160\n",
      "           1       0.93      0.97      0.95       160\n",
      "\n",
      "    accuracy                           0.95       320\n",
      "   macro avg       0.95      0.95      0.95       320\n",
      "weighted avg       0.95      0.95      0.95       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vanilla_perceptron_sentiment = VanillaPerceptron()\n",
    "vanilla_perceptron_sentiment.load(vanilla_perceptron_sentiment_data)\n",
    "\n",
    "y_dev_sentiment_pred = vanilla_perceptron_sentiment.predict(X_dev)\n",
    "\n",
    "calculate_scores(y_all_sentiment, vanilla_perceptron_sentiment.predict(X_all), title=\"Whole\")\n",
    "calculate_scores(y_dev_sentiment, y_dev_sentiment_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truthfulness Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/gcxbjppx70qfkdwy32kg04dh0000gn/T/ipykernel_38168/2355303260.py:7: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp / (tp + fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 50  Train:  nan  Val:  nan\n",
      "Epoch # 100  Train:  0.3379463177880759  Val:  nan\n",
      "Epoch # 150  Train:  0.4679020201044777  Val:  0.4791802791802792\n",
      "Epoch # 200  Train:  0.4642054621453258  Val:  0.4791802791802792\n",
      "Epoch # 250  Train:  0.3583024888867352  Val:  nan\n",
      "Epoch # 300  Train:  0.3515889733492078  Val:  nan\n",
      "Epoch # 350  Train:  0.6064952751290577  Val:  0.534324116831479\n",
      "Epoch # 400  Train:  0.6226415094339623  Val:  0.5392842451665981\n",
      "Epoch # 450  Train:  0.6643771761258777  Val:  0.558750395587504\n",
      "Epoch # 500  Train:  0.6948022772517659  Val:  0.568267674042094\n",
      "Epoch # 550  Train:  0.3627391753647064  Val:  nan\n",
      "Epoch # 600  Train:  0.3560724989296418  Val:  nan\n",
      "Epoch # 650  Train:  0.3605246976839517  Val:  nan\n",
      "Epoch # 700  Train:  0.7835954376517205  Val:  0.5822873782508284\n",
      "Epoch # 750  Train:  0.8079818769411944  Val:  0.5776475325488791\n",
      "Epoch # 800  Train:  0.37152076195754996  Val:  nan\n",
      "Epoch # 850  Train:  0.8387181116133863  Val:  0.5914697099212913\n",
      "Epoch # 900  Train:  0.375866440833814  Val:  nan\n",
      "Epoch # 950  Train:  0.8609524799350758  Val:  0.6005258564500271\n",
      "Epoch # 1000  Train:  0.891458861832883  Val:  0.6094600389220569\n"
     ]
    }
   ],
   "source": [
    "vanilla_perceptron_truthfulness = VanillaPerceptron(\n",
    "    max_iterations=1000,\n",
    "    learning_rate=20e-2,\n",
    "    shuffle=True,\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    "    rng=rng,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    ")\n",
    "\n",
    "vanilla_perceptron_truthfulness.fit(X_all, y_all_truthfulness, X_dev, y_dev_truthfulness)\n",
    "\n",
    "# Export the model\n",
    "vanilla_perceptron_truthfulness_data = vanilla_perceptron_truthfulness.export()\n",
    "\n",
    "del vanilla_perceptron_truthfulness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_perceptron_truthfulness_data[\"best_epoch\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Whole ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.79      0.88       480\n",
      "           1       0.82      1.00      0.90       480\n",
      "\n",
      "    accuracy                           0.89       960\n",
      "   macro avg       0.91      0.89      0.89       960\n",
      "weighted avg       0.91      0.89      0.89       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.32      0.48       160\n",
      "           1       0.59      0.99      0.74       160\n",
      "\n",
      "    accuracy                           0.65       320\n",
      "   macro avg       0.78      0.65      0.61       320\n",
      "weighted avg       0.78      0.65      0.61       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vanilla_perceptron_truthfulness = VanillaPerceptron()\n",
    "vanilla_perceptron_truthfulness.load(vanilla_perceptron_truthfulness_data)\n",
    "\n",
    "y_dev_truthfulness_pred = vanilla_perceptron_truthfulness.predict(X_dev)\n",
    "\n",
    "calculate_scores(y_all_truthfulness, vanilla_perceptron_truthfulness.predict(X_all), title=\"Whole\")\n",
    "calculate_scores(y_dev_truthfulness, y_dev_truthfulness_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging the Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_f1_score = calculate_f1_score(y_dev_sentiment, y_dev_sentiment_pred, average=\"macro\")\n",
    "truthfulness_f1_score = calculate_f1_score(y_dev_truthfulness, y_dev_truthfulness_pred, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.779721227307537"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([sentiment_f1_score, truthfulness_f1_score])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Vanilla Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_model_file_data = {\n",
    "    \"tf_idf_model\": tf_idf_model_data,\n",
    "    \"sentiment_classifier\": vanilla_perceptron_sentiment_data,\n",
    "    \"truthfulness_classifier\": vanilla_perceptron_truthfulness_data,\n",
    "}\n",
    "\n",
    "store_model(VANILLA_MODEL_FILE_PATH, vanilla_model_file_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Vanilla Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model_data, vanilla_perceptron_sentiment_data, vanilla_perceptron_truthfulness_data = load_model(\n",
    "    # VANILLA_MODEL_FILE_PATH\n",
    "    f\"{MODEL_PATH}/py-vanillamodel.txt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_saved_model = TfIdf()\n",
    "tf_idf_saved_model.load(tf_idf_model_data)\n",
    "\n",
    "vanilla_perceptron_sentiment_saved = VanillaPerceptron()\n",
    "vanilla_perceptron_sentiment_saved.load(vanilla_perceptron_sentiment_data)\n",
    "\n",
    "vanilla_perceptron_truthfulness_saved = VanillaPerceptron()\n",
    "vanilla_perceptron_truthfulness_saved.load(vanilla_perceptron_truthfulness_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Loaded Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 7675)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev_tf_idf_vectors_saved = tf_idf_saved_model.transform(dev_tokenized)\n",
    "X_dev_tf_idf_vectors_saved.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Train ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       480\n",
      "           1       0.50      0.99      0.66       480\n",
      "\n",
      "    accuracy                           0.49       960\n",
      "   macro avg       0.25      0.49      0.33       960\n",
      "weighted avg       0.25      0.49      0.33       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.93      0.95       160\n",
      "           1       0.93      0.97      0.95       160\n",
      "\n",
      "    accuracy                           0.95       320\n",
      "   macro avg       0.95      0.95      0.95       320\n",
      "weighted avg       0.95      0.95      0.95       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_pred_sentiment = vanilla_perceptron_sentiment_saved.predict(X_dev_tf_idf_vectors_saved)\n",
    "\n",
    "calculate_scores(y_all_sentiment, vanilla_perceptron_sentiment_saved.predict(X_all), title=\"Train\")\n",
    "calculate_scores(y_dev_sentiment, y_dev_sentiment_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Train ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       480\n",
      "           1       0.50      1.00      0.67       480\n",
      "\n",
      "    accuracy                           0.50       960\n",
      "   macro avg       0.25      0.50      0.33       960\n",
      "weighted avg       0.25      0.50      0.33       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.32      0.48       160\n",
      "           1       0.59      0.99      0.74       160\n",
      "\n",
      "    accuracy                           0.65       320\n",
      "   macro avg       0.78      0.65      0.61       320\n",
      "weighted avg       0.78      0.65      0.61       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aditya/.pyenv/versions/3.10.6/envs/csci544/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_truthfulness = vanilla_perceptron_truthfulness_saved.predict(X_dev_tf_idf_vectors_saved)\n",
    "\n",
    "calculate_scores(y_all_truthfulness, vanilla_perceptron_truthfulness_saved.predict(X_all), title=\"Train\")\n",
    "calculate_scores(y_dev_truthfulness, y_dev_truthfulness_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list()\n",
    "for (id, truthfulness, sentiment) in zip(\n",
    "    dev_raw_data[:, 0],\n",
    "    np.where(y_pred_truthfulness == -1, DECEPTIVE, TRUTHFUL),\n",
    "    np.where(y_pred_sentiment == -1, NEGATIVE, POSITIVE),\n",
    "):\n",
    "    output.append((id, truthfulness, sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_predictions(OUTPUT_FILE_PATH, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------- **\\*\\*\\*\\***\\*\\***\\*\\*\\*\\***\\*\\*\\***\\*\\*\\*\\***\\*\\***\\*\\*\\*\\*** -------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaged Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragedPerceptron:\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_iterations: int = 1000,\n",
    "        learning_rate: float = 1e-2,\n",
    "        shuffle: bool = True,\n",
    "        class_weights: dict = None,\n",
    "        lr_scheduler_func: Optional[Callable[[float, int], float]] = None,\n",
    "        score_func: Callable[[npt.NDArray, npt.NDArray], float] = calculate_f1_score,\n",
    "        rng=np.random.default_rng(seed=RANDOM_SEED),\n",
    "        debug: bool = False,\n",
    "        debug_at: int = 50,\n",
    "    ) -> None:\n",
    "        self.type = TYPE_AVERAGED_PERCEPTRON\n",
    "        self.max_iterations = max_iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.shuffle = shuffle\n",
    "        self.class_weights = class_weights\n",
    "        self.learning_rate_scheduler = lr_scheduler_func\n",
    "        self.calculate_score = score_func\n",
    "        self.rng = rng\n",
    "        self.debug = debug\n",
    "        self.debug_at = debug_at\n",
    "\n",
    "        self.best_epoch = 0\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X_train: npt.NDArray,\n",
    "        y_train: npt.NDArray,\n",
    "        X_val: npt.NDArray = None,\n",
    "        y_val: npt.NDArray = None,\n",
    "    ):\n",
    "        n_epoch = 0\n",
    "\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        current_weights: npt.NDArray = rng.random(size=(X_train.shape[-1],))\n",
    "        current_bias: float = 0.0\n",
    "        self.cache = {\"weights\": rng.random(size=(X_train.shape[-1],)), \"bias\": 0.0}\n",
    "\n",
    "        c = 1\n",
    "\n",
    "        best_val_score = -1\n",
    "        best_epoch = 0\n",
    "        best_weights = current_weights\n",
    "        best_bias = current_bias\n",
    "        best_cache = self.cache\n",
    "\n",
    "        for n_epoch in range(1, self.max_iterations + 1):\n",
    "\n",
    "            if self.shuffle:\n",
    "                idxs = np.arange(X_train.shape[0])\n",
    "                self.rng.shuffle(idxs)\n",
    "\n",
    "                X_train = X_train[idxs]\n",
    "                y_train = y_train[idxs]\n",
    "\n",
    "            for x, y_true in zip(X_train, y_train):\n",
    "\n",
    "                a = np.dot(current_weights, x) + current_bias\n",
    "                if y_true * a <= 0:\n",
    "                    if self.class_weights is None:\n",
    "                        current_weights = current_weights + y_true * x * self.learning_rate\n",
    "                        self.cache[\"weights\"] = self.cache[\"weights\"] + y_true * c * x * self.learning_rate\n",
    "                    else:\n",
    "                        current_weights = current_weights + y_true * x * self.learning_rate * self.class_weights[y_true]\n",
    "                        self.cache[\"weights\"] = (\n",
    "                            self.cache[\"weights\"] + y_true * c * x * self.learning_rate * self.class_weights[y_true]\n",
    "                        )\n",
    "\n",
    "                    current_bias = current_bias + y_true\n",
    "                    self.cache[\"bias\"] = self.cache[\"bias\"] + y_true * c\n",
    "\n",
    "                c += 1\n",
    "\n",
    "            self.weights = current_weights - (1 / c) * self.cache[\"weights\"]\n",
    "            self.bias = current_bias - (1 / c) * self.cache[\"bias\"]\n",
    "\n",
    "            if X_val is not None and y_val is not None:\n",
    "                train_score = self.calculate_score(y_train, self.predict(X_train))\n",
    "                val_score = self.calculate_score(y_val, self.predict(X_val))\n",
    "\n",
    "                if val_score > best_val_score:\n",
    "                    best_val_score = val_score\n",
    "\n",
    "                    best_epoch = n_epoch\n",
    "                    best_weights = self.weights\n",
    "                    best_bias = self.bias\n",
    "                    best_cache = self.cache\n",
    "\n",
    "                if self.debug and (n_epoch == self.max_iterations or n_epoch % self.debug_at == 0):\n",
    "                    print(\"Epoch #\", n_epoch, \" Train: \", train_score, \" Val: \", val_score)\n",
    "\n",
    "            # Update learning rate\n",
    "            if self.learning_rate_scheduler:\n",
    "                learning_rate = self.learning_rate_scheduler(learning_rate, n_epoch)\n",
    "\n",
    "        # Set best epochs, weight, bias and cache\n",
    "        self.best_epoch = best_epoch\n",
    "        self.weights = best_weights\n",
    "        self.bias = best_bias\n",
    "        self.cache = best_cache\n",
    "\n",
    "    def _activation(self, x: npt.NDArray):\n",
    "        return np.dot(self.weights, x) + self.bias\n",
    "\n",
    "    def predict(self, X: npt.NDArray):\n",
    "        predictions = list()\n",
    "        for x in X:\n",
    "            pred = np.sign(self._activation(x))\n",
    "            predictions.append(pred)\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def export(\n",
    "        self,\n",
    "    ):\n",
    "        return {\n",
    "            \"type\": self.type,\n",
    "            \"max_iterations\": self.best_epoch,\n",
    "            \"weights\": self.weights.tolist(),\n",
    "            \"bias\": float(self.bias),\n",
    "            \"best_epoch\": self.best_epoch,\n",
    "        }\n",
    "\n",
    "    def load(self, model_data: Dict[str, Any]):\n",
    "        self.type = model_data[\"type\"]\n",
    "        self.max_iterations = (model_data[\"max_iterations\"],)\n",
    "        self.weights = np.array(model_data[\"weights\"])\n",
    "        self.bias = model_data[\"bias\"]\n",
    "        self.best_epoch = model_data[\"best_epoch\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 50  Train:  0.7846532273837821  Val:  0.7901347430343019\n",
      "Epoch # 100  Train:  0.8828758169934641  Val:  0.8430079673456574\n",
      "Epoch # 150  Train:  0.9312070043777361  Val:  0.8718136608337974\n",
      "Epoch # 200  Train:  0.9520700194498473  Val:  0.903101343101343\n",
      "Epoch # 250  Train:  0.9687494574558586  Val:  0.906158357771261\n",
      "Epoch # 300  Train:  0.97812497626408  Val:  0.912222265762765\n",
      "Epoch # 350  Train:  0.9854160969829551  Val:  0.9184313725490196\n",
      "Epoch # 400  Train:  0.9874995116996758  Val:  0.9311531841652323\n",
      "Epoch # 450  Train:  0.9906241759529646  Val:  0.9249266862170088\n",
      "Epoch # 500  Train:  0.9906241759529646  Val:  0.9249882794186592\n",
      "Epoch # 550  Train:  0.9906241759529646  Val:  0.9312473143482167\n",
      "Epoch # 600  Train:  0.9906241759529646  Val:  0.9375\n",
      "Epoch # 650  Train:  0.9906241759529646  Val:  0.943747802648541\n",
      "Epoch # 700  Train:  0.9906241759529646  Val:  0.9468703304001328\n",
      "Epoch # 750  Train:  0.9906241759529646  Val:  0.9437412095639944\n",
      "Epoch # 800  Train:  0.9916660879227723  Val:  0.9437412095639944\n",
      "Epoch # 850  Train:  0.9916660879227723  Val:  0.9437412095639944\n",
      "Epoch # 900  Train:  0.9916660879227723  Val:  0.9468620268620269\n",
      "Epoch # 950  Train:  0.9916660879227723  Val:  0.9468620268620269\n",
      "Epoch # 1000  Train:  0.9927079456264494  Val:  0.9437302176546443\n",
      "Epoch # 1050  Train:  0.9927079456264494  Val:  0.9468495666871843\n",
      "Epoch # 1100  Train:  0.9927079456264494  Val:  0.9468329440279908\n",
      "Epoch # 1150  Train:  0.9927079456264494  Val:  0.9468329440279908\n",
      "Epoch # 1200  Train:  0.9927079456264494  Val:  0.9468329440279908\n",
      "Epoch # 1250  Train:  0.9927079456264494  Val:  0.9436950146627566\n",
      "Epoch # 1300  Train:  0.9927079456264494  Val:  0.9436950146627566\n",
      "Epoch # 1350  Train:  0.9937497558498378  Val:  0.9436950146627566\n",
      "Epoch # 1400  Train:  0.9937497558498378  Val:  0.9374119856047567\n",
      "Epoch # 1450  Train:  0.9937497558498378  Val:  0.9342665140710744\n",
      "Epoch # 1500  Train:  0.9937497558498378  Val:  0.9342665140710744\n",
      "Epoch # 1550  Train:  0.9937497558498378  Val:  0.9342665140710744\n",
      "Epoch # 1600  Train:  0.9937497558498378  Val:  0.9279667237582578\n",
      "Epoch # 1650  Train:  0.9937497558498378  Val:  0.9279215755403434\n",
      "Epoch # 1700  Train:  0.9937497558498378  Val:  0.92476194208237\n",
      "Epoch # 1750  Train:  0.9937497558498378  Val:  0.92476194208237\n",
      "Epoch # 1800  Train:  0.9937497558498378  Val:  0.9215986044551594\n",
      "Epoch # 1850  Train:  0.9937497558498378  Val:  0.9184313725490196\n",
      "Epoch # 1900  Train:  0.9937497558498378  Val:  0.9184313725490196\n",
      "Epoch # 1950  Train:  0.9937497558498378  Val:  0.9152600555125099\n",
      "Epoch # 2000  Train:  0.9937497558498378  Val:  0.9152600555125099\n"
     ]
    }
   ],
   "source": [
    "averaged_perceptron_sentiment = AveragedPerceptron(\n",
    "    max_iterations=2000,\n",
    "    learning_rate=3,\n",
    "    shuffle=True,\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    "    rng=rng,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    ")\n",
    "\n",
    "averaged_perceptron_sentiment.fit(X_all, y_all_sentiment, X_dev, y_dev_sentiment)\n",
    "\n",
    "averaged_perceptron_sentiment_data = averaged_perceptron_sentiment.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_perceptron_sentiment_data[\"best_epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ All ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.98      0.99       480\n",
      "           1       0.98      1.00      0.99       480\n",
      "\n",
      "    accuracy                           0.99       960\n",
      "   macro avg       0.99      0.99      0.99       960\n",
      "weighted avg       0.99      0.99      0.99       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.94      0.95       160\n",
      "           1       0.94      0.96      0.95       160\n",
      "\n",
      "    accuracy                           0.95       320\n",
      "   macro avg       0.95      0.95      0.95       320\n",
      "weighted avg       0.95      0.95      0.95       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_dev_sentiment_pred = averaged_perceptron_sentiment.predict(X_dev)\n",
    "\n",
    "calculate_scores(y_all_sentiment, averaged_perceptron_sentiment.predict(X_all), title=\"All\")\n",
    "calculate_scores(y_dev_sentiment, y_dev_sentiment_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truthful Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 50  Train:  0.803666862939873  Val:  0.6976562261889039\n",
      "Epoch # 100  Train:  0.9393915644552424  Val:  0.7935483870967742\n",
      "Epoch # 150  Train:  0.9697677524865046  Val:  0.8059771553747457\n",
      "Epoch # 200  Train:  0.9760301967412792  Val:  0.817545515315953\n",
      "Epoch # 250  Train:  0.9770712917808397  Val:  0.8037664187371418\n",
      "Epoch # 300  Train:  0.9791576204950065  Val:  0.7727977279772797\n",
      "Epoch # 350  Train:  0.9791576204950065  Val:  0.7684049696433597\n",
      "Epoch # 400  Train:  0.9812434058848815  Val:  0.7649308176100629\n",
      "Epoch # 450  Train:  0.9812434058848815  Val:  0.7608950280706006\n",
      "Epoch # 500  Train:  0.9822861118558228  Val:  0.757377248051436\n",
      "Epoch # 550  Train:  0.9822861118558228  Val:  0.7467429684646293\n",
      "Epoch # 600  Train:  0.9822861118558228  Val:  0.7425006366182838\n",
      "Epoch # 650  Train:  0.9822861118558228  Val:  0.7352697858259032\n",
      "Epoch # 700  Train:  0.983328702417338  Val:  0.7316314842088039\n",
      "Epoch # 750  Train:  0.983328702417338  Val:  0.7316314842088039\n",
      "Epoch # 800  Train:  0.983328702417338  Val:  0.727977549954424\n"
     ]
    }
   ],
   "source": [
    "averaged_perceptron_truthfulness = AveragedPerceptron(\n",
    "    max_iterations=800,\n",
    "    learning_rate=815e-2,\n",
    "    shuffle=True,\n",
    "    score_func=partial(calculate_f1_score, average=\"macro\"),\n",
    "    rng=rng,\n",
    "    debug=True,\n",
    "    debug_at=50,\n",
    ")\n",
    "\n",
    "averaged_perceptron_truthfulness.fit(X_all, y_all_truthfulness, X_dev, y_dev_truthfulness)\n",
    "averaged_perceptron_truthfulness_data = averaged_perceptron_truthfulness.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_perceptron_truthfulness_data[\"best_epoch\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Whole ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      1.00      0.97       480\n",
      "           1       1.00      0.95      0.97       480\n",
      "\n",
      "    accuracy                           0.97       960\n",
      "   macro avg       0.98      0.97      0.97       960\n",
      "weighted avg       0.98      0.97      0.97       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.86      0.83       160\n",
      "           1       0.85      0.79      0.82       160\n",
      "\n",
      "    accuracy                           0.82       320\n",
      "   macro avg       0.82      0.82      0.82       320\n",
      "weighted avg       0.82      0.82      0.82       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_dev_truthfulness_pred = averaged_perceptron_truthfulness.predict(X_dev)\n",
    "\n",
    "calculate_scores(y_all_truthfulness, averaged_perceptron_truthfulness.predict(X_all), title=\"Whole\")\n",
    "calculate_scores(y_dev_truthfulness, y_dev_truthfulness_pred, title=\"Dev\")\n",
    "\n",
    "del averaged_perceptron_truthfulness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging the Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_f1_score = calculate_f1_score(y_dev_sentiment, y_dev_sentiment_pred, average=\"macro\")\n",
    "truthfulness_f1_score = calculate_f1_score(y_dev_truthfulness, y_dev_truthfulness_pred, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8842673008290811"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([sentiment_f1_score, truthfulness_f1_score])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Averaged Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_model_file_data = {\n",
    "    \"tf_idf_model\": tf_idf_model_data,\n",
    "    \"sentiment_classifier\": averaged_perceptron_sentiment_data,\n",
    "    \"truthfulness_classifier\": averaged_perceptron_truthfulness_data,\n",
    "}\n",
    "\n",
    "store_model(AVERAGED_MODEL_FILE_PATH, averaged_model_file_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Loaded Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model_data, averaged_perceptron_sentiment_data, averaged_perceptron_truthfulness_data = load_model(\n",
    "    AVERAGED_MODEL_FILE_PATH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_saved_model = TfIdf()\n",
    "tf_idf_saved_model.load(tf_idf_model_data)\n",
    "\n",
    "averaged_perceptron_sentiment_saved = AveragedPerceptron()\n",
    "averaged_perceptron_sentiment_saved.load(averaged_perceptron_sentiment_data)\n",
    "\n",
    "averaged_perceptron_truthfulness_saved = AveragedPerceptron()\n",
    "averaged_perceptron_truthfulness_saved.load(averaged_perceptron_truthfulness_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 7675)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev_tf_idf_vectors_saved = tf_idf_saved_model.transform(dev_tokenized)\n",
    "X_dev_tf_idf_vectors_saved.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Whole ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.98      0.99       480\n",
      "           1       0.98      1.00      0.99       480\n",
      "\n",
      "    accuracy                           0.99       960\n",
      "   macro avg       0.99      0.99      0.99       960\n",
      "weighted avg       0.99      0.99      0.99       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.94      0.95       160\n",
      "           1       0.94      0.96      0.95       160\n",
      "\n",
      "    accuracy                           0.95       320\n",
      "   macro avg       0.95      0.95      0.95       320\n",
      "weighted avg       0.95      0.95      0.95       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_pred_sentiment = averaged_perceptron_sentiment_saved.predict(X_dev_tf_idf_vectors_saved)\n",
    "\n",
    "calculate_scores(y_all_sentiment, averaged_perceptron_sentiment_saved.predict(X_all), title=\"Whole\")\n",
    "calculate_scores(y_dev_sentiment, y_dev_sentiment_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Whole ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      1.00      0.97       480\n",
      "           1       1.00      0.95      0.97       480\n",
      "\n",
      "    accuracy                           0.97       960\n",
      "   macro avg       0.98      0.97      0.97       960\n",
      "weighted avg       0.98      0.97      0.97       960\n",
      "\n",
      "---------------------------------------------------------\n",
      "------------------------ Dev ------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.86      0.83       160\n",
      "           1       0.85      0.79      0.82       160\n",
      "\n",
      "    accuracy                           0.82       320\n",
      "   macro avg       0.82      0.82      0.82       320\n",
      "weighted avg       0.82      0.82      0.82       320\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_pred_truthfulness = averaged_perceptron_truthfulness_saved.predict(X_dev_tf_idf_vectors_saved)\n",
    "\n",
    "calculate_scores(y_all_truthfulness, averaged_perceptron_truthfulness_saved.predict(X_all), title=\"Whole\")\n",
    "calculate_scores(y_dev_truthfulness, y_dev_truthfulness_pred, title=\"Dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list()\n",
    "for (id, truthfulness, sentiment) in zip(\n",
    "    dev_raw_data[:, 0],\n",
    "    np.where(y_pred_truthfulness == -1, DECEPTIVE, TRUTHFUL),\n",
    "    np.where(y_pred_sentiment == -1, NEGATIVE, POSITIVE),\n",
    "):\n",
    "    output.append((id, truthfulness, sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_predictions(OUTPUT_FILE_PATH, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('csci544')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e78917e7f90f3892e7e12462ef46781cf5994bd706032ea53be00d0b1f29dcb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
