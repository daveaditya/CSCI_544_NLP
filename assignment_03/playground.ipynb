{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow multiple print statements in a cell in Jupyter Notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "from typing import List, Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data\"\n",
    "OUTPUT_PATH = \"./submission\"\n",
    "DATASET_FILES = {\n",
    "    \"ITALIAN\": {\n",
    "        \"TRAIN\": f\"{DATA_PATH}/it_isdt_train_tagged.txt\",\n",
    "        \"DEV_RAW\": f\"{DATA_PATH}/it_isdt_dev_raw.txt\",\n",
    "        \"DEV_TAGGED\": f\"{DATA_PATH}/it_isdt_dev_tagged.txt\",\n",
    "    },\n",
    "    \"JAPANESE\": {\n",
    "        \"TRAIN\": f\"{DATA_PATH}/ja_gsd_train_tagged.txt\",\n",
    "        \"DEV_RAW\": f\"{DATA_PATH}/ja_gsd_dev_raw.txt\",\n",
    "        \"DEV_TAGGED\": f\"{DATA_PATH}/ja_gsd_dev_tagged.txt\",\n",
    "    },\n",
    "}\n",
    "MODEL_FILE = f\"{OUTPUT_PATH}/hmmmodel.txt\"\n",
    "OUTPUT_FILE = f\"{OUTPUT_PATH}/hmmoutput.txt\"\n",
    "\n",
    "START_TAG = \"<ST@RT$>\"\n",
    "END_TAG = \"<6ND!>\"\n",
    "\n",
    "SMOOTHING_PARAMETER = 1.0\n",
    "OPEN_CLASS_PRECENT = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Italian Experiment\n",
    "# EXPERIMENT_TRAIN_DOCUMENT = DATASET_FILES[\"ITALIAN\"][\"TRAIN\"]\n",
    "# EXPERIMENT_TEST_RAW_DOCUMENT = DATASET_FILES[\"ITALIAN\"][\"DEV_RAW\"]\n",
    "# EXPERIMENT_TEST_RAW_TAGGED_DOCUMENT = DATASET_FILES[\"ITALIAN\"][\"DEV_TAGGED\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Japanese Experiment\n",
    "EXPERIMENT_TRAIN_DOCUMENT = DATASET_FILES[\"JAPANESE\"][\"TRAIN\"]\n",
    "EXPERIMENT_TEST_RAW_DOCUMENT = DATASET_FILES[\"JAPANESE\"][\"DEV_RAW\"]\n",
    "EXPERIMENT_TEST_RAW_TAGGED_DOCUMENT = DATASET_FILES[\"JAPANESE\"][\"DEV_TAGGED\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file_path: str):\n",
    "    document = list()\n",
    "    with open(file_path, mode=\"r\") as file:\n",
    "        csv_reader = csv.reader(file, delimiter=\" \", skipinitialspace=True, quoting=csv.QUOTE_NONE)\n",
    "        for sentence in csv_reader:\n",
    "            document.append(sentence)\n",
    "    return document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_model(\n",
    "    out_file_path: str,\n",
    "    words: List[str],\n",
    "    tags: List[str],\n",
    "    open_class_tags: List[str],\n",
    "    tag_counts: Dict[str, int],\n",
    "    transition_probabilities,\n",
    "    transition_matrix_labels,\n",
    "    emission_probabilities,\n",
    "    emission_matrix_row_labels,\n",
    "    emission_matrix_col_labels,\n",
    "    smoothing_parameter,\n",
    "):\n",
    "    \"\"\"Writes the model parameters to a txt file in JSON format\n",
    "\n",
    "    Args:\n",
    "        out_file_path (str): output model path\n",
    "        words (List[str]): list of words\n",
    "        tags (List[str]): list of tags\n",
    "        open_class_tags (List[str]): list of open class tags\n",
    "        tag_counts (Dict[str, int]): list of tag counts\n",
    "        transition_probabilities (_type_): list of transition probabilities\n",
    "        transition_matrix_labels (_type_): list of transition matric labels\n",
    "        emission_probabilities (_type_): list of emission probabilities\n",
    "        emission_matrix_row_labels (_type_): list of emission matrix row labels\n",
    "        emission_matrix_col_labels (_type_): list of emission matrix column labels\n",
    "        smoothing_parameter (_type_): smoothing parameter for laplace smoothing\n",
    "    \"\"\"\n",
    "    with open(out_file_path, mode=\"w\") as output_file:\n",
    "        out = dict()\n",
    "        out[\"tags\"] = tags\n",
    "        out[\"open_class_tags\"] = open_class_tags\n",
    "        out[\"words\"] = words\n",
    "        out[\"tag_counts\"] = tag_counts\n",
    "        out[\"smoothing_parameter\"] = smoothing_parameter\n",
    "        out[\"transition_probabilities\"] = transition_probabilities.tolist()\n",
    "        out[\"transition_matrix_labels\"] = transition_matrix_labels\n",
    "        out[\"emission_probabilities\"] = emission_probabilities.tolist()\n",
    "        out[\"emission_matrix_row_labels\"] = emission_matrix_row_labels\n",
    "        out[\"emission_matrix_col_labels\"] = emission_matrix_col_labels\n",
    "        json.dump(out, output_file, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path: str):\n",
    "    \"\"\"Load the model file to respective objects\n",
    "    \"\"\"\n",
    "    model_data = None\n",
    "    with open(model_path, mode=\"r\") as model_file:\n",
    "        model_data = json.load(model_file)\n",
    "    return (\n",
    "        model_data[\"words\"],\n",
    "        model_data[\"tags\"],\n",
    "        model_data[\"open_class_tags\"],\n",
    "        model_data[\"tag_counts\"],\n",
    "        model_data[\"smoothing_parameter\"],\n",
    "        np.array(model_data[\"transition_probabilities\"]),\n",
    "        model_data[\"transition_matrix_labels\"],\n",
    "        np.array(model_data[\"emission_probabilities\"]),\n",
    "        model_data[\"emission_matrix_row_labels\"],\n",
    "        model_data[\"emission_matrix_col_labels\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training document\n",
    "train_document = load_document(EXPERIMENT_TRAIN_DOCUMENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occurrences(train_document: List[List[str]]):\n",
    "    tag_counts = {\n",
    "        START_TAG: len(train_document),\n",
    "    }\n",
    "    word_tag_counts = {}\n",
    "    tag_tag_counts = {\n",
    "        START_TAG: {},\n",
    "    }\n",
    "\n",
    "    count = len(train_document)\n",
    "\n",
    "    # Process count number of sentences from document\n",
    "    for idx, sentence in enumerate(train_document):\n",
    "        if idx == count:\n",
    "            break\n",
    "\n",
    "        prev_tag = START_TAG\n",
    "        sentence_last_idx = len(sentence) - 1\n",
    "        for idx, word_tag_pair in enumerate(sentence):\n",
    "            # Extract word tag\n",
    "            word, tag = word_tag_pair.rsplit(\"/\", 1)\n",
    "\n",
    "            # Count the Tag!\n",
    "            if tag not in tag_counts:\n",
    "                tag_counts[tag] = 1\n",
    "            else:\n",
    "                tag_counts[tag] += 1\n",
    "\n",
    "            # Count the Word - Tag (Emission)\n",
    "            if word not in word_tag_counts:\n",
    "                word_tag_counts[word] = {tag: 1}\n",
    "            else:\n",
    "                # Check if the tag is in the dict\n",
    "                if tag not in word_tag_counts[word]:\n",
    "                    word_tag_counts[word][tag] = 1\n",
    "                else:\n",
    "                    word_tag_counts[word][tag] += 1\n",
    "\n",
    "            # Count tag-tag (Transition)\n",
    "            if prev_tag in tag_tag_counts:\n",
    "                if tag not in tag_tag_counts[prev_tag]:\n",
    "                    tag_tag_counts[prev_tag][tag] = 1\n",
    "                else:\n",
    "                    tag_tag_counts[prev_tag][tag] += 1\n",
    "            else:\n",
    "                tag_tag_counts[prev_tag] = {tag: 1}\n",
    "\n",
    "            prev_tag = tag\n",
    "\n",
    "    return (tag_counts, tag_tag_counts, word_tag_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counts, tag_tag_counts, word_tag_counts = count_occurrences(train_document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(word_tag_counts.keys())\n",
    "tags = list(tag_counts.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probabilities(\n",
    "    tags: List[str],\n",
    "    words: List[str],\n",
    "    tag_counts: Dict[str, int],\n",
    "    tag_tag_counts: Dict[str, Dict[str, int]],\n",
    "    word_tag_counts: Dict[str, Dict[str, int]],\n",
    "    smoothing_parameter: float,\n",
    "):\n",
    "    # Create row and column headers for access\n",
    "    # Transition Matric Labels (same for both row and column)\n",
    "    transition_matrix_labels = {tag: i for i, tag in enumerate(tags)}\n",
    "    transition_matrix_n_rows, transition_matrix_n_cols = len(transition_matrix_labels), len(transition_matrix_labels)\n",
    "\n",
    "    # Emission Matrix Labels\n",
    "    emission_col_labels = deepcopy(tags)\n",
    "    emission_col_labels.remove(START_TAG)\n",
    "\n",
    "    emission_matrix_n_rows, emission_matrix_n_cols = len(words), len(emission_col_labels)\n",
    "    emission_matrix_row_labels = {word: i for i, word in enumerate(words)}\n",
    "    emission_matrix_col_labels = {tag: i for i, tag in enumerate(emission_col_labels)}\n",
    "\n",
    "    # Create empty transition and emission probability matrices\n",
    "    transition_probabilities = np.zeros(shape=(transition_matrix_n_rows, transition_matrix_n_cols), dtype=np.float64)\n",
    "    emission_probabilities = np.zeros(shape=(emission_matrix_n_rows, emission_matrix_n_cols), dtype=np.float64)\n",
    "\n",
    "    # Fill in emission probablity matrix\n",
    "    for row_word, row_idx in emission_matrix_row_labels.items():\n",
    "        for col_tag, col_idx in emission_matrix_col_labels.items():\n",
    "            if col_tag not in word_tag_counts[row_word]:\n",
    "                emission_probabilities[row_idx][col_idx] = 0.0\n",
    "            else:\n",
    "                emission_probability = word_tag_counts[row_word][col_tag] / tag_counts[col_tag]\n",
    "\n",
    "                if emission_probability > 1:\n",
    "                    emission_probability = 1\n",
    "\n",
    "                emission_probabilities[row_idx][col_idx] = emission_probability\n",
    "\n",
    "    # Fill in transition probablity matrix\n",
    "    for row_tag, row_idx in transition_matrix_labels.items():\n",
    "        for col_tag, col_idx in transition_matrix_labels.items():\n",
    "            if col_tag not in tag_tag_counts[row_tag]:\n",
    "                transition_probabilities[row_idx][col_idx] = 0.0\n",
    "            else:\n",
    "                # Laplace Smoothing\n",
    "                transition_probabilities[row_idx][col_idx] = (tag_tag_counts[row_tag][col_tag] + smoothing_parameter) / (\n",
    "                    tag_counts[row_tag] + smoothing_parameter * len(tag_counts)\n",
    "                )\n",
    "\n",
    "    return (\n",
    "        transition_probabilities,\n",
    "        transition_matrix_labels,\n",
    "        emission_probabilities,\n",
    "        emission_matrix_row_labels,\n",
    "        emission_matrix_col_labels,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    transition_probabilities,\n",
    "    transition_matrix_labels,\n",
    "    emission_probabilities,\n",
    "    emission_matrix_row_labels,\n",
    "    emission_matrix_col_labels,\n",
    ") = calculate_probabilities(tags, words, tag_counts, tag_tag_counts, word_tag_counts, SMOOTHING_PARAMETER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_open_classes(\n",
    "    emission_probabilities, tags, threshold: float = 0.2\n",
    "):\n",
    "    n_open_tags = int(threshold * len(tags))\n",
    "    \n",
    "    unqiue_counts = (emission_probabilities != 0).sum(axis=0)\n",
    "\n",
    "    reverse_sorted_counts = unqiue_counts.argsort()[::-1]\n",
    "\n",
    "    open_class_tags_idx = reverse_sorted_counts[:n_open_tags]\n",
    "\n",
    "    open_class_tags = list(map(tags.__getitem__, open_class_tags_idx))\n",
    "\n",
    "    return open_class_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_class_tags = calculate_open_classes(emission_probabilities, tags, OPEN_CLASS_PRECENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "write_model(\n",
    "    MODEL_FILE,\n",
    "    words,\n",
    "    tags,\n",
    "    open_class_tags,\n",
    "    tag_counts,\n",
    "    transition_probabilities,\n",
    "    transition_matrix_labels,\n",
    "    emission_probabilities,\n",
    "    emission_matrix_row_labels,\n",
    "    emission_matrix_col_labels,\n",
    "    SMOOTHING_PARAMETER,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    words,\n",
    "    tags,\n",
    "    open_class_tags,\n",
    "    tag_counts,\n",
    "    SMOOTHING_PARAMETER,\n",
    "    transition_probabilities,\n",
    "    transition_matrix_labels,\n",
    "    emission_probabilities,\n",
    "    emission_matrix_row_labels,\n",
    "    emission_matrix_col_labels,\n",
    ") = load_model(MODEL_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decoding(\n",
    "    tags,\n",
    "    tag_counts,\n",
    "    open_class_tags,\n",
    "    emission_probabilities,\n",
    "    emission_matrix_row_labels,\n",
    "    emission_matrix_col_labels,\n",
    "    transition_probabilities,\n",
    "    transition_matrix_labels,\n",
    "    sentence,\n",
    "    smoothing_parameter,\n",
    "):\n",
    "    n_words_in_sentence = len(sentence)\n",
    "    n_tags = len(tags)\n",
    "\n",
    "    viterbi_matrix = np.zeros(shape=(n_tags, n_words_in_sentence), dtype=np.float64)\n",
    "    backtrack_matrix = np.zeros(shape=(n_tags, n_words_in_sentence), dtype=np.int32)\n",
    "\n",
    "    cumulative_probability = 0\n",
    "\n",
    "    for idx, tag in enumerate(tags):\n",
    "        # handle new word in corpus\n",
    "        word = sentence[0]\n",
    "\n",
    "        # Emission Probablity\n",
    "        # approach: set emission probability = 1 i.e. use transision probability alone\n",
    "        if word not in emission_matrix_row_labels:\n",
    "            em_prob = 1.0\n",
    "\n",
    "        elif word not in emission_matrix_row_labels or tag not in emission_matrix_col_labels:\n",
    "            em_prob = 0.0\n",
    "\n",
    "        else:\n",
    "            em_prob = emission_probabilities[emission_matrix_row_labels[word]][emission_matrix_col_labels[tag]]\n",
    "\n",
    "        # Transision Probability\n",
    "        if START_TAG not in transition_matrix_labels or tag not in transition_matrix_labels:\n",
    "            trans_prob = float(1 / (tag_counts[START_TAG] + n_tags))\n",
    "        else:\n",
    "            trans_prob = transition_probabilities[transition_matrix_labels[START_TAG]][transition_matrix_labels[tag]]\n",
    "\n",
    "        viterbi_matrix[idx][0] = trans_prob * em_prob\n",
    "\n",
    "        backtrack_matrix[idx][0] = 0\n",
    "\n",
    "    for idx in range(1, n_words_in_sentence):\n",
    "\n",
    "        word = sentence[idx]\n",
    "        tags_to_consider = tags\n",
    "        if word not in emission_matrix_row_labels:\n",
    "            tags_to_consider = open_class_tags\n",
    "\n",
    "        for end_tag in tags_to_consider:\n",
    "\n",
    "            for start_tag in tags:\n",
    "\n",
    "                # emission\n",
    "                if word not in emission_matrix_row_labels:\n",
    "                    em_prob = 1.0\n",
    "                elif word not in emission_matrix_row_labels or end_tag not in emission_matrix_col_labels:\n",
    "                    em_prob = 0.0\n",
    "                else:\n",
    "                    em_prob = emission_probabilities[emission_matrix_row_labels[word]][\n",
    "                        emission_matrix_col_labels[end_tag]\n",
    "                    ]\n",
    "                    if em_prob == 0.0:\n",
    "                        continue\n",
    "\n",
    "                # set transition key of the beginning of sentence: tag1-tag2 (follow model format)\n",
    "                if start_tag not in transition_matrix_labels or end_tag not in transition_matrix_labels:\n",
    "                    trans_prob = 1 / (tag_counts[start_tag] + n_tags)\n",
    "                else:\n",
    "                    trans_prob = transition_probabilities[transition_matrix_labels[start_tag]][\n",
    "                        transition_matrix_labels[end_tag]\n",
    "                    ]\n",
    "                    if trans_prob == 0:\n",
    "                        continue\n",
    "\n",
    "                cumulative_probability = (\n",
    "                    viterbi_matrix[transition_matrix_labels[start_tag]][idx - 1] * trans_prob * em_prob\n",
    "                )\n",
    "                if cumulative_probability == 0:\n",
    "                    continue\n",
    "\n",
    "                if cumulative_probability > viterbi_matrix[transition_matrix_labels[end_tag]][idx]:\n",
    "                    viterbi_matrix[transition_matrix_labels[end_tag]][idx] = cumulative_probability\n",
    "                    backtrack_matrix[transition_matrix_labels[end_tag]][idx] = transition_matrix_labels[start_tag]\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "    return (viterbi_matrix, backtrack_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_backtrack(tags, viterbi_matrix, backtrack_matrix, sentence):\n",
    "    n_tags = len(tags)\n",
    "    n_words_in_sentence = len(sentence)\n",
    "\n",
    "    # Backtracking\n",
    "    best_idx = 0\n",
    "    for i in range(n_tags):\n",
    "        if viterbi_matrix[i][n_words_in_sentence - 1] > viterbi_matrix[best_idx][n_words_in_sentence - 1]:\n",
    "            best_idx = i\n",
    "\n",
    "    output = [f\"{sentence[n_words_in_sentence - 1]}/{tags[best_idx]}\"]\n",
    "\n",
    "    for idx in range(n_words_in_sentence - 1, 0, -1):\n",
    "        best_idx = backtrack_matrix[best_idx][idx]\n",
    "        output.insert(0, f\"{sentence[idx - 1]}/{tags[best_idx]}\")\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load development data\n",
    "dev_raw_document = load_document(EXPERIMENT_TEST_RAW_DOCUMENT)\n",
    "dev_raw_tagged_document = load_document(EXPERIMENT_TEST_RAW_TAGGED_DOCUMENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['われわれ/NP',\n",
       "  'の/PN',\n",
       "  '組織/NN',\n",
       "  'が/PS',\n",
       "  'つぶれれ/VV',\n",
       "  'ば/PC',\n",
       "  '良い/JJ',\n",
       "  'と/PQ',\n",
       "  '日共/NN',\n",
       "  'や/PH',\n",
       "  '権力/NN',\n",
       "  'が/PS',\n",
       "  '願望/NN',\n",
       "  'を/PS',\n",
       "  'もっ/VV',\n",
       "  'て/PC',\n",
       "  'も/PK',\n",
       "  '今/NR',\n",
       "  'の/PN',\n",
       "  'ところ/NB',\n",
       "  '手/NN',\n",
       "  'を/PS',\n",
       "  '下す/VV',\n",
       "  '方法/NN',\n",
       "  'が/PS',\n",
       "  'ない/JJ',\n",
       "  '。/SYM'],\n",
       " ['われわれ/NP',\n",
       "  'の/PN',\n",
       "  '組織/NN',\n",
       "  'が/PS',\n",
       "  'つぶれれ/VV',\n",
       "  'ば/PC',\n",
       "  '良い/JJ',\n",
       "  'と/PC',\n",
       "  '日共/NN',\n",
       "  'や/PH',\n",
       "  '権力/NN',\n",
       "  'が/PS',\n",
       "  '願望/NN',\n",
       "  'を/PS',\n",
       "  'もっ/VV',\n",
       "  'て/PC',\n",
       "  'も/PK',\n",
       "  '今/NR',\n",
       "  'の/PN',\n",
       "  'ところ/NN',\n",
       "  '手/XS',\n",
       "  'を/PS',\n",
       "  '下す/VV',\n",
       "  '方法/NN',\n",
       "  'が/PS',\n",
       "  'ない/JJ',\n",
       "  '。/SYM'])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Block\n",
    "\n",
    "SAMPLE_IDX = 101\n",
    "sample, sample_tagged = dev_raw_document[SAMPLE_IDX], dev_raw_tagged_document[SAMPLE_IDX]\n",
    "\n",
    "viterbi_matrix, backtrack_matrix = viterbi_decoding(\n",
    "    tags,\n",
    "    tag_counts,\n",
    "    open_class_tags,\n",
    "    emission_probabilities,\n",
    "    emission_matrix_row_labels,\n",
    "    emission_matrix_col_labels,\n",
    "    transition_probabilities,\n",
    "    transition_matrix_labels,\n",
    "    sample,\n",
    "    SMOOTHING_PARAMETER,\n",
    ")\n",
    "output = viterbi_backtrack(tags, viterbi_matrix, backtrack_matrix, sample)\n",
    "output, sample_tagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags = list()\n",
    "for sentence in dev_raw_document:\n",
    "    viterbi_matrix, backtrack_matrix = viterbi_decoding(\n",
    "        tags,\n",
    "        tag_counts,\n",
    "        open_class_tags,\n",
    "        emission_probabilities,\n",
    "        emission_matrix_row_labels,\n",
    "        emission_matrix_col_labels,\n",
    "        transition_probabilities,\n",
    "        transition_matrix_labels,\n",
    "        sentence,\n",
    "        SMOOTHING_PARAMETER,\n",
    "    )\n",
    "    output = viterbi_backtrack(tags, viterbi_matrix, backtrack_matrix, sentence)\n",
    "    predicted_tags.append(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tagged_true: List[List[str]], tagged_preds: List[List[str]]):\n",
    "    total_count, correct_count = 0, 0\n",
    "    for sentence_true, sentence_pred in zip(tagged_true, tagged_preds):\n",
    "        for word_tag_true, word_tag_pred in zip(sentence_true, sentence_pred):\n",
    "            if word_tag_true == word_tag_pred:\n",
    "                correct_count += 1\n",
    "            total_count += 1\n",
    "    return correct_count / total_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8932207814811591"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(dev_raw_tagged_document, predicted_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(output_file_path: str, predicted_tags: str):\n",
    "    with open(output_file_path, mode=\"w\") as file:\n",
    "        for predicted_row in predicted_tags:\n",
    "            file.write(\" \".join(predicted_row) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output(OUTPUT_FILE, predicted_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use Open Class labels to handle unseen words\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('CSCI544_assignment_03')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99319869c2b84476c56e7423ed21631b8ddb5a8a9b4475198cf8370d36903f81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
