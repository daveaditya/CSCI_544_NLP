{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow multiple print statements in a cell in Jupyter Notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from typing import List, Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data\"\n",
    "OUTPUT_PATH = \".\"\n",
    "DATASET_FILES = {\n",
    "    \"ITALIAN\": {\n",
    "        \"TRAIN\": f\"{DATA_PATH}/it_isdt_train_tagged.txt\",\n",
    "        \"DEV_RAW\": f\"{DATA_PATH}/it_isdt_dev_raw.txt\",\n",
    "        \"DEV_TAGGED\": f\"{DATA_PATH}/it_isdt_dev_tagged.txt\",\n",
    "    },\n",
    "    \"JAPANESE\": {\n",
    "        \"TRAIN\": f\"{DATA_PATH}/ja_gsd_train_tagged.txt\",\n",
    "        \"DEV_RAW\": f\"{DATA_PATH}/ja_gsd_dev_raw.txt\",\n",
    "        \"DEV_TAGGED\": f\"{DATA_PATH}/ja_gsd_dev_tagged.txt\",\n",
    "    },\n",
    "}\n",
    "MODEL_FILE = f\"{OUTPUT_PATH}/hmmmodel.txt\"\n",
    "OUTPUT_FILE = f\"{OUTPUT_PATH}/hmmoutput.txt\"\n",
    "\n",
    "START_TAG = \"<ST@RT$>\"\n",
    "END_TAG = \"<6ND!>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Italian Experiment\n",
    "EXPERIMENT_TRAIN_DOCUMENT = DATASET_FILES[\"ITALIAN\"][\"TRAIN\"]\n",
    "EXPERIMENT_TEST_RAW_DOCUMENT = DATASET_FILES[\"ITALIAN\"][\"DEV_RAW\"]\n",
    "EXPERIMENT_TEST_RAW_TAGGED_DOCUMENT = DATASET_FILES[\"ITALIAN\"][\"DEV_TAGGED\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Japanese Experiment\n",
    "# EXPERIMENT_TRAIN_DOCUMENT = DATASET_FILES[\"JAPANESE\"][\"TRAIN\"]\n",
    "# EXPERIMENT_TEST_RAW_DOCUMENT = DATASET_FILES[\"JAPANESE\"][\"DEV_RAW\"]\n",
    "# EXPERIMENT_TEST_RAW_TAGGED_DOCUMENT = DATASET_FILES[\"JAPANESE\"][\"DEV_TAGGED\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file_path: str):\n",
    "    document = list()\n",
    "    with open(file_path, mode=\"r\") as file:\n",
    "        csv_reader = csv.reader(file, delimiter=\" \", skipinitialspace=True, quoting=csv.QUOTE_NONE)\n",
    "        for sentence in csv_reader:\n",
    "            document.append(sentence)\n",
    "    return document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_model(\n",
    "    file_path: str,\n",
    "    words: List[str],\n",
    "    tags: List[str],\n",
    "    tag_count_dict: Dict[str, int],\n",
    "    transition_probabilities,\n",
    "    emission_probabilities,\n",
    "):\n",
    "    import json\n",
    "\n",
    "    with open(file_path, mode=\"w\") as output_file:\n",
    "        out = {}\n",
    "        out[\"words\"] = words\n",
    "        out[\"tagds\"] = tags\n",
    "        out[\"tag_counts\"] = (tag_count_dict,)\n",
    "        out[\"transition_probabilities\"] = transition_probabilities.tolist()\n",
    "        out[\"emission_probabilities\"] = emission_probabilities.tolist()\n",
    "        json.dump(out, output_file, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file_path: str):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training document\n",
    "train_document = load_document(EXPERIMENT_TRAIN_DOCUMENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occurrences(train_document: List[List[str]]):\n",
    "    tag_count_dict = {\n",
    "        START_TAG: len(train_document),\n",
    "    }\n",
    "    word_tag_count_dict = {}\n",
    "    tag_tag_count_dict = {\n",
    "        START_TAG: {},\n",
    "    }\n",
    "\n",
    "    count = len(train_document)\n",
    "\n",
    "    # Process count number of sentences from document\n",
    "    for idx, sentence in enumerate(train_document):\n",
    "        if idx == count:\n",
    "            break\n",
    "\n",
    "        prev_tag = START_TAG\n",
    "        sentence_last_idx = len(sentence) - 1\n",
    "        for idx, word_tag_pair in enumerate(sentence):\n",
    "            # Extract word tag\n",
    "            word, tag = word_tag_pair.rsplit(\"/\", 1)\n",
    "\n",
    "            # Count the Tag!\n",
    "            if tag not in tag_count_dict:\n",
    "                tag_count_dict[tag] = 1\n",
    "            else:\n",
    "                tag_count_dict[tag] += 1\n",
    "\n",
    "            # Count the Word - Tag (Emission)\n",
    "            if word not in word_tag_count_dict:\n",
    "                word_tag_count_dict[word] = {tag: 1}\n",
    "            else:\n",
    "                # Check if the tag is in the dict\n",
    "                if tag not in word_tag_count_dict[word]:\n",
    "                    word_tag_count_dict[word][tag] = 1\n",
    "                else:\n",
    "                    word_tag_count_dict[word][tag] += 1\n",
    "\n",
    "            # Count tag-tag (Transition)\n",
    "            if prev_tag in tag_tag_count_dict:\n",
    "                if tag not in tag_tag_count_dict[prev_tag]:\n",
    "                    tag_tag_count_dict[prev_tag][tag] = 1\n",
    "                else:\n",
    "                    tag_tag_count_dict[prev_tag][tag] += 1\n",
    "            else:\n",
    "                tag_tag_count_dict[prev_tag] = {tag: 1}\n",
    "\n",
    "            # If this is the last word/tag pair, end add count for END_TAG\n",
    "            # TODO: Is it needed?\n",
    "            # if idx == sentence_last_idx:\n",
    "            #     if tag not in tag_tag_count_dict:\n",
    "            #         tag_tag_count_dict[tag] = {END_TAG: 1}\n",
    "\n",
    "            #     if END_TAG not in tag_tag_count_dict[tag]:\n",
    "            #         tag_tag_count_dict[tag][END_TAG] = 1\n",
    "            #     else:\n",
    "            #         tag_tag_count_dict[tag][END_TAG] +=1\n",
    "\n",
    "            prev_tag = tag\n",
    "\n",
    "    return (tag_count_dict, tag_tag_count_dict, word_tag_count_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_count_dict, tag_tag_count_dict, word_tag_count_dict = count_occurrences(train_document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28307, 40)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(word_tag_count_dict.keys())\n",
    "tags = list(tag_count_dict.keys())\n",
    "\n",
    "n_words = len(words)\n",
    "n_tags = len(tags)\n",
    "\n",
    "n_words, n_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create row and column headers for access\n",
    "from copy import deepcopy\n",
    "\n",
    "# Transition Matric Labels (same for both row and column)\n",
    "transition_matrix_labels = {tag: i for i, tag in enumerate(tags)}\n",
    "transition_matrix_n_rows, transition_matrix_n_cols = len(transition_matrix_labels), len(transition_matrix_labels)\n",
    "\n",
    "# Emission Matrix Labels\n",
    "emission_col_labels = deepcopy(tags)\n",
    "emission_col_labels.remove(START_TAG)\n",
    "\n",
    "emission_matrix_n_rows, emission_matrix_n_cols = len(words), len(emission_col_labels)\n",
    "emission_matrix_row_labels = {word: i for i, word in enumerate(words)}\n",
    "emission_matrix_col_labels = {tag: i for i, tag in enumerate(emission_col_labels)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty transition and emission probability matrices\n",
    "transition_probabilities = np.zeros(shape=(transition_matrix_n_rows, transition_matrix_n_cols), dtype=np.float64)\n",
    "emission_probabilities = np.zeros(shape=(emission_matrix_n_rows, emission_matrix_n_cols), dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in emission probablity matrix\n",
    "for row_word, row_idx in emission_matrix_row_labels.items():\n",
    "    for col_tag, col_idx in emission_matrix_col_labels.items():\n",
    "        if col_tag not in word_tag_count_dict[row_word]:\n",
    "            emission_probabilities[row_idx][col_idx] = 0.0\n",
    "        else:\n",
    "            emission_probability = word_tag_count_dict[row_word][col_tag] / tag_count_dict[col_tag]\n",
    "\n",
    "            if emission_probability > 1:\n",
    "                emission_probability = 1\n",
    "\n",
    "            emission_probabilities[row_idx][col_idx] = emission_probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.19458669e-04, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 8.16603774e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.81900864e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.81900864e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [7.31528895e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [7.31528895e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in transition probablity matrix\n",
    "for row_tag, row_idx in transition_matrix_labels.items():\n",
    "    for col_tag, col_idx in transition_matrix_labels.items():\n",
    "        if col_tag not in tag_tag_count_dict[row_tag]:\n",
    "            transition_probabilities[row_idx][col_idx] = 0.0\n",
    "        else:\n",
    "            # TODO: Check this, why to add total tag count\n",
    "            transition_probabilities[row_idx][col_idx] = tag_tag_count_dict[row_tag][col_tag] / (\n",
    "                tag_count_dict[row_tag] + len(tag_count_dict)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 4.30058506e-02, 0.00000000e+00, ...,\n",
       "        6.83838614e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 2.27862874e-01, 1.79795770e-01, ...,\n",
       "        1.45878920e-04, 1.60466813e-03, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 1.94174757e-02, 5.82524272e-02, ...,\n",
       "        6.79611650e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 2.65625000e-01, 3.12500000e-02, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "write_model(MODEL_FILE, words, tags, tag_count_dict, transition_probabilities, emission_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, tags, tag_count_dict, transition_probabilities, emission_probabilities = load_model(MODEL_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decoding(\n",
    "    tags,\n",
    "    tag_count_dict,\n",
    "    emission_probabilities,\n",
    "    emission_matrix_row_labels,\n",
    "    emission_matrix_col_labels,\n",
    "    transition_probabilities,\n",
    "    transition_matrix_labels,\n",
    "    sentence,\n",
    "):\n",
    "    n_words_in_sentence = len(sentence)\n",
    "    n_tags = len(tags)\n",
    "\n",
    "    viterbi_matrix = np.zeros(shape=(n_tags, n_words_in_sentence), dtype=np.float64)\n",
    "    backtrack_matrix = np.zeros(shape=(n_tags, n_words_in_sentence), dtype=np.int32)\n",
    "\n",
    "    cumulative_probability = 0\n",
    "\n",
    "    for idx, tag in enumerate(tags):\n",
    "        # handle new word in corpus\n",
    "        word = sentence[0]\n",
    "\n",
    "        # Emission Probablity\n",
    "        # approach: set emission probability = 1 i.e. use transision probability alone\n",
    "        if word not in emission_matrix_row_labels:\n",
    "            em_prob = 1.0\n",
    "\n",
    "        elif word not in emission_matrix_row_labels or tag not in emission_matrix_col_labels:\n",
    "            em_prob = 0.0\n",
    "\n",
    "        else:\n",
    "            em_prob = emission_probabilities[emission_matrix_row_labels[word]][emission_matrix_col_labels[tag]]\n",
    "\n",
    "        # Transision Probability\n",
    "        if START_TAG not in transition_matrix_labels or tag not in transition_matrix_labels:\n",
    "            trans_prob = float(1 / (tag_count_dict[START_TAG] + n_tags))\n",
    "        else:\n",
    "            trans_prob = transition_probabilities[transition_matrix_labels[START_TAG]][transition_matrix_labels[tag]]\n",
    "\n",
    "        viterbi_matrix[idx][0] = trans_prob * em_prob\n",
    "\n",
    "        backtrack_matrix[idx][0] = 0\n",
    "\n",
    "    for idx in range(1, n_words_in_sentence):\n",
    "\n",
    "        for end_tag in tags:\n",
    "\n",
    "            for start_tag in tags:\n",
    "\n",
    "                word = sentence[idx]\n",
    "\n",
    "                # emission\n",
    "                if word not in emission_matrix_row_labels:\n",
    "                    em_prob = 1.0\n",
    "                elif word not in emission_matrix_row_labels or end_tag not in emission_matrix_col_labels:\n",
    "                    em_prob = 0.0\n",
    "                else:\n",
    "                    em_prob = emission_probabilities[emission_matrix_row_labels[word]][\n",
    "                        emission_matrix_col_labels[end_tag]\n",
    "                    ]\n",
    "                    if em_prob == 0.0:\n",
    "                        continue\n",
    "\n",
    "                # set transition key of the beginning of sentence: tag1-tag2 (follow model format)\n",
    "                if start_tag not in transition_matrix_labels or end_tag not in transition_matrix_labels:\n",
    "                    trans_prob = 1 / (tag_count_dict[start_tag] + n_tags)\n",
    "                else:\n",
    "                    trans_prob = transition_probabilities[transition_matrix_labels[start_tag]][\n",
    "                        transition_matrix_labels[end_tag]\n",
    "                    ]\n",
    "                    if trans_prob == 0:\n",
    "                        continue\n",
    "\n",
    "                cumulative_probability = (\n",
    "                    viterbi_matrix[transition_matrix_labels[start_tag]][idx - 1] * trans_prob * em_prob\n",
    "                )\n",
    "                if cumulative_probability == 0:\n",
    "                    continue\n",
    "\n",
    "                if cumulative_probability > viterbi_matrix[transition_matrix_labels[end_tag]][idx]:\n",
    "                    viterbi_matrix[transition_matrix_labels[end_tag]][idx] = cumulative_probability\n",
    "                    backtrack_matrix[transition_matrix_labels[end_tag]][idx] = transition_matrix_labels[start_tag]\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "    return (viterbi_matrix, backtrack_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_backtrack(tags, viterbi_matrix, backtrack_matrix, sentence):\n",
    "    n_tags = len(tags)\n",
    "    n_words_in_sentence = len(sentence)\n",
    "\n",
    "    # Backtracking\n",
    "    best_idx = 0\n",
    "    for i in range(n_tags):\n",
    "        if viterbi_matrix[i][n_words_in_sentence - 1] > viterbi_matrix[best_idx][n_words_in_sentence - 1]:\n",
    "            best_idx = i\n",
    "\n",
    "    output = [f\"{sentence[n_words_in_sentence - 1]}/{tags[best_idx]}\"]\n",
    "\n",
    "    for idx in range(n_words_in_sentence - 1, 0, -1):\n",
    "        best_idx = backtrack_matrix[best_idx][idx]\n",
    "        output.insert(0, f\"{sentence[idx - 1]}/{tags[best_idx]}\")\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load development data\n",
    "dev_raw_document = load_document(EXPERIMENT_TEST_RAW_DOCUMENT)\n",
    "dev_raw_tagged_document = load_document(EXPERIMENT_TEST_RAW_TAGGED_DOCUMENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['\"/FB',\n",
       "  'Baggio/SP',\n",
       "  ',/FF',\n",
       "  'Savicevic/S',\n",
       "  'e/CC',\n",
       "  'Weah/BN',\n",
       "  'possono/VM',\n",
       "  'giocare/V',\n",
       "  'insieme/B',\n",
       "  './FS'],\n",
       " ['\"/FB',\n",
       "  'Baggio/SP',\n",
       "  ',/FF',\n",
       "  'Savicevic/SP',\n",
       "  'e/CC',\n",
       "  'Weah/SP',\n",
       "  'possono/VM',\n",
       "  'giocare/V',\n",
       "  'insieme/B',\n",
       "  './FS'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Block\n",
    "\n",
    "SAMPLE_IDX = 101\n",
    "sample, sample_tagged = dev_raw_document[SAMPLE_IDX], dev_raw_tagged_document[SAMPLE_IDX]\n",
    "\n",
    "viterbi_matrix, backtrack_matrix = viterbi_decoding(\n",
    "    tags,\n",
    "    tag_count_dict,\n",
    "    emission_probabilities,\n",
    "    emission_matrix_row_labels,\n",
    "    emission_matrix_col_labels,\n",
    "    transition_probabilities,\n",
    "    transition_matrix_labels,\n",
    "    sample,\n",
    ")\n",
    "output = viterbi_backtrack(tags, viterbi_matrix, backtrack_matrix, sample)\n",
    "output, sample_tagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteds_tags = list()\n",
    "for idx, sentence in enumerate(dev_raw_document):\n",
    "    viterbi_matrix, backtrack_matrix = viterbi_decoding(\n",
    "        tags,\n",
    "        tag_count_dict,\n",
    "        emission_probabilities,\n",
    "        emission_matrix_row_labels,\n",
    "        emission_matrix_col_labels,\n",
    "        transition_probabilities,\n",
    "        transition_matrix_labels,\n",
    "        sentence,\n",
    "    )\n",
    "    output = viterbi_backtrack(tags, viterbi_matrix, backtrack_matrix, sentence)\n",
    "    predicteds_tags.append(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tagged_true, tagged_preds):\n",
    "    total_count, correct_count = 0, 0\n",
    "    for sentence_true, sentence_pred in zip(tagged_true, tagged_preds):\n",
    "        for word_tag_true, word_tag_pred in zip(sentence_true, sentence_pred):\n",
    "            if word_tag_true == word_tag_pred:\n",
    "                correct_count += 1\n",
    "            total_count += 1\n",
    "    return correct_count / total_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9327342962714141"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(dev_raw_tagged_document, predicteds_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use Open Class labels to handle unseen words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Smoothing and unseen words and transitions. You should implement some method to handle unknown vocabulary and unseen transitions in the test data, otherwise your programs won’t work.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('CSCI544_assignment_03')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99319869c2b84476c56e7423ed21631b8ddb5a8a9b4475198cf8370d36903f81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
