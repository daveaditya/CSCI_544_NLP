{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/aditya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "! pip install bs4 # in case you don't have it installed\n",
    "\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Jewelry_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data\"\n",
    "DATA_FILE = \"amazon_reviews_us_Jewelry_v1_00.tsv\"\n",
    "\n",
    "DATA_COL = \"review_body\"\n",
    "TARGET_COL = \"star_rating\"\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/gcxbjppx70qfkdwy32kg04dh0000gn/T/ipykernel_30773/1935721861.py:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(f\"{DATA_PATH}/amazon_reviews_us_Jewelry_v1_00.tsv\", sep=\"\\t\", usecols=[TARGET_COL, DATA_COL])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>so beautiful even tho clearly not high end ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.. I got this set for my mother, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Exactly as pictured and my daughter's friend l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Love it. Fits great. Super comfortable and nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Got this as a Mother's Day gift for my Mom and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  star_rating                                        review_body\n",
       "0           5  so beautiful even tho clearly not high end ......\n",
       "1           5  Great product.. I got this set for my mother, ...\n",
       "2           5  Exactly as pictured and my daughter's friend l...\n",
       "3           5  Love it. Fits great. Super comfortable and nea...\n",
       "4           5  Got this as a Mother's Day gift for my Mom and..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the tab separated data file, and print the first 5 rows for confirmation\n",
    "data = pd.read_csv(f\"{DATA_PATH}/amazon_reviews_us_Jewelry_v1_00.tsv\", sep=\"\\t\", usecols=[TARGET_COL, DATA_COL], low_memory=True)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"review_body\"].isna().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1766807</td>\n",
       "      <td>1766807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10</td>\n",
       "      <td>1618522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>5</td>\n",
       "      <td>Love it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1040896</td>\n",
       "      <td>4288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        star_rating review_body\n",
       "count       1766807     1766807\n",
       "unique           10     1618522\n",
       "top               5     Love it\n",
       "freq        1040896        4288"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 4, 3, 2, '5', '1', '3', '4', '2'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.star_rating.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1040896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             review_body\n",
       "star_rating             \n",
       "1                 150441\n",
       "2                  97259\n",
       "3                 153660\n",
       "4                 259019\n",
       "5                1040896\n",
       "1                   4566\n",
       "2                   3541\n",
       "3                   5999\n",
       "4                  11411\n",
       "5                  40015"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby([TARGET_COL]).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the outlier which is star_rating = \"2012-12-21\"\n",
    "data = data[data.star_rating != \"2012-12-21\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan valued rows\n",
    "data = data[data[TARGET_COL].notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1766807</td>\n",
       "      <td>1766807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10</td>\n",
       "      <td>1618522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>5</td>\n",
       "      <td>Love it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1040896</td>\n",
       "      <td>4288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        star_rating review_body\n",
       "count       1766807     1766807\n",
       "unique           10     1618522\n",
       "top               5     Love it\n",
       "freq        1040896        4288"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all star rating to integer\n",
    "data[TARGET_COL] = data.star_rating.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>so beautiful even tho clearly not high end ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.. I got this set for my mother, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Exactly as pictured and my daughter's friend l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Love it. Fits great. Super comfortable and nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Got this as a Mother's Day gift for my Mom and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                        review_body\n",
       "0            5  so beautiful even tho clearly not high end ......\n",
       "1            5  Great product.. I got this set for my mother, ...\n",
       "2            5  Exactly as pictured and my daughter's friend l...\n",
       "3            5  Love it. Fits great. Super comfortable and nea...\n",
       "4            5  Got this as a Mother's Day gift for my Mom and..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>so beautiful even tho clearly not high end ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.. I got this set for my mother, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Exactly as pictured and my daughter's friend l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Love it. Fits great. Super comfortable and nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Got this as a Mother's Day gift for my Mom and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                        review_body\n",
       "0            5  so beautiful even tho clearly not high end ......\n",
       "1            5  Great product.. I got this set for my mother, ...\n",
       "2            5  Exactly as pictured and my daughter's friend l...\n",
       "3            5  Love it. Fits great. Super comfortable and nea...\n",
       "4            5  Got this as a Mother's Day gift for my Mom and..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data.review_body.notnull()]\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are no empty reviews\n",
    "(data.review_body.str.len() <= 0).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can continue with the process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We select 20000 reviews randomly from each rating class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = data.groupby(TARGET_COL, group_keys=False).apply(lambda x: x.sample(N_SAMPLES, random_state=RANDOM_SEED))\n",
    "sampled_data.reset_index(inplace=True)\n",
    "sampled_data.drop(columns=[\"index\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Too small even for the knuckles.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Did not fit right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>This stupid kit has 16 gauge needles not 14gauge.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I would not suggest this item I bought the one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I am sure that it will be lovely once I get it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                        review_body\n",
       "0            1                   Too small even for the knuckles.\n",
       "1            1                                  Did not fit right\n",
       "2            1  This stupid kit has 16 gauge needles not 14gauge.\n",
       "3            1  I would not suggest this item I bought the one...\n",
       "4            1  I am sure that it will be lovely once I get it..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_len_before_cleaning = sampled_data.review_body.str.len().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all reviews to lower case (optional according to study)\n",
    "def to_lower(data: pd.Series):\n",
    "    return data.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_characters(data: pd.Series):\n",
    "    import unicodedata\n",
    "\n",
    "    \"\"\"Removes accented characters from the Series\n",
    "\n",
    "    Args:\n",
    "        data (pd.Series): Series of string\n",
    "\n",
    "    Returns:\n",
    "        _type_: pd.Series\n",
    "    \"\"\"\n",
    "    import unicodedata\n",
    "\n",
    "    return data.apply(lambda x: unicodedata.normalize(\"NFKD\", x).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_encodings(data: pd.Series):\n",
    "  return data.str.replace(r\"&#\\d+;\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(data: pd.Series):\n",
    "  return data.str.replace(r\"<[a-zA-Z]+\\s?/?>\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(data: pd.Series):\n",
    "  return data.str.replace(r\"https?://([\\w\\-\\._]+){2,}/[\\w\\-\\.\\-/=\\+_\\?]+\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_and_url(data: pd.Series):\n",
    "    \"\"\"Function to remove\n",
    "             1. HTML encodings\n",
    "             2. HTML tags (both closed and open)\n",
    "             3. URLs\n",
    "\n",
    "    Args:\n",
    "        data (pd.Series): A Pandas series of type string\n",
    "\n",
    "    Returns:\n",
    "        _type_: pd.Series\n",
    "    \"\"\"\n",
    "    # Remove HTML encodings\n",
    "    data.str.replace(r\"&#\\d+;\", \" \", regex=True)\n",
    "\n",
    "    # Remove HTML tags (both open and closed)\n",
    "    data.str.replace(r\"<[a-zA-Z]+\\s?/?>\", \" \", regex=True)\n",
    "\n",
    "    # Remove URLs\n",
    "    data.str.replace(r\"https?://([\\w\\-\\._]+){2,}/[\\w\\-\\.\\-/=\\+_\\?]+\", \" \", regex=True)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emot in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (3.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install emot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle emoji\n",
    "def convert_emoji_to_txt(data: pd.Series):\n",
    "  from emot.emo_unicode import UNICODE_EMOJI, EMOTICONS_EMO\n",
    "\n",
    "  EMO_TO_TXT_DICT = dict()\n",
    "  for emot in UNICODE_EMOJI:\n",
    "    EMO_TO_TXT_DICT[emot] = f\" {re.sub(r',|:|_', '', UNICODE_EMOJI[emot])} \"\n",
    "\n",
    "  for emo in EMOTICONS_EMO:\n",
    "    EMO_TO_TXT_DICT[emot] = f\" {re.sub(r',| ', '', EMOTICONS_EMO[emo])} \"\n",
    "\n",
    "  def convert_emojis(text, emo_to_txt_dict):\n",
    "    for emot in emo_to_txt_dict:\n",
    "        text = text.replace(emot, emo_to_txt_dict[emot])\n",
    "    return text\n",
    "\n",
    "  return data.apply(lambda x: convert_emojis(x, EMO_TO_TXT_DICT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_digits_with_tag(data: pd.Series):  \n",
    "  return data.str.replace(r\"\\d+\", \" NUM \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-alphabetical characters\n",
    "def remove_non_alpha_characters(data: pd.Series):\n",
    "    return data.str.replace(r\"_+|\\\\|[^a-zA-Z0-9\\s]\", \" \", regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "def remove_extra_spaces(data: pd.Series):\n",
    "    return data.str.replace(r\"^\\s*|\\s\\s*\", \" \", regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (0.1.72)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (from contractions) (0.0.21)\n",
      "Requirement already satisfied: anyascii in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n",
      "Requirement already satisfied: pyahocorasick in /Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n"
     ]
    }
   ],
   "source": [
    "# Install contractions package, if you don't have it\n",
    "! pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding contractions\n",
    "def fix_contractions(data: pd.Series):\n",
    "    import contractions\n",
    "\n",
    "    def contraction_fixer(txt: str):\n",
    "        return \" \".join([contractions.fix(word) for word in txt.split()])\n",
    "\n",
    "    return data.apply(contraction_fixer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: convert_emoji_to_txt\n",
      "Ended: convert_emoji_to_txt\n",
      "Starting: to_lower\n",
      "Ended: to_lower\n",
      "Starting: remove_accented_characters\n",
      "Ended: remove_accented_characters\n",
      "Starting: remove_html_encodings\n",
      "Ended: remove_html_encodings\n",
      "Starting: remove_html_tags\n",
      "Ended: remove_html_tags\n",
      "Starting: remove_url\n",
      "Ended: remove_url\n",
      "Starting: fix_contractions\n",
      "Ended: fix_contractions\n",
      "Starting: remove_non_alpha_characters\n",
      "Ended: remove_non_alpha_characters\n",
      "Starting: remove_extra_spaces\n",
      "Ended: remove_extra_spaces\n"
     ]
    }
   ],
   "source": [
    "# A dictionary containing the columns and a list of functions to perform on it in order\n",
    "data_cleaning_pipeline = {\n",
    "    DATA_COL: [\n",
    "        convert_emoji_to_txt,\n",
    "        to_lower,\n",
    "        remove_accented_characters,\n",
    "        remove_html_encodings,\n",
    "        remove_html_tags,\n",
    "        remove_url,\n",
    "        fix_contractions,\n",
    "        remove_non_alpha_characters,\n",
    "        remove_extra_spaces,\n",
    "    ]\n",
    "}\n",
    "\n",
    "cleaned_data = sampled_data.copy()\n",
    "\n",
    "# Process all the cleaning instructions\n",
    "for col, pipeline in data_cleaning_pipeline.items():\n",
    "    # Get the column to perform cleaning on\n",
    "    temp_data = cleaned_data[col].copy()\n",
    "\n",
    "    # Perform all the cleaning functions sequencially\n",
    "    for func in pipeline:\n",
    "        print(f\"Starting: {func.__name__}\")\n",
    "        temp_data = func(temp_data)\n",
    "        print(f\"Ended: {func.__name__}\")\n",
    "\n",
    "    # Replace the old column with cleaned one.\n",
    "    cleaned_data[col] = temp_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_len_after_cleaning = cleaned_data.review_body.str.len().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'189.50703,185.32883'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{avg_len_before_cleaning},{avg_len_after_cleaning}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_len_before_preprocessing = cleaned_data[DATA_COL].str.len().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data: pd.Series):\n",
    "    from nltk.tokenize import word_tokenize\n",
    "\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "    return data.apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Set\n",
    "\n",
    "\n",
    "def remove_stopwords(data: pd.Series):\n",
    "    \"\"\"Remove stop words using the NLTK stopwords dictionary\n",
    "\n",
    "    Args:\n",
    "        string (str): a document\n",
    "\n",
    "    Returns:\n",
    "        str: a document with stopwords removed\n",
    "    \"\"\"\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    nltk.download(\"stopwords\")\n",
    "\n",
    "    stopwords = set(stopwords.words())\n",
    "\n",
    "    def remover(word_list: List[str], stopwords: Set[str]):\n",
    "        return [word for word in word_list if not word in stopwords]\n",
    "\n",
    "    return data.apply(lambda word_list: remover(word_list, stopwords))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(data: pd.Series, consider_pos_tag: bool = True):\n",
    "    from nltk.corpus import wordnet\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "    nltk.download(\"omw-1.4\")\n",
    "\n",
    "    # POS tagging\n",
    "    def perform_nltk_pos_tag(data: pd.Series):\n",
    "        from nltk import pos_tag\n",
    "\n",
    "        nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "        return data.apply(pos_tag)\n",
    "\n",
    "    # Convert POS tag to wordnet pos tags\n",
    "    def wordnet_pos_tagger(tag: str):\n",
    "        if tag.startswith(\"J\"):\n",
    "            return wordnet.ADJ\n",
    "        elif tag.startswith(\"V\"):\n",
    "            return wordnet.VERB\n",
    "        elif tag.startswith(\"N\"):\n",
    "            return wordnet.NOUN\n",
    "        elif tag.startswith(\"R\"):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = list()\n",
    "\n",
    "    if consider_pos_tag:\n",
    "        pos_tagged_data = data.copy()\n",
    "        pos_tagged_data = perform_nltk_pos_tag(data)\n",
    "\n",
    "        for row in pos_tagged_data:\n",
    "\n",
    "            lemmatized_row = list()\n",
    "\n",
    "            if consider_pos_tag:\n",
    "                for word, tag in row:\n",
    "                    wordnet_pos_tag = wordnet_pos_tagger(tag)\n",
    "\n",
    "                    if wordnet_pos_tag is None:\n",
    "                        lemmatized_row.append(word)\n",
    "                    else:\n",
    "                        result = lemmatizer.lemmatize(word, wordnet_pos_tag)\n",
    "                        lemmatized_row.append(lemmatizer.lemmatize(word, wordnet_pos_tag))\n",
    "\n",
    "            lemmatized.append(lemmatized_row)\n",
    "    else:\n",
    "        for row in data:\n",
    "            lemmatized_row = list()\n",
    "\n",
    "            for word in row:\n",
    "                lemmatized_row.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "            lemmatized.append(lemmatized_row)\n",
    "\n",
    "    return pd.Series(lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate lemmatized sentences back into one sentence\n",
    "def concatenate(data: pd.Series):\n",
    "    return data.apply(lambda words: \" \".join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: tokenize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/aditya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended: tokenize\n",
      "Starting: lemmatize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/aditya/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/aditya/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended: lemmatize\n",
      "Starting: concatenate\n",
      "Ended: concatenate\n"
     ]
    }
   ],
   "source": [
    "preprocessing_pipeline = {DATA_COL: [tokenize, lemmatize, concatenate]}\n",
    "\n",
    "# Run the pipeline\n",
    "preprocessed_data = cleaned_data.copy()\n",
    "\n",
    "# Process all the cleaning instructions\n",
    "for col, pipeline in preprocessing_pipeline.items():\n",
    "    # Get the column to perform cleaning on\n",
    "    temp_data = preprocessed_data[col].copy()\n",
    "\n",
    "    # Perform all the cleaning functions sequencially\n",
    "    for func in pipeline:\n",
    "        print(f\"Starting: {func.__name__}\")\n",
    "\n",
    "        if func.__name__ == \"lemmatize\":\n",
    "            temp_data = func(temp_data, consider_pos_tag=True)\n",
    "        else:\n",
    "            temp_data = func(temp_data)\n",
    "\n",
    "        print(f\"Ended: {func.__name__}\")\n",
    "\n",
    "    # Replace the old column with cleaned one.\n",
    "    preprocessed_data[col] = temp_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>too small even for the knuckle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>do not fit right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>this stupid kit have 16 gauge needle not 14gauge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i would not suggest this item i buy the one wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>i be sure that it will be lovely once i get it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                        review_body\n",
       "0            1                     too small even for the knuckle\n",
       "1            1                                   do not fit right\n",
       "2            1   this stupid kit have 16 gauge needle not 14gauge\n",
       "3            1  i would not suggest this item i buy the one wi...\n",
       "4            1  i be sure that it will be lovely once i get it..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "avg_len_after_preprocessing = preprocessed_data[DATA_COL].str.len().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'185.32883,176.85228'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{avg_len_before_preprocessing},{avg_len_after_preprocessing}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty reviews\n",
    "preprocessed_data = preprocessed_data[preprocessed_data[DATA_COL].str.len() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = preprocessed_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data 80-20 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(final_data, test_size=0.2, stratify=final_data[TARGET_COL], random_state=RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/aditya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/Users/aditya/.pyenv/versions/3.10.6/envs/csci544-assignment-01/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=word_tokenize)\n",
    "vectorizer.fit(final_data[DATA_COL])\n",
    "\n",
    "X_tfidf_train = vectorizer.transform(train[DATA_COL])\n",
    "X_tfidf_test = vectorizer.transform(test[DATA_COL])\n",
    "y_train = train[TARGET_COL]\n",
    "y_test = test[TARGET_COL]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred):\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, average=None)\n",
    "    recall = recall_score(y_true, y_pred, average=None)\n",
    "    f1 = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "    for rating_precision, rating_recall, rating_f1 in zip(precision, recall, f1):\n",
    "        print(f\"{rating_precision},{rating_recall},{rating_f1}\")\n",
    "\n",
    "    print(f\"{np.mean(precision)},{np.mean(recall)},{np.mean(f1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5179242918024568,0.5166291572893223,0.5172759138708063\n",
      "0.3148377508050533,0.31775,0.31628717183028493\n",
      "0.3168876755070203,0.40625,0.3560473269062227\n",
      "0.37042925278219396,0.3495,0.359660406483149\n",
      "0.6373411534701857,0.48924462231115556,0.5535587943964907\n",
      "0.43148402487338205,0.4158747559200956,0.4205659226973907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# clf = Perceptron(max_iter=1000, alpha=0.5, random_state=RANDOM_SEED) # 0.43115027900835684\n",
    "# clf = Perceptron(max_iter=1000, alpha=0.5, random_state=RANDOM_SEED, tol=1e-5) # 0.4336870195755223\n",
    "# clf = Perceptron(max_iter=4000, alpha=0.5, random_state=RANDOM_SEED, tol=1e-5, early_stopping=True) # 0.4343847796358854\n",
    "# clf = Perceptron(max_iter=8000, alpha=0.01, random_state=RANDOM_SEED, tol=1e-5, early_stopping=True, class_weight=\"balanced\") # 0.4343847796358854\n",
    "\n",
    "# class_weight = {1: 0.29525, 2: 16.95725, 3: 8.9525, 4: 1, 5: 0.7385} # 0.45103975891511683\n",
    "# class_weight = {1: 0.29525, 2: 7.8048, 3: 8.4525, 4: 1, 5: 0.9385}\n",
    "class_weight = {1: 0.9525, 2: 1.99825, 3: 1.9225, 4: 0.625, 5: 0.8585}\n",
    "clf = Perceptron(max_iter=8000, alpha=0.012, random_state=RANDOM_SEED, tol=1e-4, early_stopping=True, class_weight=\"balanced\") # 0.45103975891511683\n",
    "\n",
    "clf.fit(X_tfidf_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_tfidf_test)\n",
    "\n",
    "# print(\"Train ...\")\n",
    "# calc_metrics(y_train, clf.predict(X_tfidf_train))\n",
    "# print(\"Test...\")\n",
    "calc_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6652977412731006,0.48612153038259565,0.5617685305591678\n",
      "0.38524890190336747,0.52625,0.444843617920541\n",
      "0.3793507362784471,0.56675,0.4544907778668805\n",
      "0.6078431372549019,0.14725,0.2370698329643791\n",
      "0.6618088298328333,0.7723861930965483,0.7128347183748847\n",
      "0.53990986930853,0.4997515446958287,0.4822014955371706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# class_weight = {1: 0.95, 2: 1.7, 3: 1.65, 4: 1, 5: 0.6525} # 0.5250080879095086\n",
    "# class_weight = {1: 0.95, 2: 1.65, 3: 1.85, 4: 1, 5: 0.6525} # 0.5265625011400694\n",
    "# class_weight = {1: 0.95, 2: 1.725, 3: 2.85, 4: 1, 5: 0.6525} # 0.5283863569082248\n",
    "# class_weight = {1: 0.95, 2: 1.725, 3: 2.85, 4: 1, 5: 0.6525} # 0.5298186572543087\n",
    "# class_weight = {1: 0.95, 2: 1.725, 3: 2.925, 4: 1, 5: 0.8525} # 0.5298707666039373\n",
    "# class_weight = {1: 0.95, 2: 1.725, 3: 2.925, 4: 1, 5: 0.9585} # 0.5305190760270104\n",
    "# class_weight = {1: 0.95, 2: 1.8525, 3: 2.925, 4: 1, 5: 0.9585} # 0.5318580010845554\n",
    "# class_weight = {1: 0.95, 2: 1.8525, 3: 3.3525, 4: 1, 5: 0.9585} # 0.5328127772891916\n",
    "# class_weight = {1: 0.95, 2: 1.9725, 3: 3.3525, 4: 1, 5: 0.9585} # 0.534678946516937\n",
    "# class_weight = {1: 0.95, 2: 2.3725, 3: 3.3525, 4: 1, 5: 0.9585} # 0.5378650442928313\n",
    "# class_weight = {1: 0.95, 2: 2.85725, 3: 3.5525, 4: 1, 5: 0.9585} # 0.5403434839237587\n",
    "# class_weight = {1: 0.95, 2: 4.85725, 3: 3.8525, 4: 1, 5: 0.9585} # 0.5474152267990974\n",
    "# class_weight = {1: 0.7625, 2: 4.85725, 3: 3.8525, 4: 1, 5: 0.9585} # 0.551693399374575\n",
    "# class_weight = {1: 0.7625, 2: 5.25725, 3: 3.9525, 4: 1, 5: 0.9585} # 0.5519983833002682\n",
    "# class_weight = {1: 0.7625, 2: 5.95725, 3: 3.9525, 4: 1, 5: 0.9585} # 0.5530668437190186\n",
    "# class_weight = {1: 0.5625, 2: 5.95725, 3: 4.2525, 4: 1, 5: 0.9585} # 0.5634729752537446\n",
    "# class_weight = {1: 0.5625, 2: 6.95725, 3: 4.6525, 4: 1, 5: 0.8585} # 0.5656444257835423\n",
    "# class_weight = {1: 0.2625, 2: 6.95725, 3: 4.6525, 4: 1, 5: 0.8585} # 0.5732672392507041\n",
    "class_weight = {1: 0.9525, 2: 1.99825, 3: 1.9225, 4: 0.625, 5: 0.8585} # 0.5746383318772281\n",
    "\n",
    "clf = LinearSVC(dual=False, C=0.1, max_iter=1000, class_weight=class_weight, random_state=RANDOM_SEED)\n",
    "\n",
    "clf.fit(X_tfidf_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_tfidf_test)\n",
    "\n",
    "calc_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7653631284916201,0.3083270817704426,0.439572192513369\n",
      "0.3659177122847972,0.627,0.4621337755666114\n",
      "0.3540203525870718,0.6175,0.4500318848501412\n",
      "0.6307339449541285,0.06875,0.12398557258791706\n",
      "0.6792910900704054,0.6998499249624812,0.6894172723912775\n",
      "0.5590652456776046,0.4642854013465848,0.43302813958186326\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# class_weight = {1: 1, 2: 1, 3: 1, 4: 1, 5: 1.1024} # 0.5172256481829293\n",
    "class_weight = {1: 0.9525, 2: 1.99825, 3: 1.9225, 4: 0.625, 5: 0.8585} \n",
    "\n",
    "clf = LogisticRegression(penalty='l2', solver=\"saga\", max_iter=200, multi_class=\"multinomial\", C=0.1024, random_state=RANDOM_SEED, class_weight=class_weight)\n",
    "\n",
    "clf.fit(X_tfidf_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_tfidf_test)\n",
    "\n",
    "# print(\"Train ...\")\n",
    "# calc_metrics(y_train, clf.predict(X_tfidf_train))\n",
    "# print(\"Test...\")\n",
    "calc_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6752488843117062,0.4918729682420605,0.5691550925925926\n",
      "0.38682055100521223,0.5195,0.44344857020913364\n",
      "0.40814814814814815,0.41325,0.41068322981366456\n",
      "0.4389505549949546,0.435,0.4369663485685585\n",
      "0.6687398593834505,0.6185592796398199,0.6426715176715176\n",
      "0.5155815995686943,0.49563644957637615,0.5005849517710934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "class_prior = [0.2, 0.2048, 0.2, 0.2, 0.22476]\n",
    "\n",
    "# clf = MultinomialNB(alpha=1.064) # 0.4952600291865206\n",
    "# clf = MultinomialNB(alpha=2.5) # 0.5024158722296946\n",
    "# clf = MultinomialNB(alpha=3.9086) # 0.5065314917640114\n",
    "# clf = MultinomialNB(alpha=32.7886) # 0.5124296411150511\n",
    "clf = MultinomialNB(alpha=32.8824, class_prior=class_prior) # 0.5126996219647234\n",
    "\n",
    "clf.fit(X_tfidf_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_tfidf_test)\n",
    "\n",
    "# print(\"Train ...\")\n",
    "# calc_metrics(y_train, clf.predict(X_tfidf_train))\n",
    "# print(\"Test...\")\n",
    "calc_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('csci544-assignment-01')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "94e57c780941729b66a50fa43f276db225d69de54eca80cd479b96d3e11990ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
